{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7M0j3W7ubfc",
        "outputId": "8e3a0814-0753-4bf3-f925-f91b0e5cb305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting qiskit\n",
            "  Downloading qiskit-0.39.2.tar.gz (13 kB)\n",
            "Collecting qcware\n",
            "  Downloading qcware-7.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting qcware-quasar\n",
            "  Downloading qcware_quasar-1.0.7-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting chex>=0.0.4\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (1.3.0)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.22+cuda11.cudnn805)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.21.6)\n",
            "Requirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.23)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from optax) (4.1.1)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.7)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Collecting qiskit-terra==0.22.2\n",
            "  Downloading qiskit_terra-0.22.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8 MB 50.8 MB/s \n",
            "\u001b[?25hCollecting qiskit-aer==0.11.1\n",
            "  Downloading qiskit_aer-0.11.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.2 MB 78.6 MB/s \n",
            "\u001b[?25hCollecting qiskit-ibmq-provider==0.19.2\n",
            "  Downloading qiskit_ibmq_provider-0.19.2-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 86.2 MB/s \n",
            "\u001b[?25hCollecting websocket-client>=1.0.1\n",
            "  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting requests-ntlm>=1.1.0\n",
            "  Downloading requests_ntlm-1.1.0-py2.py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (2.23.0)\n",
            "Collecting websockets>=10.0\n",
            "  Downloading websockets-10.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 76.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-ibmq-provider==0.19.2->qiskit) (2.8.2)\n",
            "Collecting ply>=3.10\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 638 kB/s \n",
            "\u001b[?25hCollecting symengine>=0.9\n",
            "  Downloading symengine-0.9.2-cp37-cp37m-manylinux2010_x86_64.whl (37.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.5 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill>=0.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.22.2->qiskit) (0.3.6)\n",
            "Collecting tweedledum<2.0,>=1.1\n",
            "  Downloading tweedledum-1.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (943 kB)\n",
            "\u001b[K     |████████████████████████████████| 943 kB 37.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.22.2->qiskit) (1.7.1)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.22.2->qiskit) (5.4.8)\n",
            "Collecting retworkx>=0.11.0\n",
            "  Downloading retworkx-0.12.0-py3-none-any.whl (10 kB)\n",
            "Collecting stevedore>=3.0.0\n",
            "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting shared-memory38\n",
            "  Downloading shared_memory38-0.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: importlib-metadata<5.0 in /usr/local/lib/python3.7/dist-packages (from qiskit-terra==0.22.2->qiskit) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0->qiskit-terra==0.22.2->qiskit) (3.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.8.0->qiskit-ibmq-provider==0.19.2->qiskit) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19->qiskit-ibmq-provider==0.19.2->qiskit) (2.10)\n",
            "Collecting ntlm-auth>=1.0.2\n",
            "  Downloading ntlm_auth-1.5.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting cryptography>=1.3\n",
            "  Downloading cryptography-38.0.3-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.2->qiskit) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibmq-provider==0.19.2->qiskit) (2.21)\n",
            "Collecting rustworkx==0.12.0\n",
            "  Downloading rustworkx-0.12.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 39.6 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.3->qiskit-terra==0.22.2->qiskit) (1.2.1)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from qcware) (2.6.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from qcware) (21.3)\n",
            "Collecting python-decouple>=3.4\n",
            "  Downloading python_decouple-3.6-py3-none-any.whl (9.9 kB)\n",
            "Collecting rich>=12.0\n",
            "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
            "\u001b[K     |████████████████████████████████| 237 kB 66.5 MB/s \n",
            "\u001b[?25hCollecting lz4>=3.1.3\n",
            "  Downloading lz4-4.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 56.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp>=3.7.4.post0 in /usr/local/lib/python3.7/dist-packages (from qcware) (3.8.3)\n",
            "Collecting requests>=2.19\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from qcware) (1.10.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from qcware) (0.8.10)\n",
            "Requirement already satisfied: setuptools>=57.1.0 in /usr/local/lib/python3.7/dist-packages (from qcware) (57.4.0)\n",
            "Collecting qubovert>=1.2.3\n",
            "  Downloading qubovert-1.2.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 57.1 MB/s \n",
            "\u001b[?25hCollecting colorama>=0.4.4\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting icontract>=2.5.3\n",
            "  Downloading icontract-2.6.2-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 291 kB/s \n",
            "\u001b[?25hCollecting backoff>=1.10.0\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: sortedcontainers>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from qcware-quasar) (2.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7.4.post0->qcware) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7.4.post0->qcware) (1.8.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7.4.post0->qcware) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7.4.post0->qcware) (22.1.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7.4.post0->qcware) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7.4.post0->qcware) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7.4.post0->qcware) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7.4.post0->qcware) (2.1.1)\n",
            "Collecting asttokens<3,>=2\n",
            "  Downloading asttokens-2.1.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->qcware) (3.0.9)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=12.0->qcware) (2.6.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (5.10.0)\n",
            "Building wheels for collected packages: qiskit\n",
            "  Building wheel for qiskit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qiskit: filename=qiskit-0.39.2-py3-none-any.whl size=12224 sha256=74597e3fbe1c4a71db38270eb3803651e546c78bf2a0033853b4f866922eeb28\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dc/90/0ee55ccffd13c16db1abd4c43028f7c9cedb5576b190402190\n",
            "Successfully built qiskit\n",
            "Installing collected packages: rustworkx, pbr, tweedledum, symengine, stevedore, shared-memory38, retworkx, requests, ply, ntlm-auth, cryptography, websockets, websocket-client, requests-ntlm, qiskit-terra, commonmark, asttokens, rich, qubovert, qiskit-ibmq-provider, qiskit-aer, qcware-quasar, python-decouple, lz4, icontract, colorama, chex, backoff, qiskit, qcware, optax\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed asttokens-2.1.0 backoff-2.2.1 chex-0.1.5 colorama-0.4.6 commonmark-0.9.1 cryptography-38.0.3 icontract-2.6.2 lz4-4.0.2 ntlm-auth-1.5.0 optax-0.1.3 pbr-5.11.0 ply-3.11 python-decouple-3.6 qcware-7.4.3 qcware-quasar-1.0.7 qiskit-0.39.2 qiskit-aer-0.11.1 qiskit-ibmq-provider-0.19.2 qiskit-terra-0.22.2 qubovert-1.2.5 requests-2.28.1 requests-ntlm-1.1.0 retworkx-0.12.0 rich-12.6.0 rustworkx-0.12.0 shared-memory38-0.1.2 stevedore-3.5.2 symengine-0.9.2 tweedledum-1.1.1 websocket-client-1.4.2 websockets-10.4\n",
            "Cloning into 'deep-hedging'...\n",
            "remote: Enumerating objects: 611, done.\u001b[K\n",
            "remote: Counting objects: 100% (418/418), done.\u001b[K\n",
            "remote: Compressing objects: 100% (207/207), done.\u001b[K\n",
            "remote: Total 611 (delta 276), reused 288 (delta 211), pack-reused 193\u001b[K\n",
            "Receiving objects: 100% (611/611), 12.35 MiB | 8.05 MiB/s, done.\n",
            "Resolving deltas: 100% (384/384), done.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "  %pip install optax qiskit qcware qcware-quasar\n",
        "  ! rm -rf deep-hedging\n",
        "  ! git clone https://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@github.com/SnehalRaj/jpmc-qcware-deephedging deep-hedging\n",
        "  ! cp -r deep-hedging/* .\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1zT04NeNud3q"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import sys\n",
        "import warnings\n",
        "from math import factorial\n",
        "from typing import Callable, NamedTuple\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "class Agent(NamedTuple):\n",
        "    init: Callable\n",
        "    train_step: Callable\n",
        "    eval_step: Callable\n",
        "\n",
        "\n",
        "def binomial(n, k):\n",
        "    return factorial(n) // factorial(k) // factorial(n - k)\n",
        "\n",
        "\n",
        "def compute_black_scholes_deltas(\n",
        "    seq_prices,\n",
        "    *,\n",
        "    num_days=8,\n",
        "    num_trading_days=252,\n",
        "    mu=0.0,\n",
        "    sigma=0.5,\n",
        "    strike=1.0,\n",
        "):\n",
        "    seq_prices = seq_prices[..., None]\n",
        "    seq_prices = seq_prices[:, :-1]\n",
        "    strike_price = seq_prices[0, 0] * strike\n",
        "    T = jnp.arange(1, num_days + 1) / num_trading_days\n",
        "    T = jnp.repeat(jnp.flip(T[None, :]), seq_prices.shape[0], 0)\n",
        "    d1 = jnp.divide(\n",
        "        jnp.log(seq_prices[..., 0] / strike_price) + (mu + 0.5 * sigma**2) * T,\n",
        "        sigma * jnp.sqrt(T),\n",
        "    )\n",
        "    seq_deltas = jax.scipy.stats.norm.cdf(d1, 0.0, 1.0)\n",
        "    return seq_deltas\n",
        "\n",
        "\n",
        "def compute_prices(\n",
        "    seq_jumps,\n",
        "    *,\n",
        "    num_trading_days=252,\n",
        "    mu=0.0,\n",
        "    sigma=0.5,\n",
        "    initial_price=100.0,\n",
        "):\n",
        "    num_jumps = 1\n",
        "    bernoulli_prob = 0.5\n",
        "    seq_jumps = seq_jumps - bernoulli_prob  # mean 0\n",
        "    seq_jumps /= np.sqrt(bernoulli_prob * (1 - bernoulli_prob))  # std 1\n",
        "    num_paths, num_days = seq_jumps.shape\n",
        "    seq_jumps = seq_jumps.reshape(num_paths, num_days * num_jumps)\n",
        "    brownian = jnp.cumsum(seq_jumps, axis=1)\n",
        "    brownian /= np.sqrt(num_jumps * num_trading_days)\n",
        "    t = jnp.arange(1, 1 + num_days) / num_trading_days\n",
        "    log_prices = (mu - sigma**2 / 2) * t + sigma * brownian\n",
        "    seq_prices = jnp.exp(log_prices)\n",
        "    seq_prices = jnp.concatenate([jnp.ones((num_paths, 1)), seq_prices], axis=1)\n",
        "    seq_prices *= initial_price\n",
        "    return seq_prices\n",
        "\n",
        "\n",
        "def compute_rewards(seq_prices, seq_deltas, *, strike=0.9, cost_eps=0.0):\n",
        "    seq_actions = [\n",
        "        seq_deltas[:, [0]],\n",
        "        seq_deltas[:, 1:] - seq_deltas[:, :-1],\n",
        "        -seq_deltas[:, [-1]],\n",
        "    ]\n",
        "    seq_actions = jnp.concatenate(seq_actions, axis=1)\n",
        "    payoff = -jnp.maximum(seq_prices[:, -1] - strike * seq_prices[:, 0], 0.0)\n",
        "    costs = -(jnp.abs(seq_actions) * cost_eps + seq_actions) * seq_prices\n",
        "    seq_rewards = costs.at[:, -1].add(payoff)\n",
        "    return seq_rewards\n",
        "\n",
        "\n",
        "def compute_bounds(\n",
        "    num_days=8,\n",
        "    num_trading_days=252,\n",
        "    mu=0.0,\n",
        "    sigma=0.5,\n",
        "    initial_price=100.0,\n",
        "    strike=0.9,\n",
        "    cost_eps=0.0,\n",
        "):\n",
        "    # TODO: add cost_eps\n",
        "    jumps_max = jnp.ones((num_days))\n",
        "    jumps_min = jnp.zeros((num_days))\n",
        "    seq_jumps = jnp.stack([jumps_min, jumps_max], axis=0)\n",
        "    prices_min, prices_max = compute_prices(\n",
        "        seq_jumps,\n",
        "        num_trading_days=num_trading_days,\n",
        "        mu=mu,\n",
        "        sigma=sigma,\n",
        "        initial_price=initial_price,\n",
        "    )\n",
        "    payoffs_min = -jnp.maximum(prices_max - strike * initial_price, 0)\n",
        "    values_max = (2 * (prices_max - strike * initial_price))[::-1][:-1]\n",
        "    values_min = (2 * (prices_min - strike * initial_price) + payoffs_min)[::-1][:-1]\n",
        "    Gt_range = jnp.stack((values_min, values_max), axis=0)\n",
        "    return Gt_range\n",
        "\n",
        "\n",
        "def compute_returns(seq_rewards):\n",
        "    seq_returns = jnp.cumsum(seq_rewards[:, ::-1], axis=1)[:, ::-1]\n",
        "    return seq_returns\n",
        "\n",
        "\n",
        "def compute_utility(seq_rewards, *, utility_lambda=1.0):\n",
        "    returns = seq_rewards.sum(axis=1)\n",
        "    utility = (\n",
        "        -1 / utility_lambda * jnp.log(jnp.mean(jnp.exp(-utility_lambda * returns)))\n",
        "    )\n",
        "    return utility\n",
        "\n",
        "\n",
        "def get_pyramid_idxs(num_qubits):\n",
        "    num_max = num_qubits\n",
        "    num_min = num_qubits - 1\n",
        "    if num_max == num_min:\n",
        "        num_min -= 1\n",
        "    end_idxs = np.concatenate(\n",
        "        [np.arange(1, num_max - 1), num_max - np.arange(1, num_min + 1)]\n",
        "    )\n",
        "    start_idxs = np.concatenate(\n",
        "        [\n",
        "            np.arange(end_idxs.shape[0] + num_min - num_max) % 2,\n",
        "            np.arange(num_max - num_min),\n",
        "        ]\n",
        "    )\n",
        "    rbs_idxs = [\n",
        "        np.arange(start_idxs[i], end_idxs[i] + 1).reshape(-1, 2)\n",
        "        for i in range(len(start_idxs))\n",
        "    ]\n",
        "    return rbs_idxs\n",
        "\n",
        "\n",
        "def get_butterfly_idxs(num_qubits):\n",
        "    def _get_butterfly_idxs(n):\n",
        "        if n == 2:\n",
        "            return np.array([[[0, 1]]])\n",
        "        else:\n",
        "            rbs_idxs = _get_butterfly_idxs(n // 2)\n",
        "            first = np.concatenate([rbs_idxs, rbs_idxs + n // 2], 1)\n",
        "            last = np.arange(n).reshape(1, 2, n // 2).transpose(0, 2, 1)\n",
        "            rbs_idxs = np.concatenate([first, last], 0)\n",
        "            return rbs_idxs\n",
        "\n",
        "    rbs_idxs = _get_butterfly_idxs(int(2 ** np.ceil(np.log2(num_qubits))))\n",
        "    rbs_idxs = [list(map(list, rbs_idx)) for rbs_idx in rbs_idxs]\n",
        "    rbs_idxs = [\n",
        "        [\n",
        "            [i, j]\n",
        "            for i, j in rbs_idx\n",
        "            if (i in range(num_qubits)) and (j in range(num_qubits))\n",
        "        ]\n",
        "        for rbs_idx in rbs_idxs\n",
        "    ]\n",
        "    return rbs_idxs[::-1]\n",
        "\n",
        "\n",
        "def get_triangle_idxs(num_qubits):\n",
        "    rbs_idxs = [[(i, i + 1)] for i in range(num_qubits - 1)]\n",
        "    rbs_idxs += rbs_idxs[::-1]\n",
        "    return rbs_idxs\n",
        "\n",
        "\n",
        "def get_iks_idxs(num_qubits):\n",
        "    rbs_idxs_down = [[(i, i + 1)] for i in range(num_qubits - 1)]\n",
        "    rbs_idxs_up = [[(i, i + 1)] for i in range(num_qubits - 1)][::-1]\n",
        "    rbs_idxs = [\n",
        "        (m + n if m != n else m) for m, n in zip(rbs_idxs_down, rbs_idxs_up)\n",
        "    ] + rbs_idxs_down[num_qubits - 1 :]\n",
        "    return rbs_idxs\n",
        "\n",
        "\n",
        "def make_ortho_fn(rbs_idxs, num_qubits):\n",
        "    rbs_idxs = [list(map(list, rbs_idx)) for rbs_idx in rbs_idxs]\n",
        "    len_idxs = np.cumsum([0] + list(map(len, rbs_idxs)))\n",
        "\n",
        "    def get_rbs_unary(theta):\n",
        "        cos_theta, sin_theta = jnp.cos(theta), jnp.sin(theta)\n",
        "        unary = jnp.array(\n",
        "            [\n",
        "                [cos_theta, sin_theta],\n",
        "                [-sin_theta, cos_theta],\n",
        "            ]\n",
        "        )\n",
        "        unary = unary.transpose(*[*range(2, unary.ndim), 0, 1])\n",
        "        return unary\n",
        "\n",
        "    def get_rbs_unary_grad(theta):\n",
        "        cos_theta, sin_theta = jnp.cos(theta), jnp.sin(theta)\n",
        "        unary = jnp.array(\n",
        "            [\n",
        "                [-sin_theta, cos_theta],\n",
        "                [-cos_theta, -sin_theta],\n",
        "            ]\n",
        "        )\n",
        "        unary = unary.transpose(*[*range(2, unary.ndim), 0, 1])\n",
        "        return unary\n",
        "\n",
        "    @jax.custom_jvp\n",
        "    def get_parallel_rbs_unary(thetas):\n",
        "        unitaries = []\n",
        "        for i, idxs in enumerate(rbs_idxs):\n",
        "            idxs = sum(idxs, [])\n",
        "            sub_thetas = thetas[len_idxs[i] : len_idxs[i + 1]]\n",
        "            rbs_blocks = get_rbs_unary(sub_thetas)\n",
        "            eye_block = jnp.eye(num_qubits - len(idxs), dtype=thetas.dtype)\n",
        "            permutation = idxs + [i for i in range(num_qubits) if i not in idxs]\n",
        "            permutation = np.argsort(permutation)\n",
        "            unary = jax.scipy.linalg.block_diag(*rbs_blocks, eye_block)\n",
        "            unary = unary[permutation][:, permutation]\n",
        "            unitaries.append(unary)\n",
        "        unitaries = jnp.stack(unitaries)\n",
        "        return unitaries\n",
        "\n",
        "    @get_parallel_rbs_unary.defjvp\n",
        "    def get_parallel_rbs_unary_jvp(primals, tangents):\n",
        "        (thetas,) = primals\n",
        "        (thetas_dot,) = tangents\n",
        "        unitaries = []\n",
        "        unitaries_dot = []\n",
        "        for i, idxs in enumerate(rbs_idxs):\n",
        "            idxs = sum(idxs, [])\n",
        "            sub_thetas = thetas[len_idxs[i] : len_idxs[i + 1]]\n",
        "            sub_thetas_dot = thetas_dot[len_idxs[i] : len_idxs[i + 1]]\n",
        "            rbs_blocks = get_rbs_unary(sub_thetas)\n",
        "            rbs_blocks_grad = get_rbs_unary_grad(sub_thetas)\n",
        "            rbs_blocks_dot = sub_thetas_dot[..., None, None] * rbs_blocks_grad\n",
        "            eye_block = jnp.eye(num_qubits - len(idxs), dtype=thetas.dtype)\n",
        "            zero_block = jnp.zeros_like(eye_block)\n",
        "            permutation = idxs + [i for i in range(num_qubits) if i not in idxs]\n",
        "            permutation = np.argsort(permutation)\n",
        "            unary = jax.scipy.linalg.block_diag(*rbs_blocks, eye_block)\n",
        "            unary_dot = jax.scipy.linalg.block_diag(*rbs_blocks_dot, zero_block)\n",
        "            unary = unary[permutation][:, permutation]\n",
        "            unary_dot = unary_dot[permutation][:, permutation]\n",
        "            unitaries.append(unary)\n",
        "            unitaries_dot.append(unary_dot)\n",
        "        primal_out = jnp.stack(unitaries)\n",
        "        tangent_out = jnp.stack(unitaries_dot)\n",
        "        return primal_out, tangent_out\n",
        "\n",
        "    def orthogonal_fn(thetas):\n",
        "        unitaries = get_parallel_rbs_unary(thetas)\n",
        "        unary = jnp.linalg.multi_dot(unitaries[::-1])\n",
        "        return unary\n",
        "\n",
        "    return orthogonal_fn\n",
        "\n",
        "\n",
        "def compute_compound(unary, order=1):\n",
        "    num_qubits = unary.shape[-1]\n",
        "    if (order == 0) or (order == num_qubits):\n",
        "        return jnp.ones((1, 1))\n",
        "    elif order == 1:\n",
        "        return unary\n",
        "    else:\n",
        "        subsets = list(itertools.combinations(range(num_qubits), order))\n",
        "        compounds = unary[subsets, ...][..., subsets].transpose(0, 2, 1, 3)\n",
        "        compound = jnp.linalg.det(compounds)\n",
        "    return compound\n",
        "\n",
        "\n",
        "def decompose_state(state):\n",
        "    num_qubits = int(np.log2(state.shape[-1]))\n",
        "    batch_dims = state.shape[:-1]\n",
        "    state = state.reshape(-1, 2**num_qubits)\n",
        "    idxs = list(itertools.product(*[[0, 1]] * num_qubits))\n",
        "    subspace_idxs = [\n",
        "        [\n",
        "            (np.array(idx) * 2 ** np.arange(num_qubits)[::-1]).sum()\n",
        "            for idx in idxs\n",
        "            if sum(idx) == weight\n",
        "        ]\n",
        "        for weight in range(num_qubits + 1)\n",
        "    ]\n",
        "    subspace_states = [\n",
        "        state[..., subspace_idxs[weight]] for weight in range(num_qubits + 1)\n",
        "    ]\n",
        "    alphas = [\n",
        "        jnp.linalg.norm(subspace_state, axis=-1) for subspace_state in subspace_states\n",
        "    ]\n",
        "    betas = [\n",
        "        subspace_state / (alpha[..., None] + 1e-6)\n",
        "        for alpha, subspace_state in zip(alphas, subspace_states)\n",
        "    ]\n",
        "    alphas = [alpha.reshape(*batch_dims, -1) for alpha in alphas]\n",
        "    betas = [beta.reshape(*batch_dims, -1) for beta in betas]\n",
        "    alphas = jnp.stack(alphas, -1)[..., 0, :]\n",
        "    return alphas, betas\n",
        "\n",
        "def get_square_idxs(num_qubits, num_layers=None):\n",
        "    if num_layers is None:\n",
        "        num_layers = 1+int(np.log2(num_qubits))\n",
        "    rbs_idxs = [[(i,i+1) for i in range(0,num_qubits-1,2)]]\n",
        "    rbs_idxs += [[(i,i+1) for i in range(1,num_qubits-1,2)]]\n",
        "    return rbs_idxs * num_layers\n",
        "\n",
        "#get_square_idxs = get_pyramid_idxs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zQXeX5Zi8Mw7"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(formatter={'float': \"{0:0.3f}\".format})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "din5MEYJDAAz"
      },
      "source": [
        "### Hardware exp circuit construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GVJS12FSE2MQ"
      },
      "outputs": [],
      "source": [
        "# Global counter\n",
        "\n",
        "global_number_of_circuits_executed = 0\n",
        "\n",
        "# Global object keeping track of result\n",
        "# Used for pickling\n",
        "# Populated initially in DeepHedgingBenchmark().__test_model\n",
        "# and with run results in run_circuit\n",
        "# keeping track of batch_idx in scan (under \"Models\")\n",
        "\n",
        "global_hardware_run_results_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uKZMcKfmDF6b"
      },
      "outputs": [],
      "source": [
        "import qiskit\n",
        "\n",
        "import quasar\n",
        "from qcware_transpile.translations.quasar.to_qiskit import translate\n",
        "from qiskit.compiler import assemble\n",
        "import collections\n",
        "\n",
        "from qio import loader\n",
        "\n",
        "import numpy as np\n",
        "from qnn import _get_butterfly_idxs, _get_pyramid_idxs, _make_orthogonal_fn\n",
        "# fix for older versions of Qiskit\n",
        "if qiskit.__version__ <= '0.37.1':\n",
        "    import qiskit.providers.aer.noise as noise\n",
        "else:\n",
        "    import qiskit_aer.noise as noise\n",
        "import json\n",
        "import pickle\n",
        "import time\n",
        "import copy\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import itertools\n",
        "from utils import save_params, load_params\n",
        "import datetime\n",
        "def prepare_circuit(rbs_idxs, time_step, num_qubits, seq_jumps, thetas):\n",
        "    def _get_layer_circuit(params):\n",
        "      _params = np.array(params).astype('float')\n",
        "      circuit_layer = quasar.Circuit()\n",
        "      idx_angle = 0\n",
        "      for gates_per_timestep in rbs_idxs:\n",
        "        for gate in gates_per_timestep:\n",
        "          circuit_layer.add_gate(quasar.Gate.RBS(theta=-_params[idx_angle]), tuple(gate))\n",
        "          idx_angle+=1\n",
        "      return circuit_layer\n",
        "\n",
        "    first_gates = [quasar.Circuit().H(0)]*(num_qubits-2)  + [quasar.Circuit().I(0)] +[quasar.Circuit().X(0)]\n",
        "    circuit = quasar.Circuit.join_in_qubits(first_gates)\n",
        "    if time_step ==0:\n",
        "      layer_circuit = _get_layer_circuit(thetas[0])\n",
        "      circuit = quasar.Circuit.join_in_time([circuit, layer_circuit])\n",
        "    else:\n",
        "      thetas = thetas.reshape(2,time_step, -1)\n",
        "      for idx,jump in enumerate(seq_jumps):\n",
        "        layer_circuit = _get_layer_circuit(thetas[int(jump)][idx])\n",
        "        circuit = quasar.Circuit.join_in_time([circuit, layer_circuit])\n",
        "    # Translate from qcware-quasar to qiskit\n",
        "    qiskit_circuit = translate(circuit)\n",
        "    # qiskit_circuit.save_statevector()\n",
        "    qiskit_circuit = qiskit.transpile(qiskit_circuit, optimization_level=0)\n",
        "    c = qiskit.ClassicalRegister(num_qubits)\n",
        "    qiskit_circuit.add_register(c)\n",
        "    qiskit_circuit.barrier()\n",
        "    qiskit_circuit.measure(qubit=range(num_qubits),cbit=c)\n",
        "    return qiskit_circuit\n",
        "\n",
        "\n",
        "\n",
        "def counter_to_dict(c):\n",
        "    \"\"\"Converts counter returned by pytket get_counts function\n",
        "    to dictionary returned by qiskit\n",
        "    canonical use:\n",
        "    >>> result = backend.get_result(handle)\n",
        "    >>> counts = result.get_counts(basis=BasisOrder.dlo)\n",
        "    >>> counts_qiskit = counter_to_dict(counts)\n",
        "    \"\"\"\n",
        "    d = {}\n",
        "    for k, v in c.items():\n",
        "        d[''.join(str(x) for x in k)] = int(v)\n",
        "    return d\n",
        "\n",
        "def run_circuit(circs,num_qubits, backend_name = 'qiskit_noisy'):\n",
        "    \"\"\"\n",
        "    backend name accepted \n",
        "    \"\"\"\n",
        "    global global_number_of_circuits_executed\n",
        "    global global_hardware_run_results_dict\n",
        "    results = np.zeros((len(circs), 2**num_qubits))\n",
        "    \n",
        "    global_number_of_circuits_executed += len(circs)\n",
        "    num_measurements = 1000\n",
        "    \n",
        "    if \"qiskit\" in backend_name:\n",
        "        backend = qiskit.Aer.get_backend('qasm_simulator')\n",
        "        if backend_name == 'qiskit_noiseless':\n",
        "            measurement = qiskit.execute(circs, backend, shots=num_measurements)\n",
        "        elif backend_name == 'qiskit_noisy': \n",
        "            # Error probabilities\n",
        "            prob_1 = 0.001  # 1-qubit gate\n",
        "            prob_2 = 0.01   # 2-qubit gate\n",
        "            # Dylan's tunes error probabilities\n",
        "            # prob_1 = 0  # 1-qubit gate\n",
        "            # prob_2 = 3.5e-3   # 2-qubit gate\n",
        "\n",
        "            # Depolarizing quantum errors\n",
        "            error_1 = noise.depolarizing_error(prob_1, 1)\n",
        "            error_2 = noise.depolarizing_error(prob_2, 2)\n",
        "\n",
        "            # Add errors to noise model\n",
        "            noise_model = noise.NoiseModel()\n",
        "            noise_model.add_all_qubit_quantum_error(error_1, ['h', 'x', 'ry'])\n",
        "            noise_model.add_all_qubit_quantum_error(error_2, ['cz'])\n",
        "\n",
        "            # Get basis gates from noise model\n",
        "            basis_gates = noise_model.basis_gates\n",
        "            measurement = qiskit.execute(circs, backend,basis_gates=basis_gates, noise_mode=noise_model, shots=num_measurements)\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected backend name {backend_name}\")\n",
        "        all_counts = measurement.result().get_counts()\n",
        "    elif \"quantinuum\" in backend_name:\n",
        "        # From docs: \"Batches cannot exceed the maximum limit of 500 H-System Quantum Credits (HQCs) total\"\n",
        "        # Therefore batching is more or less useless on quantinuum\n",
        "        from pytket.extensions.qiskit import qiskit_to_tk\n",
        "        from pytket.circuit import BasisOrder\n",
        "        from pytket.extensions.quantinuum import QuantinuumBackend\n",
        "    \n",
        "        outpath_stem = \"_\".join([\n",
        "            \"1103_30_points\",\n",
        "            global_hardware_run_results_dict['model_type'],\n",
        "            backend_name,\n",
        "            global_hardware_run_results_dict['layer_type'],\n",
        "            str(global_hardware_run_results_dict['epsilon']),\n",
        "            str(global_hardware_run_results_dict['batch_idx']),\n",
        "        ])\n",
        "        \n",
        "        outpath_result_final = f\"data/{outpath_stem}.json\"\n",
        "        outpath_handles = f\"data/handles_{outpath_stem}.pickle\"\n",
        "        \n",
        "        if Path(outpath_result_final).exists():\n",
        "            # if precomputed results already present on disk, simply load\n",
        "            print(f\"Using precomputed counts from {outpath_result_final}\")\n",
        "            all_counts = json.load(open(outpath_result_final, \"r\"))['all_counts']\n",
        "        else:\n",
        "            if backend_name == \"quantinuum_H1-2E\":\n",
        "                backend = QuantinuumBackend(device_name=\"H1-2E\")\n",
        "            elif backend_name == \"quantinuum_H1-2\":\n",
        "                backend = QuantinuumBackend(device_name=\"H1-2\")\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown Quantinuum backend: {backend_name}\")\n",
        "            if Path(outpath_handles).exists():\n",
        "                # if circuits already submitted, simply load from disk\n",
        "                print(f\"Using pickled handles from {outpath_handles}\")\n",
        "                handles = pickle.load(open(outpath_handles, \"rb\"))\n",
        "            else:\n",
        "                # otherwise, submit circuits and pickle handles\n",
        "                circs_tk = [qiskit_to_tk(circ) for circ in circs]\n",
        "                for idx, circ in enumerate(circs_tk):\n",
        "                    circ.name = f'{outpath_stem}_{idx+1}_of_{len(circs)}'\n",
        "                compiled_circuits = backend.get_compiled_circuits(circs_tk, optimisation_level=2)\n",
        "                handles = backend.process_circuits(compiled_circuits, n_shots=num_measurements)\n",
        "                pickle.dump(handles, open(outpath_handles, \"wb\"))\n",
        "                print(f\"Dumped handles to {outpath_handles}\")\n",
        "            # retrieve results from handles\n",
        "            result_list = []\n",
        "            \n",
        "            with tqdm(total=len(handles), desc='#jobs finished') as pbar:\n",
        "                for handle in handles:\n",
        "                    while True:\n",
        "                        status = backend.circuit_status(handle).status\n",
        "                        if status.name == 'COMPLETED':\n",
        "                            result = backend.get_result(handle)\n",
        "                            result_list.append(copy.deepcopy(result))\n",
        "                            pbar.update(1)\n",
        "                            break\n",
        "                        else:\n",
        "                            assert status.name in ['QUEUED', 'RUNNING'] \n",
        "                        time.sleep(1)\n",
        "            global_hardware_run_results_dict['result_list'] = [x.to_dict() for x in result_list]\n",
        "            # convert from tket counts format to qiskit\n",
        "            all_counts = [\n",
        "                counter_to_dict(\n",
        "                    result.get_counts(basis=BasisOrder.dlo)\n",
        "                ) for result in result_list\n",
        "            ]\n",
        "            global_hardware_run_results_dict['all_counts'] = all_counts\n",
        "            # dump result on disk\n",
        "            json.dump(global_hardware_run_results_dict, open(outpath_result_final, \"w\"))\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected backend name {backend_name}\")\n",
        "    global_hardware_run_results_dict['batch_idx'] += 1 \n",
        "\n",
        "    # Post processing\n",
        "    for j in range(len(circs)):\n",
        "        if len(circs) == 1:\n",
        "            measurementRes = all_counts\n",
        "        else:\n",
        "            measurementRes = all_counts[j]\n",
        "        num_qubits = len(list(measurementRes)[0]) \n",
        "        filtered_counts = {f\"{i:0{num_qubits}b}\":0 for i in range(2**num_qubits)}\n",
        "        num_postselected = 0\n",
        "        for bitstring, count in measurementRes.items():\n",
        "            ham_weight = sum([int(x) for x in bitstring])\n",
        "            if ham_weight == 0 or ham_weight == num_qubits:\n",
        "                continue\n",
        "            filtered_counts[bitstring] = count\n",
        "            num_postselected+= count\n",
        "        results[j] = np.sqrt([filtered_counts[k]/num_postselected for k in sorted(filtered_counts)])\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qwgrpuZGMr0G"
      },
      "outputs": [],
      "source": [
        "def make_ortho_fn(rbs_idxs, num_qubits):\n",
        "    rbs_idxs = [list(map(list, rbs_idx)) for rbs_idx in rbs_idxs]\n",
        "    len_idxs = np.cumsum([0] + list(map(len, rbs_idxs)))\n",
        "    def get_rbs_unary(theta):\n",
        "        cos_theta, sin_theta = jnp.cos(theta), jnp.sin(theta)\n",
        "        unary = jnp.array(\n",
        "            [\n",
        "                [cos_theta, sin_theta],\n",
        "                [-sin_theta, cos_theta],\n",
        "            ]\n",
        "        )\n",
        "        unary = unary.transpose(*[*range(2, unary.ndim), 0, 1])\n",
        "        return unary\n",
        "    def get_parallel_rbs_unary(thetas):\n",
        "        unitaries = []\n",
        "        for i, idxs in enumerate(rbs_idxs):\n",
        "            idxs = sum(idxs, [])\n",
        "            sub_thetas = thetas[len_idxs[i] : len_idxs[i + 1]]\n",
        "            rbs_blocks = get_rbs_unary(sub_thetas)\n",
        "            eye_block = jnp.eye(num_qubits - len(idxs), dtype=thetas.dtype)\n",
        "            permutation = idxs + [i for i in range(num_qubits) if i not in idxs]\n",
        "            permutation = np.argsort(permutation)\n",
        "            unary = jax.scipy.linalg.block_diag(*rbs_blocks, eye_block)\n",
        "            unary = unary[permutation][:, permutation]\n",
        "            unitaries.append(unary)\n",
        "        unitaries = jnp.stack(unitaries)\n",
        "        return unitaries\n",
        "\n",
        "    def orthogonal_fn(thetas):\n",
        "        unitaries = get_parallel_rbs_unary(thetas)\n",
        "        if len(unitaries) > 1:\n",
        "            unary = jnp.linalg.multi_dot(unitaries[::-1])\n",
        "        else:\n",
        "            unary = unitaries[0]\n",
        "        return unary[::-1][:,::-1]\n",
        "\n",
        "    return orthogonal_fn\n",
        "\n",
        "\n",
        "def compute_compound(unary, order=1):\n",
        "    num_qubits = unary.shape[-1]\n",
        "    if (order == 0) or (order == num_qubits):\n",
        "        return jnp.ones((1, 1))\n",
        "    elif order == 1:\n",
        "        return unary\n",
        "    else:\n",
        "        subsets = list(itertools.combinations(range(num_qubits), order))\n",
        "        compounds = unary[subsets, ...][..., subsets].transpose(0, 2, 1, 3)\n",
        "        compound = jnp.linalg.det(compounds)\n",
        "    return compound\n",
        "\n",
        "def decompose_state(state):\n",
        "    num_qubits = int(np.log2(state.shape[-1]))\n",
        "    batch_dims = state.shape[:-1]\n",
        "    state = state.reshape(-1, 2**num_qubits)\n",
        "    idxs = list(itertools.product(*[[0, 1]] * num_qubits))\n",
        "    subspace_idxs = [\n",
        "        [\n",
        "            int((2**np.array(bla)).sum())\n",
        "            for bla in itertools.combinations(range(num_qubits), weight)\n",
        "        ]\n",
        "        for weight in range(num_qubits + 1)\n",
        "    ]\n",
        "    subspace_states = [\n",
        "        state[..., subspace_idxs[weight]] for weight in range(num_qubits + 1)\n",
        "    ]\n",
        "    alphas = [\n",
        "        jnp.linalg.norm(subspace_state, axis=-1) for subspace_state in subspace_states\n",
        "    ]\n",
        "    betas = [\n",
        "        subspace_state / (alpha[..., None] + 1e-6)\n",
        "        for alpha, subspace_state in zip(alphas, subspace_states)\n",
        "    ]\n",
        "    alphas = [alpha.reshape(*batch_dims, -1) for alpha in alphas]\n",
        "    betas = [beta.reshape(*batch_dims, -1) for beta in betas]\n",
        "    alphas = jnp.stack(alphas, -1)[..., 0, :]\n",
        "    return alphas, betas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZnhSuoSQC7re"
      },
      "outputs": [],
      "source": [
        "def make_agent(\n",
        "    num_days=14,\n",
        "    num_jumps=1,\n",
        "    num_trading_days=252,\n",
        "    mu=0.0,\n",
        "    sigma=0.2,\n",
        "    initial_price=100.0,\n",
        "    strike=1.0,\n",
        "    cost_eps=0.0,\n",
        "    train_num_paths=32,\n",
        "    eval_num_paths=32,\n",
        "    utility_lambda=0.1,\n",
        "    model=\"vanilla\",\n",
        "):\n",
        "    bernoulli_prob = 0.5\n",
        "\n",
        "    def net_fn_apply(params, key, batch_jumps):\n",
        "        for time_step in range(num_days):\n",
        "            seq_jumps = batch_jumps[:,:time_step]\n",
        "            num_qubits = num_days - time_step + 2\n",
        "            rbs_idxs = get_square_idxs(num_qubits)\n",
        "            num_params = sum(map(len, rbs_idxs))\n",
        "            if time_step == 0:\n",
        "                thetas_shape = (1, num_params)\n",
        "            else:\n",
        "                thetas_shape = (2 * time_step, num_params)\n",
        "            thetas = params[0][\"actor_thetas_{}\".format(time_step)]\n",
        "            state = jnp.ones((2 ** (num_days - time_step),)) / np.sqrt(\n",
        "                2 ** (num_days - time_step)\n",
        "            )\n",
        "            state = jnp.kron(state, jnp.array([0.0, 1.0, 0.0, 0.0]))\n",
        "            alphas, betas = decompose_state(state)\n",
        "            thetas = thetas.reshape(-1, num_params)\n",
        "            unaries = jax.vmap(make_ortho_fn(rbs_idxs, num_qubits))(thetas)\n",
        "            if time_step == 0:\n",
        "                seq_unaries = jnp.repeat(unaries, seq_jumps.shape[0], axis=0)\n",
        "            else:\n",
        "                unaries = unaries.reshape(2, time_step, num_qubits, num_qubits)\n",
        "                seq_unaries = jnp.einsum(\"bt,tij->btij\", seq_jumps, unaries[1])\n",
        "                seq_unaries += jnp.einsum(\"bt,tij->btij\", 1 - seq_jumps, unaries[0])\n",
        "                if time_step > 1:\n",
        "                    seq_unaries = jax.vmap(jnp.linalg.multi_dot)(seq_unaries[:,::-1,:,:])\n",
        "                else:\n",
        "                    seq_unaries = seq_unaries[:, 0]\n",
        "            compounds = [\n",
        "                jax.vmap(compute_compound, in_axes=(0, None))(seq_unaries, order)\n",
        "                for order in range(num_qubits + 1)\n",
        "            ]\n",
        "            deltas_betas = [compound @ beta for compound, beta in zip(compounds, betas)]\n",
        "            deltas_ranges = [(0, 1) for _ in range(len(deltas_betas))]\n",
        "            deltas_dist = [\n",
        "                beta**2 @ jnp.linspace(*delta_range, beta.shape[-1])\n",
        "                for beta, delta_range in zip(deltas_betas, deltas_ranges)\n",
        "            ]\n",
        "            deltas_exp = [alpha**2 * dist for alpha, dist in zip(alphas, deltas_dist)]\n",
        "            deltas_exp = jnp.array(deltas_exp).sum(0)\n",
        "            if time_step == 0:\n",
        "                seq_deltas_exp = [deltas_exp]\n",
        "            else:\n",
        "                seq_deltas_exp.append(deltas_exp)\n",
        "        return (\n",
        "            seq_jumps,\n",
        "            seq_deltas_exp,\n",
        "        )\n",
        "\n",
        "\n",
        "    def hardware_net_fn_apply(params, key, batch_jumps):\n",
        "        for time_step in range(num_days):\n",
        "            seq_jumps = batch_jumps[:,:time_step]\n",
        "            num_qubits = num_days - time_step + 2\n",
        "            rbs_idxs = get_square_idxs(num_qubits)\n",
        "            num_params = sum(map(len, rbs_idxs))\n",
        "            if time_step == 0:\n",
        "                thetas_shape = (1, num_params)\n",
        "            else:\n",
        "                thetas_shape = (2 * time_step, num_params)\n",
        "            thetas = params[0][\"actor_thetas_{}\".format(time_step)]\n",
        "            state = jnp.ones((2 ** (num_days - time_step),)) / np.sqrt(\n",
        "                2 ** (num_days - time_step)\n",
        "            )\n",
        "            state = jnp.kron(state, jnp.array([0.0, 1.0, 0.0, 0.0]))\n",
        "            alphas, betas = decompose_state(state)\n",
        "            # Begin Quantum-HW\n",
        "            circs = []\n",
        "            for jumps in seq_jumps:\n",
        "                circs.append(prepare_circuit(rbs_idxs, time_step, num_qubits, jumps, thetas))\n",
        "            results = jnp.array(run_circuit(circs,num_qubits))\n",
        "            deltas_alphas, deltas_betas = decompose_state(results)\n",
        "            # End Quantum-HW\n",
        "            deltas_ranges = [(0, 1) for _ in range(len(deltas_betas))]\n",
        "            deltas_dist = [\n",
        "                beta**2 @ jnp.linspace(*delta_range, beta.shape[-1])\n",
        "                for beta, delta_range in zip(deltas_betas, deltas_ranges)\n",
        "            ]\n",
        "            deltas_exp = [alpha**2 * dist for alpha, dist in zip(alphas, deltas_dist)]\n",
        "            deltas_exp = jnp.array(deltas_exp).sum(0)\n",
        "            if time_step == 0:\n",
        "                seq_deltas_exp = [deltas_exp]\n",
        "            else:\n",
        "                seq_deltas_exp.append(deltas_exp)\n",
        "        \n",
        "        return (\n",
        "            seq_jumps,\n",
        "            seq_deltas_exp,\n",
        "        )\n",
        "    \n",
        "    def eval_step(params, batch_jumps):\n",
        "        key = jax.random.PRNGKey(123)\n",
        "        keys = jax.random.split(key, 2)\n",
        "        keys = jax.random.split(key, 4)\n",
        "        net_params = params\n",
        "        \n",
        "        seq_jumps, seq_deltas_exp = net_fn_apply(net_params, keys[0], batch_jumps)\n",
        "        seq_jumps, seq_deltas_exp_hw = hardware_net_fn_apply(net_params, keys[0], batch_jumps)\n",
        "\n",
        "        day_jumps = jax.random.bernoulli(\n",
        "            keys[1], bernoulli_prob, (seq_jumps.shape[0], 1)\n",
        "        )\n",
        "        seq_jumps = jnp.concatenate([seq_jumps, day_jumps], axis=-1)\n",
        "        seq_prices = compute_prices(\n",
        "            seq_jumps,\n",
        "            num_trading_days=num_trading_days,\n",
        "            mu=mu,\n",
        "            sigma=sigma,\n",
        "            initial_price=initial_price,\n",
        "        )\n",
        "        seq_deltas_hw = jnp.stack(seq_deltas_exp_hw,axis=1)\n",
        "        seq_deltas = jnp.stack(seq_deltas_exp, axis=1)\n",
        "        seq_rewards = compute_rewards(\n",
        "            seq_prices, seq_deltas, strike=strike, cost_eps=cost_eps\n",
        "        )\n",
        "        seq_bs_deltas = compute_black_scholes_deltas(\n",
        "            seq_prices,\n",
        "            num_days=num_days,\n",
        "            num_trading_days=num_trading_days,\n",
        "            mu=mu,\n",
        "            sigma=sigma,\n",
        "            strike=strike,\n",
        "        )\n",
        "        seq_rewards = compute_rewards(\n",
        "            seq_prices, seq_deltas, strike=strike, cost_eps=cost_eps\n",
        "        )\n",
        "        seq_hw_rewards = compute_rewards(\n",
        "            seq_prices, seq_deltas_hw, strike=strike, cost_eps=cost_eps\n",
        "        ) \n",
        "        seq_bs_rewards = compute_rewards(\n",
        "            seq_prices, seq_bs_deltas, strike=strike, cost_eps=cost_eps\n",
        "        )\n",
        "        returns = seq_rewards.sum(axis=1)\n",
        "        hw_returns = seq_hw_rewards.sum(axis=1)\n",
        "        bs_returns = seq_bs_rewards.sum(axis=1)\n",
        "        metrics = {\n",
        "            \"returns\": jnp.array(returns),\n",
        "            \"hw_returns\": jnp.array(hw_returns),\n",
        "            \"seq_deltas\": jnp.array(seq_deltas_exp),\n",
        "            \"seq_deltas_hw\": jnp.array(seq_deltas_exp_hw),\n",
        "        }\n",
        "        utility_lambda = 1E-1\n",
        "        utility = compute_utility(seq_rewards, utility_lambda=utility_lambda)\n",
        "        hw_utility = compute_utility(seq_hw_rewards, utility_lambda=utility_lambda)\n",
        "        bs_utility = compute_utility(seq_bs_rewards, utility_lambda=utility_lambda)\n",
        "        metrics[f'U_{utility_lambda}'] = utility\n",
        "        metrics[f'U_hw_{utility_lambda}'] = hw_utility\n",
        "        metrics[f'U_bs_{utility_lambda}'] = bs_utility\n",
        "        return metrics\n",
        "\n",
        "    return Agent(init=None, train_step=None, eval_step=eval_step)\n",
        "\n",
        "\n",
        "def experiment(hparams, seed, params_save_loc, jumps_save_loc):\n",
        "    global global_number_of_circuits_executed\n",
        "    global global_hardware_run_results_dict\n",
        "    global_number_of_circuits_executed = 0\n",
        "    global_hardware_run_results_dict = {\n",
        "        'model_type' : hparams[\"model\"],\n",
        "        'measurementRes' : None,\n",
        "        'epsilon' : hparams[\"cost_eps\"],\n",
        "        'backend_name' : None,\n",
        "        'num_trading_days' : hparams[\"num_trading_days\"],\n",
        "        'batch_idx' : 0,\n",
        "    }\n",
        "    agent = make_agent(**hparams)\n",
        "    params = load_params(params_save_loc)\n",
        "    batch_jumps = load_params(jumps_save_loc)[-4:] # Only consider first 4 paths for h/w experiments\n",
        "    eval_metrics = agent.eval_step(params, batch_jumps)\n",
        "    eval_metrics = jax.device_get(eval_metrics)\n",
        "    print(f'Total number of circuits executed = {global_number_of_circuits_executed}')\n",
        "\n",
        "    utility_lambda = 1E-1\n",
        "    utility_agent = eval_metrics[f'U_{utility_lambda}']\n",
        "    utility_hw_agent = eval_metrics[f'U_hw_{utility_lambda}']\n",
        "    print(\"---\"*10+'Utility'+\"---\"*10)\n",
        "    print(\"Agent {:.2f}, Hardware Agent {:,.2f}\".format( utility_agent, utility_hw_agent ))\n",
        "    print(\"---\"*10+'Deltas'+\"---\"*10)\n",
        "    print(f'Agent :\\n {eval_metrics[\"seq_deltas\"]}')\n",
        "    print(f'Hardware Agent :\\n {eval_metrics[\"seq_deltas_hw\"]}')\n",
        "    print(\"---\"*10+'Terminal PnL'+\"---\"*10)\n",
        "    print(f'Agent :\\n {eval_metrics[\"returns\"]}')\n",
        "    print(f'Hardware Agent :\\n {eval_metrics[\"hw_returns\"]}')\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSFA-LY3C_eW",
        "outputId": "5dee0647-ac98-4a29-afb6-f1cb4c7d2723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of circuits executed = 40\n",
            "------------------------------Utility------------------------------\n",
            "Agent -1.87, Hardware Agent -1.87\n",
            "------------------------------Deltas------------------------------\n",
            "Agent :\n",
            " [[0.277 0.277 0.277 0.277]\n",
            " [0.292 0.251 0.292 0.251]\n",
            " [0.231 0.219 0.231 0.202]\n",
            " [0.143 0.151 0.153 0.150]\n",
            " [0.071 0.064 0.075 0.062]\n",
            " [0.064 0.075 0.057 0.080]\n",
            " [0.151 0.157 0.157 0.175]\n",
            " [0.135 0.126 0.171 0.146]\n",
            " [0.071 0.062 0.101 0.084]\n",
            " [0.603 0.294 0.850 0.077]]\n",
            "Hardware Agent :\n",
            " [[0.278 0.282 0.280 0.278]\n",
            " [0.296 0.251 0.292 0.260]\n",
            " [0.227 0.217 0.223 0.208]\n",
            " [0.144 0.159 0.157 0.156]\n",
            " [0.073 0.067 0.076 0.055]\n",
            " [0.066 0.079 0.058 0.076]\n",
            " [0.159 0.157 0.160 0.174]\n",
            " [0.137 0.136 0.173 0.148]\n",
            " [0.070 0.060 0.100 0.084]\n",
            " [0.601 0.291 0.854 0.071]]\n",
            "------------------------------Terminal PnL------------------------------\n",
            "Agent :\n",
            " [-2.923 -2.932 2.004 -2.788]\n",
            "Hardware Agent :\n",
            " [-2.919 -2.927 2.043 -2.851]\n"
          ]
        }
      ],
      "source": [
        "num_days = 10\n",
        "env_kwargs = dict(\n",
        "    num_days=num_days,\n",
        "    num_jumps=1,\n",
        "    num_trading_days=30,\n",
        "    mu=0.0,\n",
        "    sigma=0.2,\n",
        "    initial_price=100.0,\n",
        "    strike=1.,\n",
        "    cost_eps=0.002,\n",
        "    utility_lambda=0.1,\n",
        ")\n",
        "\n",
        "hparams = dict(env_kwargs)\n",
        "hparams[\"model\"] = \"distributional\"\n",
        "experiment(hparams, seed=19983, params_save_loc='params/10-0.002-1.0_distributional_20221114-165133.pkl', jumps_save_loc= 'data/seq_jumps_10_days')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.9 ('jpmc-check': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "aeebd5b777ec7291cb611112c8ba5d8721451214eea05e9ccddb5913c09817ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}