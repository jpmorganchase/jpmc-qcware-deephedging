{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPrjBpBQIf1C"
      },
      "source": [
        "# Installs and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TSbLf0lxIlhR"
      },
      "outputs": [],
      "source": [
        "import optax\n",
        "from jax import numpy as jnp\n",
        "import jax\n",
        "from functools import partial\n",
        "from tqdm import tqdm, trange\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FgXP8UqIp_k"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5k4mJjbK9JR"
      },
      "source": [
        "We begin by import the modules from the repository. Then to generate train and test data sets for geometric Brownian motion simulations we use the gen_paths() function in `data.py`. \n",
        "\n",
        "Note: The data generation has been commented here because we pickled a particular train and test split. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WNDSG3KziiBV"
      },
      "outputs": [],
      "source": [
        "from source.models import simple_network, recurrent_network, lstm_network, attention_network\n",
        "from source.qnn import linear, ortho_linear, ortho_linear_noisy\n",
        "from source.train import build_train_fn, gen_paths, entropy_loss\n",
        "from source.utils import train_test_split, get_batches, HyperParams\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "seed = 100\n",
        "key = jax.random.PRNGKey(seed)\n",
        "hps = HyperParams(n_steps=30, discrete_path = False)\n",
        "\n",
        "# Data\n",
        "# S = gen_paths(hps)\n",
        "# [S_train, S_test] = train_test_split([S], test_size=0.2)\n",
        "# _, train_batches = get_batches(jnp.array(S_train[0]), batch_size=hps.batch_size)\n",
        "# _, test_batches = get_batches(jnp.array(S_test[0]), batch_size=hps.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NATMtIEggZtz"
      },
      "outputs": [],
      "source": [
        "# saving train and test batches\n",
        "# pickle.dump(train_batches, open('/content/drive/MyDrive/JPMC/train_batches_30_days', 'wb'))\n",
        "# pickle.dump(test_batches, open('/content/drive/MyDrive/JPMC/test_batches_30_days', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUvxpg6RgYAE"
      },
      "source": [
        "# DeepHedgingBenchmark()\n",
        "\n",
        "This is a class to benchmark the performance of different models and layers for deep hedging. It has two methods: __train_model() and __test_model() which are used to train and test the deep learning models. It also has a train() method to train the model on given input data.\n",
        "\n",
        "## Parameters\n",
        "- `key`: A random key value used for jax random splitting.\n",
        "- `eps`: A list of float values representing the hedge intervals to be used in training.\n",
        "- `layers`: A list of string values representing the layer types to be used in \n",
        "training. It should only contain values from `['linear', 'ortho_pyramid', 'ortho_butterfly', 'noisy_ortho_pyramid', 'noisy_ortho_butterfly']`.\n",
        "- `models`: A list of string values representing the model types to be used in training. It should only contain values from `['simple', 'recurrent', 'lstm', 'attention']`.\n",
        "\n",
        "## Methods\n",
        "- `__train_model(hps, train_batches)`: A private method that trains the model. It takes in hyperparameters hps and train batches train_batches. The hyperparameters include layer_type, model_type, n_steps, epsilon, and num_epochs. It returns the training losses, trained model parameters and time taken for training.\n",
        "- `__test_model(hps,params, test_batches)`: A private method that tests the model. It takes in hyperparameters hps, trained model parameters params and test batches test_batches. The hyperparameters include layer_type, model_type, n_steps, epsilon, and num_epochs. It returns the testing loss.\n",
        "- `train(inputs, save_loc)`: A method to train the model. It takes in inputs and save_loc. Inputs are training data, and save_loc is the path where the trained model is to be saved. If the path exists, it loads the model from the location and continues training. It trains the model using the __train_model() method and for each combination of layers, eps and models. It saves the training information in train_info as a dictionary.\n",
        "- `test(test_batches,save_loc)`:  A method to test the model. It takes in test_batches and save_loc. test_batches are testing data, and save_loc is the path where the trained model is to be saved. If the path exists, it loads the model from the location and continues testing. It trains the model using the __test_model() method and for each combination of layers, eps and models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1Gr5y7i3jYpo"
      },
      "outputs": [],
      "source": [
        "_LAYERS  = [\n",
        "    'linear',\n",
        "    'ortho_pyramid',\n",
        "    'ortho_butterfly',\n",
        "    'noisy_ortho_pyramid',\n",
        "    'noisy_ortho_butterfly'\n",
        "]\n",
        "\n",
        "_MODELS = [\n",
        "    'simple',\n",
        "    'recurrent',\n",
        "    'lstm',\n",
        "    'attention'\n",
        "]\n",
        "class DeepHedgingBenchmark():\n",
        "  \"\"\"\n",
        "    Initializes a DeepHedgingBenchmark object with the given key, epsilon values,\n",
        "    layer types, and model types.\n",
        "\n",
        "    Args:\n",
        "    - key: a random key for reproducibility\n",
        "    - eps: a list of epsilon values for training\n",
        "    - layers: a list of layer types to use for training\n",
        "    - models: a list of model types to use for training\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "  def __init__(self, key, eps,  layers, models):\n",
        "    assert all(layer in  _LAYERS for layer in layers), f'Layers don\\'t have valid layer types.'\n",
        "    assert all(model in  _MODELS for model in models), f'Models don\\'t have valid model types.'\n",
        "    self.__key = key\n",
        "    self.__models = models\n",
        "    self.__layers = layers\n",
        "    self.__eps = eps\n",
        "    self.train_info = {layer:{str(eps):{} for eps in self.__eps} for layer in self.__layers}\n",
        "  def __train_model(self, hps, train_batches):\n",
        "    \"\"\"\n",
        "    Trains a model with the given hyperparameters and training batches.\n",
        "\n",
        "    Args:\n",
        "    - hps: a HyperParams object specifying the hyperparameters for the model\n",
        "    - train_batches: a generator of training batches\n",
        "\n",
        "    Returns:\n",
        "    - train_losses: a list of training losses for each epoch\n",
        "    - params: the final model parameters\n",
        "    - elapsed: the elapsed time for training the model\n",
        "    \"\"\"\n",
        "    if hps.layer_type == 'linear':\n",
        "      layer_func = linear\n",
        "    else:\n",
        "      layout = hps.layer_type.split('_')[-1]\n",
        "      if hps.layer_type.startswith('ortho'):\n",
        "        layer_func = partial(ortho_linear,layout = layout)\n",
        "      elif hps.layer_type.startswith('noisy_ortho'):\n",
        "        layer_func = partial(ortho_linear_noisy,layout = layout,noise_scale=0.01)\n",
        "\n",
        "    if hps.model_type == 'simple':\n",
        "      net = simple_network(hps=hps, layer_func=layer_func)\n",
        "    elif hps.model_type == 'recurrent':\n",
        "      net = recurrent_network(hps=hps, layer_func=layer_func)\n",
        "    elif hps.model_type == 'lstm':\n",
        "      net = lstm_network(hps=hps, layer_func=layer_func)\n",
        "    elif hps.model_type == 'attention':\n",
        "      net = attention_network(hps=hps, layer_func=layer_func)\n",
        "    \n",
        "    opt = optax.adam(1E-3)\n",
        "    key, init_key = jax.random.split(self.__key)\n",
        "    params, state, _ = net.init(init_key, (1, hps.n_steps, 1))\n",
        "    opt_state = opt.init(params)\n",
        "    loss_metric = entropy_loss\n",
        "\n",
        "    # Training\n",
        "\n",
        "    train_fn, loss_fn = build_train_fn(hps, net, opt, loss_metric)\n",
        "    num_epochs = hps.num_epochs\n",
        "    loss = 0.0\n",
        "    train_losses=[]\n",
        "    elapsed = 0    \n",
        "    with trange(1, num_epochs+1) as t:\n",
        "      for epoch in t:\n",
        "        loss_epoch = []\n",
        "        for i, inputs in enumerate(train_batches):\n",
        "          inputs = inputs[...,None]\n",
        "          key, train_key = jax.random.split(key)\n",
        "          params, state, opt_state, loss, (wealths, deltas, outputs) = train_fn(\n",
        "              params, state, opt_state, train_key, inputs)\n",
        "          loss_epoch.append(loss)\n",
        "        loss = jnp.mean(jnp.array(loss_epoch))\n",
        "        train_losses.append(loss)  \n",
        "        t.set_postfix(loss=loss,model=hps.model_type, layer=hps.layer_type, eps=hps.epsilon)\n",
        "        if epoch==num_epochs:\n",
        "          elapsed = t.format_dict[\"elapsed\"]\n",
        "    return train_losses,params, elapsed\n",
        "  def __test_model(self, hps,params, test_batches):\n",
        "\n",
        "    if hps.layer_type == 'linear':\n",
        "      layer_func = linear\n",
        "    else:\n",
        "      layout = hps.layer_type.split('_')[-1]\n",
        "      if hps.layer_type.startswith('ortho'):\n",
        "        layer_func = partial(ortho_linear,layout = layout)\n",
        "      elif hps.layer_type.startswith('noisy_ortho'):\n",
        "        layer_func = partial(ortho_linear_noisy,layout = layout,noise_scale=0.01)\n",
        "\n",
        "    if hps.model_type == 'simple':\n",
        "      net = simple_network(hps=hps, layer_func=layer_func)\n",
        "    elif hps.model_type == 'recurrent':\n",
        "      net = recurrent_network(hps=hps, layer_func=layer_func)\n",
        "    elif hps.model_type == 'lstm':\n",
        "      net = lstm_network(hps=hps, layer_func=layer_func)\n",
        "    elif hps.model_type == 'attention':\n",
        "      net = attention_network(hps=hps, layer_func=layer_func)\n",
        "    \n",
        "    opt = optax.adam(1E-3)\n",
        "    key, init_key = jax.random.split(self.__key)\n",
        "    _, state, _ = net.init(init_key, (1, hps.n_steps, 1))\n",
        "    loss_metric = entropy_loss\n",
        "\n",
        "    # Testing\n",
        "\n",
        "    _, loss_fn = build_train_fn(hps, net, opt, loss_metric)\n",
        "    loss = 0.0    \n",
        "    loss_epoch = []\n",
        "    for i, inputs in enumerate(test_batches):\n",
        "      inputs = inputs[...,None]\n",
        "      key, test_key = jax.random.split(key)\n",
        "      loss,_ = jax.jit(loss_fn)(params, state, test_key, inputs)\n",
        "      loss_epoch.append(loss)\n",
        "    loss = jnp.mean(jnp.array(loss_epoch))\n",
        "    print(f'Model = {hps.model_type} | Layer = {hps.layer_type} | EPS = {hps.epsilon}| Loss = {loss}')\n",
        "    return loss\n",
        "\n",
        "  def train(self, inputs, save_loc):\n",
        "    if os.path.exists(save_loc):\n",
        "      self.train_info = pickle.load(open(save_loc, 'rb'))\n",
        "    else:\n",
        "      self.train_info = {layer:{str(eps):{} for eps in self.__eps} for layer in self.__layers}\n",
        "    for layer in self.__layers:\n",
        "      for eps in self.__eps:\n",
        "        for model in self.__models:\n",
        "            hps = HyperParams(S0=100,\n",
        "                  n_steps=30,\n",
        "                  n_paths=120000,\n",
        "                  discrete_path=False,\n",
        "                  strike_price=100,\n",
        "                  epsilon=eps,\n",
        "                  sigma=0.2,\n",
        "                  risk_free=0,\n",
        "                  dividend=0,\n",
        "                  model_type=model,\n",
        "                  layer_type=layer,\n",
        "                  n_features=16,\n",
        "                  n_layers=3,\n",
        "                  loss_param=1.0,\n",
        "                  batch_size=256,\n",
        "                  test_size=0.2,\n",
        "                  optimizer='adam',\n",
        "                  learning_rate=1E-3,\n",
        "                  num_epochs=100\n",
        "                  )\n",
        "\n",
        "            if model in self.train_info[layer][str(eps)].keys():\n",
        "              train_losses,params, elapsed = self.train_info[layer][str(eps)][model]\n",
        "              \n",
        "              loss = min(train_losses)\n",
        "              num_params = sum(x.size for x in jax.tree_util.tree_leaves(params))\n",
        "              epochs = len(train_losses)\n",
        "              print(f'[eps={eps}, layer={layer}, loss={loss}, model={model}, num_params = {num_params}, elapsed = {elapsed}, num_epochs = {epochs}] already saved, continuing...')\n",
        "              continue\n",
        "            else:\n",
        "              result = self.__train_model(hps, inputs)\n",
        "              self.train_info[layer][str(eps)][model] = result\n",
        "              pickle.dump(open(save_loc,'wb'), self.train_info)\n",
        "  \n",
        "  def test(self, test_batches, save_loc):\n",
        "    if os.path.exists(save_loc):\n",
        "      self.train_info = pickle.load(open(save_loc, 'rb'))\n",
        "    for model in self.__models:\n",
        "      for eps in self.__eps:\n",
        "        for layer in self.__layers:\n",
        "            hps = HyperParams(S0=100,\n",
        "                  n_steps=30,\n",
        "                  n_paths=120000,\n",
        "                  discrete_path=False,\n",
        "                  strike_price=100,\n",
        "                  epsilon=eps,\n",
        "                  sigma=0.2,\n",
        "                  risk_free=0,\n",
        "                  dividend=0,\n",
        "                  model_type=model,\n",
        "                  layer_type=layer,\n",
        "                  n_features=16,\n",
        "                  n_layers=3,\n",
        "                  loss_param=1.0,\n",
        "                  batch_size=256,\n",
        "                  test_size=0.2,\n",
        "                  optimizer='adam',\n",
        "                  learning_rate=1E-3,\n",
        "                  num_epochs=100\n",
        "                  )\n",
        "            if model in self.train_info[layer][str(eps)].keys():\n",
        "              _,params, _ = self.train_info[layer][str(eps)][model]\n",
        "              self.__test_model(hps,params, test_batches)\n",
        "            else:\n",
        "              print(f\"Error! layer={layer}, eps={eps}, model={model} not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HqfLzp-fjesE"
      },
      "outputs": [],
      "source": [
        "seed = 100\n",
        "key = jax.random.PRNGKey(seed)\n",
        "\n",
        "LAYERS = ['linear', 'ortho_pyramid', 'ortho_butterfly']\n",
        "EPS = [ 0.0 , 0.01]\n",
        "MODELS = ['simple','recurrent','lstm', 'attention']\n",
        "\n",
        "dhb = DeepHedgingBenchmark(key=key,eps=EPS, layers=LAYERS, models=MODELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xQ0xOceqC-u9"
      },
      "outputs": [],
      "source": [
        "train_batches = pickle.load(open('data/train_batches_30_days', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CType_0ZrN7r",
        "outputId": "6c379f84-4eb1-450e-e359-d8305327008a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[eps=0.0, layer=linear, loss=2.8535077571868896, model=simple, num_params = 881, elapsed = 68.77824378013611, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.0, layer=linear, loss=2.9285597801208496, model=recurrent, num_params = 881, elapsed = 285.0432679653168, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.0, layer=linear, loss=2.850743532180786, model=lstm, num_params = 569, elapsed = 217.25190377235413, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.0, layer=linear, loss=2.8527638912200928, model=attention, num_params = 1905, elapsed = 68.99567246437073, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=linear, loss=5.03331995010376, model=simple, num_params = 881, elapsed = 62.16713500022888, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=linear, loss=5.045419692993164, model=recurrent, num_params = 881, elapsed = 283.9681055545807, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=linear, loss=4.733962059020996, model=lstm, num_params = 569, elapsed = 219.38532209396362, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=linear, loss=4.695190906524658, model=attention, num_params = 1905, elapsed = 69.76996874809265, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.0, layer=ortho_pyramid, loss=2.8582749366760254, model=simple, num_params = 521, elapsed = 238.8198413848877, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.0, layer=ortho_pyramid, loss=2.9269745349884033, model=recurrent, num_params = 521, elapsed = 3302.076815366745, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.0, layer=ortho_pyramid, loss=2.853080987930298, model=lstm, num_params = 457, elapsed = 3354.0220391750336, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.0, layer=ortho_pyramid, loss=2.857003927230835, model=attention, num_params = 1305, elapsed = 321.2496063709259, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=ortho_pyramid, loss=5.012640476226807, model=simple, num_params = 521, elapsed = 236.08173298835754, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=ortho_pyramid, loss=4.974891185760498, model=recurrent, num_params = 521, elapsed = 3306.8421840667725, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=ortho_pyramid, loss=4.743077754974365, model=lstm, num_params = 457, elapsed = 3371.1014199256897, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=ortho_pyramid, loss=4.770812511444092, model=attention, num_params = 1305, elapsed = 328.11352586746216, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.0, layer=ortho_butterfly, loss=2.857255458831787, model=simple, num_params = 257, elapsed = 91.16442251205444, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.0, layer=ortho_butterfly, loss=2.926149368286133, model=recurrent, num_params = 257, elapsed = 677.7678999900818, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.0, layer=ortho_butterfly, loss=2.8768887519836426, model=lstm, num_params = 217, elapsed = 765.6732606887817, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.0, layer=ortho_butterfly, loss=2.853703737258911, model=attention, num_params = 865, elapsed = 113.17532968521118, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=ortho_butterfly, loss=5.022629737854004, model=simple, num_params = 257, elapsed = 91.81758737564087, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=ortho_butterfly, loss=4.859183311462402, model=recurrent, num_params = 257, elapsed = 678.7052388191223, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=ortho_butterfly, loss=4.78007173538208, model=lstm, num_params = 217, elapsed = 764.6208181381226, num_epochs = 100] already saved, continuing...\n",
            "[eps=0.01, layer=ortho_butterfly, loss=4.7667694091796875, model=attention, num_params = 865, elapsed = 113.5314679145813, num_epochs = 100] already saved, continuing...\n"
          ]
        }
      ],
      "source": [
        "dhb.train(train_batches,save_loc='params/train_info.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YAheb09WeUC5"
      },
      "outputs": [],
      "source": [
        "test_batches = pickle.load(open('data/test_batches_30_days', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na_5LlaIeM5l",
        "outputId": "34edd995-761e-4ba8-ec0c-c3d85700502d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model = simple | Layer = linear | EPS = 0.0| Loss = 2.8678064346313477\n",
            "Model = simple | Layer = ortho_pyramid | EPS = 0.0| Loss = 2.8730738162994385\n",
            "Model = simple | Layer = ortho_butterfly | EPS = 0.0| Loss = 2.8743155002593994\n",
            "Model = simple | Layer = linear | EPS = 0.01| Loss = 5.0649566650390625\n",
            "Model = simple | Layer = ortho_pyramid | EPS = 0.01| Loss = 5.048909664154053\n",
            "Model = simple | Layer = ortho_butterfly | EPS = 0.01| Loss = 5.043356418609619\n",
            "Model = recurrent | Layer = linear | EPS = 0.0| Loss = 2.933910369873047\n",
            "Model = recurrent | Layer = ortho_pyramid | EPS = 0.0| Loss = 2.939173460006714\n",
            "Model = recurrent | Layer = ortho_butterfly | EPS = 0.0| Loss = 2.930788516998291\n",
            "Model = recurrent | Layer = linear | EPS = 0.01| Loss = 5.075922966003418\n",
            "Model = recurrent | Layer = ortho_pyramid | EPS = 0.01| Loss = 5.101611137390137\n",
            "Model = recurrent | Layer = ortho_butterfly | EPS = 0.01| Loss = 4.854455947875977\n",
            "Model = lstm | Layer = linear | EPS = 0.0| Loss = 2.852872371673584\n",
            "Model = lstm | Layer = ortho_pyramid | EPS = 0.0| Loss = 2.8559463024139404\n",
            "Model = lstm | Layer = ortho_butterfly | EPS = 0.0| Loss = 2.879241704940796\n",
            "Model = lstm | Layer = linear | EPS = 0.01| Loss = 4.743974685668945\n",
            "Model = lstm | Layer = ortho_pyramid | EPS = 0.01| Loss = 4.755107879638672\n",
            "Model = lstm | Layer = ortho_butterfly | EPS = 0.01| Loss = 4.787721633911133\n",
            "Model = attention | Layer = linear | EPS = 0.0| Loss = 2.864751100540161\n",
            "Model = attention | Layer = ortho_pyramid | EPS = 0.0| Loss = 2.875650405883789\n",
            "Model = attention | Layer = ortho_butterfly | EPS = 0.0| Loss = 2.861236572265625\n",
            "Model = attention | Layer = linear | EPS = 0.01| Loss = 4.712751388549805\n",
            "Model = attention | Layer = ortho_pyramid | EPS = 0.01| Loss = 4.806332588195801\n",
            "Model = attention | Layer = ortho_butterfly | EPS = 0.01| Loss = 4.82267427444458\n"
          ]
        }
      ],
      "source": [
        "dhb.test(test_batches,save_loc='params/train_info.pkl')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "jpmc",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad54ef31d854a95caa7f093c1b575c6633ad4c5ad56f723ed5e92cb8b22d7116"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
