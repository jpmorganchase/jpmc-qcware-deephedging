{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4N54UWkze-O"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_peKxaSNo1T",
    "outputId": "14e52d8e-ce58-40ad-b71d-ae4be0fce23a"
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "  %pip install QuantLib\n",
    "  %pip install optax\n",
    "  %pip install qiskit\n",
    "  %pip install qcware\n",
    "\n",
    "  %pip install qcware-quasar\n",
    "  ! rm -rf deep-hedging\n",
    "  ! git clone https://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@github.com/SnehalRaj/jpmc-qcware-deephedging deep-hedging\n",
    "  ! cp -r deep-hedging/* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FXSzgmKfN8-a"
   },
   "outputs": [],
   "source": [
    "import qiskit\n",
    "\n",
    "import quasar\n",
    "from qcware_transpile.translations.quasar.to_qiskit import translate, audit\n",
    "from qiskit.compiler import assemble\n",
    "import collections\n",
    "\n",
    "from qio import loader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "S5IfE-WEzjqL"
   },
   "source": [
    "## Circuit constructions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `prepare_circuit(input, params, loader_layout, layer_layout)`: This function prepares a quantum circuit for a given input and set of parameters, which can later be executed on quantum hardware. The function takes three inputs: input, params, and optional arguments `loader_layout` and `layer_layout`. The function first determines the number of qubits in the circuit based on the length of the input array. It then creates a loader circuit using the loader function provided in the loader_layout format. The function then calls a `_get_layer_circuit()` function that creates a circuit layer based on the params array and the layer_layout format. The circuit layer is constructed using the RBS gate defined using `quasar.Gate.RBS()`. The `quasar.Gate.RBS()` function is called with a negative value of the params array elements (so as to take care of qiskit's reverse qubits notation) and added to the circuit layer for each gate in the `rbs_idxs` array. The function then combines the loader and layer circuits into a single `quasar.Circuit` object, which is then translated to a Qiskit circuit using the `translate()` function. The Qiskit circuit is then optimized and measured, and the function returns the resulting circuit.\n",
    "\n",
    "- `run_circuit(circs,circuit_dim, backend_name)`: This function accepts a list of `qiskit` circuits (which need to have the same qubit count), the number of qubits in each of the given circuit and the backend_name. The circuits are assumed to be hamming-weights preserving circuit used as part of quantum orthogonal layers. The function prepares a numpy array called `results` containing the output vector in unary basis. Currently this function supports two backends `qiskit` and `quantinuum`. The results run on `quantinuum`-based backends are stored using global variables `global_number_of_circuits_executed` and  `global_hardware_run_results_dict`. This function then runs the circuit on the selected backend, and returns the result of the computation. If the backend is 'qiskit', the function uses the Qiskit Aer simulator to simulate the circuit and compute the result. If the backend is 'quantinuum', the function uses the Quantinuum simulator to perform the computation. Note that this function assumes that the user has already installed the required packages for the specified backend, and that the backend is properly configured and accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3g2FYe7qX20R"
   },
   "outputs": [],
   "source": [
    "# Global counter\n",
    "\n",
    "global_number_of_circuits_executed = 0\n",
    "\n",
    "# Global object keeping track of result\n",
    "# Used for pickling\n",
    "# Populated initially in DeepHedgingBenchmark().__test_model\n",
    "# and with run results in run_circuit\n",
    "# keeping track of batch_idx in scan (under \"Models\")\n",
    "\n",
    "global_hardware_run_results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1QEKbaJDOjXK"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from qnn import _get_butterfly_idxs, _get_pyramid_idxs, _make_orthogonal_fn\n",
    "# fix for older versions of Qiskit\n",
    "if qiskit.__version__ <= '0.37.1':\n",
    "    import qiskit.providers.aer.noise as noise\n",
    "else:\n",
    "    import qiskit_aer.noise as noise\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def prepare_circuit(input, params, loader_layout='parallel', layer_layout='butterfly'):\n",
    "    def _get_layer_circuit():\n",
    "      _params = np.array(params).astype('float')\n",
    "      if layer_layout == 'butterfly':\n",
    "        rbs_idxs = _get_butterfly_idxs(num_qubits, num_qubits)\n",
    "      elif layer_layout == 'pyramid':\n",
    "        rbs_idxs = _get_pyramid_idxs(num_qubits, num_qubits)\n",
    "      circuit_layer = quasar.Circuit()\n",
    "      idx_angle = 0\n",
    "      for gates_per_timestep in rbs_idxs[::-1]:\n",
    "        for gate in gates_per_timestep:\n",
    "          circuit_layer.add_gate(quasar.Gate.RBS(theta=-_params[::-1][idx_angle]), tuple(gate))\n",
    "          idx_angle+=1\n",
    "      return circuit_layer\n",
    "    \n",
    "    num_qubits = len(input)\n",
    "    loader_circuit = loader(np.array(input),mode=loader_layout,initial=True,controlled=False)\n",
    "    layer_circuit = _get_layer_circuit()\n",
    "    circuit = quasar.Circuit.join_in_time([loader_circuit, layer_circuit])\n",
    "    # Translate from qcware-quasar to qiskit\n",
    "    qiskit_circuit = translate(circuit)\n",
    "    \n",
    "    # qiskit_circuit.save_statevector()    \n",
    "\n",
    "    qiskit_circuit = qiskit.transpile(qiskit_circuit, optimization_level=3)\n",
    "    c = qiskit.ClassicalRegister(num_qubits)\n",
    "    qiskit_circuit.add_register(c)\n",
    "    qiskit_circuit.barrier()\n",
    "    qiskit_circuit.measure(qubit=range(num_qubits),cbit=c)\n",
    "    return qiskit_circuit\n",
    "\n",
    "def counter_to_dict(c):\n",
    "    \"\"\"Converts counter returned by pytket get_counts function\n",
    "    to dictionary returned by qiskit\n",
    "    canonical use:\n",
    "    >>> result = backend.get_result(handle)\n",
    "    >>> counts = result.get_counts(basis=BasisOrder.dlo)\n",
    "    >>> counts_qiskit = counter_to_dict(counts)\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    for k, v in c.items():\n",
    "        d[''.join(str(x) for x in k)] = int(v)\n",
    "    return d\n",
    "\n",
    "def run_circuit(circs,circuit_dim, backend_name = 'quantinuum_H1-1'):\n",
    "    \"\"\"\n",
    "    backend name accepted \n",
    "    \"\"\"\n",
    "    global global_number_of_circuits_executed\n",
    "    global global_hardware_run_results_dict\n",
    "    input_size = circuit_dim\n",
    "    results = np.zeros((len(circs), input_size))\n",
    "    \n",
    "    global_number_of_circuits_executed += len(circs)\n",
    "    num_measurements = 1000\n",
    "    \n",
    "    if \"qiskit\" in backend_name:\n",
    "        backend = qiskit.Aer.get_backend('qasm_simulator')\n",
    "        if backend_name == 'qiskit_noiseless':\n",
    "            measurement = qiskit.execute(circs, backend, shots=num_measurements)\n",
    "        elif backend_name == 'qiskit_noisy': \n",
    "            # Error probabilities\n",
    "            prob_1 = 0.001  # 1-qubit gate\n",
    "            prob_2 = 0.01   # 2-qubit gate\n",
    "            # Dylan's tunes error probabilities\n",
    "            # prob_1 = 0  # 1-qubit gate\n",
    "            # prob_2 = 3.5e-3   # 2-qubit gate\n",
    "\n",
    "            # Depolarizing quantum errors\n",
    "            error_1 = noise.depolarizing_error(prob_1, 1)\n",
    "            error_2 = noise.depolarizing_error(prob_2, 2)\n",
    "\n",
    "            # Add errors to noise model\n",
    "            noise_model = noise.NoiseModel()\n",
    "            noise_model.add_all_qubit_quantum_error(error_1, ['h', 'x', 'ry'])\n",
    "            noise_model.add_all_qubit_quantum_error(error_2, ['cz'])\n",
    "\n",
    "            # Get basis gates from noise model\n",
    "            basis_gates = noise_model.basis_gates\n",
    "            measurement = qiskit.execute(circs, backend,basis_gates=basis_gates, noise_mode=noise_model, shots=num_measurements)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected backend name {backend_name}\")\n",
    "        all_counts = measurement.result().get_counts()\n",
    "    elif \"quantinuum\" in backend_name:\n",
    "        # From docs: \"Batches cannot exceed the maximum limit of 500 H-System Quantum Credits (HQCs) total\"\n",
    "        # Therefore batching is more or less useless on quantinuum\n",
    "        from pytket.extensions.qiskit import qiskit_to_tk\n",
    "        from pytket.circuit import BasisOrder\n",
    "        from pytket.extensions.quantinuum import QuantinuumBackend\n",
    "    \n",
    "        outpath_stem = \"_\".join([\n",
    "            \"1115_device\",\n",
    "            global_hardware_run_results_dict['model_type'],\n",
    "            backend_name,\n",
    "            global_hardware_run_results_dict['layer_type'],\n",
    "            str(global_hardware_run_results_dict['epsilon']),\n",
    "            str(global_hardware_run_results_dict['batch_idx']),\n",
    "        ])\n",
    "        \n",
    "        outpath_result_final = f\"data/{outpath_stem}.json\"\n",
    "        outpath_handles = f\"data/handles_{outpath_stem}.pickle\"\n",
    "        \n",
    "        if Path(outpath_result_final).exists():\n",
    "            # if precomputed results already present on disk, simply load\n",
    "            print(f\"Using precomputed counts from {outpath_result_final}\")\n",
    "            all_counts = json.load(open(outpath_result_final, \"r\"))['all_counts']\n",
    "        else:\n",
    "            if backend_name == \"quantinuum_H1-2E\":\n",
    "                backend = QuantinuumBackend(device_name=\"H1-2E\")\n",
    "            elif backend_name == \"quantinuum_H1-2\":\n",
    "                backend = QuantinuumBackend(device_name=\"H1-2\")\n",
    "            elif backend_name == \"quantinuum_H1-1E\":\n",
    "                backend = QuantinuumBackend(device_name=\"H1-1E\")\n",
    "            elif backend_name == \"quantinuum_H1-1\":\n",
    "                backend = QuantinuumBackend(device_name=\"H1-1\")\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown Quantinuum backend: {backend_name}\")\n",
    "            if Path(outpath_handles).exists():\n",
    "                # if circuits already submitted, simply load from disk\n",
    "                print(f\"Using pickled handles from {outpath_handles}\")\n",
    "                handles = pickle.load(open(outpath_handles, \"rb\"))\n",
    "            else:\n",
    "                # otherwise, submit circuits and pickle handles\n",
    "                circs_tk = [qiskit_to_tk(circ) for circ in circs]\n",
    "                for idx, circ in enumerate(circs_tk):\n",
    "                    circ.name = f'{outpath_stem}_{idx+1}_of_{len(circs)}'\n",
    "                compiled_circuits = backend.get_compiled_circuits(circs_tk, optimisation_level=2)\n",
    "                handles = backend.process_circuits(compiled_circuits, n_shots=num_measurements)\n",
    "                pickle.dump(handles, open(outpath_handles, \"wb\"))\n",
    "                print(f\"Dumped handles to {outpath_handles}\")\n",
    "            # retrieve results from handles\n",
    "            result_list = []\n",
    "            \n",
    "            with tqdm(total=len(handles), desc='#jobs finished') as pbar:\n",
    "                for handle in handles:\n",
    "                    while True:\n",
    "                        status = backend.circuit_status(handle).status\n",
    "                        if status.name == 'COMPLETED':\n",
    "                            result = backend.get_result(handle)\n",
    "                            result_list.append(copy.deepcopy(result))\n",
    "                            pbar.update(1)\n",
    "                            break\n",
    "                        else:\n",
    "                            assert status.name in ['QUEUED', 'RUNNING'] \n",
    "                        time.sleep(1)\n",
    "            global_hardware_run_results_dict['result_list'] = [x.to_dict() for x in result_list]\n",
    "            # convert from tket counts format to qiskit\n",
    "            all_counts = [\n",
    "                counter_to_dict(\n",
    "                    result.get_counts(basis=BasisOrder.dlo)\n",
    "                ) for result in result_list\n",
    "            ]\n",
    "            global_hardware_run_results_dict['all_counts'] = all_counts\n",
    "            # dump result on disk\n",
    "            json.dump(global_hardware_run_results_dict, open(outpath_result_final, \"w\"))\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected backend name {backend_name}\")\n",
    "        \n",
    "    global_hardware_run_results_dict['batch_idx'] += 1    \n",
    "    # Post processing\n",
    "    # Discard bitstrings that do not correspond to unary encoding (not Hamming weight 1)\n",
    "    # We build a dictionary with all unary bitstrings and only add counts corresponding to unary bitstrings\n",
    "    # Note: f\"{2**i:0{input_size}b}\" converts 2**i to its binary string representation.\n",
    "    for j in range(len(circs)):\n",
    "        measurementRes = all_counts[j]\n",
    "        num_postselected = 0\n",
    "        filtered_counts = {f\"{2**i:0{input_size}b}\":0 for i in range(input_size)}\n",
    "        for bitstring, count in measurementRes.items():\n",
    "            if sum([int(x) for x in bitstring]) != 1:\n",
    "                continue\n",
    "            filtered_counts[bitstring] += count\n",
    "            num_postselected+= count\n",
    "        results[j] = [filtered_counts[k]/num_postselected for k in sorted(filtered_counts)][::-1]    \n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "__w2M8wQskTn"
   },
   "source": [
    "## ortho_linear_hardware()\n",
    "\n",
    "This layer replaces `ortho_linear()` present in `qnn.py` and runs the same operation but on real hardware using the `run_circuit()` function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TqFtMKbVhkR9"
   },
   "outputs": [],
   "source": [
    "from qnn import *\n",
    "def ortho_linear_hardware(\n",
    "    n_features: int,\n",
    "    layout: Union[str, List[List[Tuple[int, int]]]] = 'butterfly',\n",
    "    normalize_inputs: bool = True,\n",
    "    normalize_outputs: bool = True,\n",
    "    normalize_stop_gradient: bool = True,\n",
    "    with_scale: bool = True,\n",
    "    with_bias: bool = True,\n",
    "    t_init: Optional[InitializerFn] = None,\n",
    "    s_init: Optional[InitializerFn] = None,\n",
    "    b_init: Optional[InitializerFn] = None,\n",
    ") -> ModuleFn:\n",
    "    \"\"\" Create an orthogonal layer from a layout of RBS gates which can be executed on hardware.\n",
    "    Args:\n",
    "        n_features: The number of features in the output.\n",
    "        layout: The layout of the RBS gates.\n",
    "        normalize_inputs: Whether to normalize the inputs.\n",
    "        normalize_outputs: Whether to normalize the outputs.\n",
    "        normalize_stop_gradient: Whether to stop the gradient of the norm.\n",
    "        with_scale: Whether to use a scale parameter.\n",
    "        with_bias: Whether to include a bias term.\n",
    "        t_init: The initializer for the angles.\n",
    "        s_init: The initializer for the scale.\n",
    "        b_init: The initializer for the bias.\n",
    "    \"\"\"\n",
    "    def apply_fn(params, state, key, inputs, **kwargs):\n",
    "        # Step 1: preprocess the inputs\n",
    "        if layout == 'butterfly':\n",
    "            rbs_idxs = _get_butterfly_idxs(inputs.shape[-1], n_features)\n",
    "            circuit_dim = int(2**np.ceil(\n",
    "                np.log2(max(inputs.shape[-1], n_features))))\n",
    "        elif layout == 'pyramid':\n",
    "            rbs_idxs = _get_pyramid_idxs(inputs.shape[-1], n_features)\n",
    "            make_unitary = _get_pyramid_idxs(inputs.shape[-1], n_features)\n",
    "            circuit_dim = max(inputs.shape[-1], n_features)\n",
    "        else:\n",
    "            rbs_idxs = layout\n",
    "            circuit_dim = max(\n",
    "                [max(idxs) for moment in layout for idxs in moment])\n",
    "        if normalize_inputs:\n",
    "            norm = jnp.linalg.norm(inputs, axis=-1)[..., None]\n",
    "            if normalize_stop_gradient:\n",
    "                norm = lax.stop_gradient(norm)\n",
    "            inputs /= norm\n",
    "        if inputs.shape[-1] < circuit_dim:\n",
    "            zeros = jnp.zeros(\n",
    "                (*inputs.shape[:-1], circuit_dim - inputs.shape[-1]), )\n",
    "            inputs = jnp.concatenate([zeros, inputs], axis=-1)\n",
    "        # Step 2: generate the circuits\n",
    "        circs = []\n",
    "        out_shape = inputs.shape[:-1]+(n_features,)\n",
    "        for input in inputs.reshape(-1,circuit_dim):\n",
    "            circs.append(prepare_circuit(input,params['t']))\n",
    "        # run circuits and truncate to desired number of outputs\n",
    "        outputs = jnp.array(run_circuit(circs, circuit_dim))[..., -n_features:]\n",
    "        \n",
    "        outputs = outputs.reshape(out_shape)\n",
    "        # unitary = make_unitary(params['t'])\n",
    "        # outputs = jnp.dot(inputs, unitary.T)[..., -n_features:]\n",
    "        # outputs = inputs\n",
    "        if with_scale:\n",
    "            outputs *= params['s']\n",
    "        if with_bias:\n",
    "            outputs += params['b']\n",
    "        return outputs, state\n",
    "\n",
    "    def init_fn(key, inputs_shape):\n",
    "        if layout == 'butterfly':\n",
    "            rbs_idxs = _get_butterfly_idxs(inputs_shape[-1], n_features)\n",
    "        elif layout == 'pyramid':\n",
    "            rbs_idxs = _get_pyramid_idxs(inputs_shape[-1], n_features)\n",
    "        else:\n",
    "            rbs_idxs = layout\n",
    "        n_angles = sum(map(len, rbs_idxs))\n",
    "        params, state = {}, None\n",
    "        key, t_key, b_key, s_key = jax.random.split(key, 4)\n",
    "        t_init_ = t_init or uniform(-np.pi, np.pi)\n",
    "        t_shape = (n_angles, )\n",
    "        params['t'] = t_init_(t_key, t_shape)\n",
    "        if with_scale:\n",
    "            s_init_ = s_init or ones()\n",
    "            s_shape = (n_features, )\n",
    "            params['s'] = s_init_(s_key, s_shape)\n",
    "        if with_bias:\n",
    "            b_init_ = b_init or zeros()\n",
    "            b_shape = (n_features, )\n",
    "            params['b'] = b_init_(b_key, b_shape)\n",
    "        shape = inputs_shape[:-1] + (n_features, )\n",
    "        return params, state, shape\n",
    "\n",
    "    return ModuleFn(apply_fn, init=init_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "A6TcMo24PAKh"
   },
   "source": [
    "# Data\n",
    "\n",
    "We begin by import the modules from the repository. Then to generate test data using geometric Brownian motion we use the `gen_paths()` function in `data.py`. \n",
    "\n",
    "Note: The data generation has been commented here because we pickled a particular test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOnoeMTmz7ZO",
    "outputId": "b6171e83-ceec-4116-e9fd-b8c6790c2fb6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# from models import simple_network, attention_network\n",
    "from qnn import linear\n",
    "from train import build_train_fn\n",
    "from qnn import ortho_linear, ortho_linear_noisy\n",
    "from models import simple_network, recurrent_network_hardware, lstm_network_hardware, attention_network\n",
    "from loss_metrics import entropy_loss\n",
    "from data import gen_paths\n",
    "from utils import train_test_split, get_batches, HyperParams\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import optax\n",
    "from functools import partial \n",
    "from utils import HyperParams\n",
    "seed = 100\n",
    "key = jax.random.PRNGKey(seed)\n",
    "# No need to generate data as we load from disk\n",
    "# hps = HyperParams(S0=100,\n",
    "#                   n_steps=5,\n",
    "#                   n_paths=10000,\n",
    "#                   discrete_path=False,\n",
    "#                   strike_price=100,\n",
    "#                   epsilon=0.0,\n",
    "#                   sigma=0.2,\n",
    "#                   risk_free=0,\n",
    "#                   dividend=0,\n",
    "#                   model_type='simple',\n",
    "#                   layer_type='noisy_ortho',\n",
    "#                   n_features=8,\n",
    "#                   n_layers=1,\n",
    "#                   loss_param=1.0,\n",
    "#                   batch_size=4,\n",
    "#                   test_size=0.2,\n",
    "#                   optimizer='adam',\n",
    "#                   learning_rate=1E-3,\n",
    "#                   num_epochs=100\n",
    "#                   )\n",
    "\n",
    "\n",
    "# Data\n",
    "# S = gen_paths(hps)\n",
    "# [S_train, S_test] = train_test_split([S], test_size=0.2)\n",
    "# _, test_batches = get_batches(jnp.array(S_test[0]), batch_size=hps.batch_size)\n",
    "# test_batch = test_batches[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepHedgingBenchmark()\n",
    "\n",
    "This is a class to benchmark the performance of different models and layers for deep hedging. It has one main method __test_model() which is used to perform inference using the layers and models specified in the input. Note that choosing `hps.layer_type` to `ortho_linear_hardware()` runs inference on hardware backend using `run_circuit()` function defined above. \n",
    "\n",
    "#### Parameters\n",
    "- `key`: A random key value used for jax random splitting.\n",
    "- `eps`: A list of float values representing the hedge intervals to be used in training.\n",
    "- `layers`: A list of string values representing the layer types to be used in \n",
    "training. It should only contain values from `['linear', 'ortho', 'noisy_ortho', 'hardware_ortho']`.\n",
    "- `models`: A list of string values representing the model types to be used in training. It should only contain values from `['simple', 'recurrent', 'lstm', 'attention']`.\n",
    "\n",
    "#### Methods\n",
    "- `__test_model(hps,test_batch, save_dir)`: A private method that tests the model. It takes in hyperparameters hps, a batch of paths `test_batch` to run inference on and `save_dir` which specifies where to load the saved model parameters from. The hyperparameters include layer_type, model_type, n_steps, epsilon, and num_epochs. It returns the testing loss.\n",
    "- `test(test_batch)`:  A method to test the model. It takes in `test_batch` which is the testing data and then output the necessary information about the model. It outputs the layer, the model architecture, the utility on these paths and the number of circuits executed. It also prints the output actions for each day and the Terminal PnL for each paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fVm_ZjYhHCQu"
   },
   "outputs": [],
   "source": [
    "from utils import load_params\n",
    "class DeepHedgingBenchmark():\n",
    "  \"\"\"\n",
    "  Runs the benchmark with different models / layers\n",
    "  Input: test_batch above\n",
    "  test_batch has 8 datapoints\n",
    "  \"\"\"\n",
    "  def __init__(self, key, eps,  layers, models):\n",
    "      self.__key = key\n",
    "      self.__models = models\n",
    "      self.__layers = layers\n",
    "      self.__eps = eps\n",
    "      self.test_info = {layer:{str(eps):{} for eps in self.__eps} for layer in self.__layers}\n",
    "  def __test_model(self, hps, test_batch, save_dir = 'params/params_all_models_16_qubits_5_days.pkl'):\n",
    "    # set up global objects for pickling circuit execution results\n",
    "    global global_number_of_circuits_executed\n",
    "    global global_hardware_run_results_dict\n",
    "    global_number_of_circuits_executed = 0\n",
    "    global_hardware_run_results_dict = {\n",
    "        'model_type' : hps.model_type,\n",
    "        'measurementRes' : None,\n",
    "        'epsilon' : hps.epsilon,\n",
    "        'backend_name' : None,\n",
    "        'layer_type' : hps.layer_type,\n",
    "        'batch_idx' : 0,\n",
    "    }\n",
    "    if hps.layer_type in ['linear','linear_svb']:\n",
    "      layer_func = linear\n",
    "    elif hps.layer_type=='ortho':\n",
    "      layer_func = ortho_linear\n",
    "    elif hps.layer_type=='noisy_ortho':\n",
    "      layer_func = partial(ortho_linear_noisy,noise_scale=0.01)\n",
    "    elif hps.layer_type=='hardware_ortho':\n",
    "      # TODO want to run this on Quantinuum device \n",
    "      layer_func = ortho_linear_hardware\n",
    "\n",
    "    if hps.model_type == 'simple':\n",
    "      net = simple_network(hps=hps, layer_func=layer_func)\n",
    "    elif hps.model_type == 'recurrent':\n",
    "      net = recurrent_network_hardware(hps=hps, layer_func=layer_func)\n",
    "    elif hps.model_type == 'lstm':\n",
    "      net = lstm_network_hardware(hps=hps, layer_func=layer_func)\n",
    "    elif hps.model_type == 'attention':\n",
    "      net = attention_network(hps=hps, layer_func=layer_func)\n",
    "    \n",
    "    opt = optax.adam(1E-3)\n",
    "    key, init_key = jax.random.split(self.__key)\n",
    "    _, state, _ = net.init(init_key, (1, hps.n_steps, 1))\n",
    "    loss_metric = entropy_loss\n",
    "\n",
    "    # Training\n",
    "\n",
    "    train_fn, loss_fn = build_train_fn(hps, net, opt, loss_metric)\n",
    "\n",
    "    train_info = load_params(save_dir)\n",
    "    layer_type = \"noisy_ortho\" if hps.layer_type == 'hardware_ortho' else hps.layer_type\n",
    "    train_losses, params = train_info[layer_type][str(hps.epsilon)][hps.model_type]\n",
    "    loss, (state, wealths, deltas, outputs) = loss_fn(params, state, key, test_batch[...,None])\n",
    "    print(f'Model = {hps.model_type} | Layer = {hps.layer_type} | EPS = {hps.epsilon}| Loss = {loss} | #circs = {global_number_of_circuits_executed}')\n",
    "    print(f'Deltas = {deltas[...,0]}')\n",
    "    print(f'Terminal PnL = {wealths.reshape(-1)}')\n",
    "    return loss\n",
    "  def test(self, inputs):\n",
    "    for model in self.__models:\n",
    "      for eps in self.__eps:\n",
    "        for layer in self.__layers:\n",
    "            hps = HyperParams(S0=100,\n",
    "                  n_steps=5,\n",
    "                  n_paths=120000,\n",
    "                  discrete_path=True,\n",
    "                  strike_price=100,\n",
    "                  epsilon=eps,\n",
    "                  sigma=0.2,\n",
    "                  risk_free=0,\n",
    "                  dividend=0,\n",
    "                  model_type=model,\n",
    "                  layer_type=layer,\n",
    "                  n_features=16,\n",
    "                  n_layers=1,\n",
    "                  loss_param=1.0,\n",
    "                  batch_size=4,\n",
    "                  test_size=0.2,\n",
    "                  optimizer='adam',\n",
    "                  learning_rate=1E-3,\n",
    "                  num_epochs=100)\n",
    "            self.test_info[layer][str(eps)][model] = self.__test_model(hps, inputs)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "T-RtLEOMgIHt"
   },
   "outputs": [],
   "source": [
    "seed = 100\n",
    "key = jax.random.PRNGKey(seed)\n",
    "\n",
    "LAYERS = ['hardware_ortho']\n",
    "EPS = [  0.01]\n",
    "MODELS = ['lstm']\n",
    "\n",
    "# LAYERS = ['linear','ortho','noisy_ortho','hardware_ortho']\n",
    "# EPS = [ 0.01]\n",
    "# MODELS = ['lstm']\n",
    "\n",
    "# test only\n",
    "\n",
    "# LAYERS = ['hardware_ortho']\n",
    "# EPS = [ 0.01]\n",
    "# MODELS = ['simple','recurrent','lstm','attention']\n",
    "\n",
    "dhb = DeepHedgingBenchmark(key=key,eps=EPS, layers=LAYERS, models=MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RxuPah3oKIZF"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': \"{0:0.3f}\".format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "83HKjeblRioM"
   },
   "outputs": [],
   "source": [
    "# Fixing test_batch as suggested by Snehal\n",
    "# pickle.dump(test_batch, open('data/1115_test_batch_4_points.pickle', 'wb'))\n",
    "test_batch = pickle.load(open('data/1115_test_batch_4_points.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3V7QYQWlnlHy"
   },
   "source": [
    "Non-emulator results:\n",
    "5 days, 4 paths\n",
    "\n",
    "```\n",
    "Model = lstm | Layer = linear | EPS = 0.01| Loss = 2.1739442348480225 | #circs = 0\n",
    "Deltas = [[0.435 -0.002 -0.187 -0.182 -0.050 -0.014]\n",
    " [0.435 0.050 0.019 -0.001 -0.027 -0.476]\n",
    " [0.435 -0.015 -0.000 -0.085 -0.038 -0.296]\n",
    " [0.435 0.000 0.019 -0.001 -0.002 -0.451]]\n",
    "Terminal PnL = [-2.578 -1.225 -1.420 -2.671]\n",
    "Model = lstm | Layer = ortho | EPS = 0.01| Loss = 2.1762888431549072 | #circs = 0\n",
    "Deltas = [[0.435 0.001 -0.203 -0.165 -0.049 -0.019]\n",
    " [0.435 0.051 0.011 -0.006 -0.045 -0.447]\n",
    " [0.435 -0.013 0.004 -0.090 -0.025 -0.310]\n",
    " [0.435 0.000 0.010 0.001 -0.001 -0.446]]\n",
    "Terminal PnL = [-2.586 -1.194 -1.439 -2.671]\n",
    "Model = lstm | Layer = noisy_ortho | EPS = 0.01| Loss = 2.1889312267303467 | #circs = 0\n",
    "Deltas = [[0.437 0.004 -0.213 -0.158 -0.043 -0.027]\n",
    " [0.428 0.040 0.027 -0.009 -0.022 -0.463]\n",
    " [0.432 -0.019 0.000 -0.104 -0.018 -0.291]\n",
    " [0.435 -0.000 0.029 0.010 -0.001 -0.472]]\n",
    "Terminal PnL = [-2.620 -1.205 -1.435 -2.669]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHOSr4XgzC4a",
    "outputId": "6cb557cf-99c7-4654-b4f0-6831cfb2c96a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_0.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_1.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_2.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_3.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_4.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_5.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_6.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_7.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_8.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_9.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_10.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_11.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_12.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_13.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_14.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_15.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_16.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_17.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_18.json\n",
      "Using precomputed counts from data/1115_device_lstm_quantinuum_H1-1_hardware_ortho_0.01_19.json\n",
      "Model = lstm | Layer = hardware_ortho | EPS = 0.01| Loss = 2.1947038173675537 | #circs = 80\n",
      "Deltas = [[0.439 -0.011 -0.186 -0.170 -0.047 -0.025]\n",
      " [0.436 0.043 0.037 0.003 -0.012 -0.506]\n",
      " [0.447 -0.003 0.007 -0.096 -0.011 -0.344]\n",
      " [0.435 0.004 0.038 0.007 -0.004 -0.481]]\n",
      "Terminal PnL = [-2.610 -1.284 -1.488 -2.658]\n"
     ]
    }
   ],
   "source": [
    "dhb.test(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WSgwaeMQIcjF",
    "outputId": "fcf0adc0-db39-497b-e3d4-d603b150300a"
   },
   "outputs": [],
   "source": [
    "# dhb.test(test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "esRqWWUQT4y4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jpmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad54ef31d854a95caa7f093c1b575c6633ad4c5ad56f723ed5e92cb8b22d7116"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
