{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from absl import app\n",
        "\n",
        "# Addresses `UnrecognizedFlagError: Unknown command line flag 'f'`\n",
        "sys.argv = sys.argv[:1]\n",
        "\n",
        "# `app.run` calls `sys.exit`\n",
        "try:\n",
        "  app.run(lambda argv: None)\n",
        "except:\n",
        "  pass\n",
        "%pip install dm-haiku\n",
        "%pip install optax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7CIXtruS1wE",
        "outputId": "a8507548-71e0-452f-a14d-ad24266ecc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.8-py3-none-any.whl (350 kB)\n",
            "\u001b[K     |████████████████████████████████| 350 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting jmp>=0.0.2\n",
            "  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.8.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.21.6)\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.8 jmp-0.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (1.2.0)\n",
            "Collecting chex>=0.0.4\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.21)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.21.6)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.20+cuda11.cudnn805)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from optax) (4.1.1)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.7)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (0.8.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (3.8.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (5.9.0)\n",
            "Installing collected packages: chex, optax\n",
            "Successfully installed chex-0.1.5 optax-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## qnn"
      ],
      "metadata": {
        "id": "aS03ScTZT-Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "from functools import partial\n",
        "import itertools\n",
        "from typing import (Callable, List, Mapping, NamedTuple, Optional, Sequence,\n",
        "                    Tuple, Union)\n",
        "\n",
        "import jax\n",
        "import numpy as np\n",
        "from jax import lax\n",
        "from jax import numpy as jnp\n",
        "\n",
        "# Typing\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "Array = jnp.ndarray\n",
        "Shape = Tuple[int, ...]\n",
        "Dtype = Union[jnp.float32, jnp.float64]\n",
        "PRNGKey = Array\n",
        "Params = Mapping[str, Mapping[str, jnp.ndarray]]\n",
        "InitializerFn = Callable[[PRNGKey, Shape, Dtype], Array]\n",
        "\n",
        "\n",
        "class ModuleFn(NamedTuple):\n",
        "    apply: Callable[..., Array]\n",
        "    shape: Optional[Callable[[Shape], Shape]]\n",
        "    init: Optional[Callable[..., Tuple[Params, Array]]] = None\n",
        "\n",
        "\n",
        "def add_scope_to_params(scope, params):\n",
        "    return dict((f\"{scope}/{key}\", array) for key, array in params.items())\n",
        "\n",
        "\n",
        "def get_params_by_scope(scope, params):\n",
        "    return dict((key[len(scope) + 1:], array) for key, array in params.items()\n",
        "                if key.startswith(scope + '/'))\n",
        "\n",
        "\n",
        "# Initializers\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def constant(val: float, ) -> InitializerFn:\n",
        "    def init_fn(key, shape, dtype=jnp.float32):\n",
        "        return jnp.broadcast_to(val, shape).astype(dtype)\n",
        "\n",
        "    return init_fn\n",
        "\n",
        "\n",
        "def zeros() -> InitializerFn:\n",
        "    \"\"\" Initialize with zeros.\"\"\"\n",
        "    return constant(0.)\n",
        "\n",
        "\n",
        "def ones() -> InitializerFn:\n",
        "    \"\"\" Initialize with ones.\"\"\"\n",
        "    return constant(1.)\n",
        "\n",
        "\n",
        "def uniform(\n",
        "    minval: float = 0.,\n",
        "    maxval: float = 1.,\n",
        ") -> InitializerFn:\n",
        "    def init_fn(key, shape, dtype=jnp.float32):\n",
        "        return jax.random.uniform(key, shape, dtype, minval, maxval)\n",
        "\n",
        "    return init_fn\n",
        "\n",
        "\n",
        "def normal(\n",
        "    mean: float = 0.,\n",
        "    std: float = 1.,\n",
        ") -> InitializerFn:\n",
        "    def init_fn(key, shape, dtype=jnp.float32):\n",
        "        _mean = lax.convert_element_type(mean, dtype)\n",
        "        _std = lax.convert_element_type(std, dtype)\n",
        "        return _mean + _std * jax.random.normal(key, shape, dtype)\n",
        "\n",
        "    return init_fn\n",
        "\n",
        "\n",
        "def truncated_normal(\n",
        "    mean: float = 0.,\n",
        "    std: float = 1.,\n",
        ") -> InitializerFn:\n",
        "    def init_fn(key, shape, dtype=jnp.float32):\n",
        "        _mean = lax.convert_element_type(mean, dtype)\n",
        "        _std = lax.convert_element_type(std, dtype)\n",
        "        return _mean + _std * jax.random.truncated_normal(\n",
        "            key, -2., 2., shape, dtype)\n",
        "\n",
        "    return init_fn\n",
        "\n",
        "\n",
        "# Activations\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "def activation(activation_fn: Callable[[Array], Array], ) -> ModuleFn:\n",
        "    def shape_fn(inputs_shape):\n",
        "        return inputs_shape\n",
        "\n",
        "    def apply_fn(params, key, inputs, **kwargs):\n",
        "        return activation_fn(inputs)\n",
        "\n",
        "    return ModuleFn(apply_fn, shape_fn)\n",
        "\n",
        "\n",
        "relu = activation(jax.nn.relu)\n",
        "gelu = activation(jax.nn.gelu)\n",
        "selu = activation(jax.nn.selu)\n",
        "tanh = activation(jax.nn.tanh)\n",
        "square = activation(jnp.square)\n",
        "sigmoid = activation(jax.nn.sigmoid)\n",
        "log_softmax = activation(jax.nn.log_softmax)\n",
        "softmax = activation(jax.nn.softmax)\n",
        "\n",
        "\n",
        "def linear(\n",
        "    n_features: int,\n",
        "    with_bias: bool = True,\n",
        ") -> ModuleFn:\n",
        "    def apply_fn(params, key, inputs, **kwargs):\n",
        "        outputs = jnp.dot(inputs, params['w'])\n",
        "        if with_bias:\n",
        "            outputs += params['b']\n",
        "        return outputs\n",
        "\n",
        "    def init_fn(key, inputs_shape):\n",
        "        params = {}\n",
        "        key, w_key, b_key = jax.random.split(key, 3)\n",
        "        w_init = truncated_normal(std=1. / inputs_shape[-1])\n",
        "        w_shape = (inputs_shape[-1], n_features)\n",
        "        params['w'] = w_init(w_key, w_shape)\n",
        "        if with_bias:\n",
        "            b_init = zeros()\n",
        "            b_shape = (n_features, )\n",
        "            params['b'] = b_init(b_key, b_shape)\n",
        "        return params\n",
        "\n",
        "    def shape_fn(inputs_shape):\n",
        "        shape = inputs_shape[:-1] + (n_features, )\n",
        "        return shape\n",
        "\n",
        "    return ModuleFn(apply_fn, shape_fn, init=init_fn)\n",
        "\n",
        "\n",
        "def flatten() -> ModuleFn:\n",
        "    def apply_fn(params, key, inputs, **kwargs):\n",
        "        return jnp.reshape(inputs, (inputs.shape[0], -1))\n",
        "\n",
        "    def shape_fn(inputs_shape):\n",
        "        return (inputs_shape[0], np.prod(inputs_shape[1:]))\n",
        "\n",
        "    return ModuleFn(apply_fn, shape_fn)\n",
        "\n",
        "\n",
        "def sequential(*modules: List[ModuleFn], ) -> ModuleFn:\n",
        "    def apply_fn(params, key, inputs, **kwargs):\n",
        "        outputs = inputs\n",
        "        if key is not None:\n",
        "            keys = jax.random.split(key, len(modules))\n",
        "        else:\n",
        "            keys = len(modules) * [None]\n",
        "        for idx, module in enumerate(modules):\n",
        "            outputs = module.apply(\n",
        "                params['layer_{}'.format(idx)],\n",
        "                keys[idx],\n",
        "                outputs,\n",
        "                **kwargs,\n",
        "            )\n",
        "        return outputs\n",
        "\n",
        "    def init_fn(key, inputs_shape):\n",
        "        params = dict(\n",
        "            ('layer_{}'.format(idx), None) for idx in range(len(modules)))\n",
        "        keys = jax.random.split(key, len(modules))\n",
        "        shape = inputs_shape\n",
        "        for idx, module in enumerate(modules):\n",
        "            if module.init is not None:\n",
        "                module_params = module.init(keys[idx], shape)\n",
        "                params['layer_{}'.format(idx)] = module_params\n",
        "            shape = module.shape(shape)\n",
        "        return params\n",
        "\n",
        "    def shape_fn(inputs_shape):\n",
        "        shape = inputs_shape\n",
        "        for module in modules:\n",
        "            shape = module.shape(shape)\n",
        "        return shape\n",
        "\n",
        "    return ModuleFn(apply_fn, shape_fn, init=init_fn)\n",
        "\n",
        "\n",
        "def _make_orthogonal_fn(rbs_idxs, size):\n",
        "    num_thetas = sum(map(len, rbs_idxs))\n",
        "    rbs_idxs = [list(map(list, rbs_idx)) for rbs_idx in rbs_idxs]\n",
        "    len_idxs = np.cumsum([0] + list(map(len, rbs_idxs)))\n",
        "\n",
        "    def _get_rbs_unitary(theta):\n",
        "        cos_theta, sin_theta = jnp.cos(theta), jnp.sin(theta)\n",
        "        unitary = jnp.array([\n",
        "            [cos_theta, -sin_theta],\n",
        "            [sin_theta, cos_theta],\n",
        "        ])\n",
        "        unitary = unitary.transpose(*[*range(2, unitary.ndim), 0, 1])\n",
        "        return unitary\n",
        "\n",
        "    def _get_rbs_unitary_grad(theta):\n",
        "        cos_theta, sin_theta = jnp.cos(theta), jnp.sin(theta)\n",
        "        unitary = jnp.array([\n",
        "            [-sin_theta, -cos_theta],\n",
        "            [cos_theta, -sin_theta],\n",
        "        ])\n",
        "        unitary = unitary.transpose(*[*range(2, unitary.ndim), 0, 1])\n",
        "        return unitary\n",
        "\n",
        "    @jax.custom_jvp\n",
        "    def _get_parallel_rbs_unitary(thetas):\n",
        "        unitaries = []\n",
        "        for i, idxs in enumerate(rbs_idxs):\n",
        "            idxs = sum(idxs, [])\n",
        "            sub_thetas = thetas[len_idxs[i]:len_idxs[i + 1]]\n",
        "            rbs_blocks = _get_rbs_unitary(sub_thetas)\n",
        "            eye_block = jnp.eye(size - len(idxs), dtype=thetas.dtype)\n",
        "            permutation = idxs + [i for i in range(size) if i not in idxs]\n",
        "            permutation = np.argsort(permutation)\n",
        "            unitary = jax.scipy.linalg.block_diag(*rbs_blocks, eye_block)\n",
        "            unitary = unitary[permutation][:, permutation]\n",
        "            unitaries.append(unitary)\n",
        "        unitaries = jnp.stack(unitaries)\n",
        "        return unitaries\n",
        "\n",
        "    @_get_parallel_rbs_unitary.defjvp\n",
        "    def get_parallel_rbs_unitary_jvp(primals, tangents):\n",
        "        thetas, = primals\n",
        "        thetas_dot, = tangents\n",
        "        unitaries = []\n",
        "        unitaries_dot = []\n",
        "        for i, idxs in enumerate(rbs_idxs):\n",
        "            idxs = sum(idxs, [])\n",
        "            sub_thetas = thetas[len_idxs[i]:len_idxs[i + 1]]\n",
        "            sub_thetas_dot = thetas_dot[len_idxs[i]:len_idxs[i + 1]]\n",
        "            rbs_blocks = _get_rbs_unitary(sub_thetas)\n",
        "            rbs_blocks_grad = _get_rbs_unitary_grad(sub_thetas)\n",
        "            rbs_blocks_dot = sub_thetas_dot[..., None, None] * rbs_blocks_grad\n",
        "            eye_block = jnp.eye(size - len(idxs), dtype=thetas.dtype)\n",
        "            zero_block = jnp.zeros_like(eye_block)\n",
        "            permutation = idxs + [i for i in range(size) if i not in idxs]\n",
        "            permutation = np.argsort(permutation)\n",
        "            unitary = jax.scipy.linalg.block_diag(*rbs_blocks, eye_block)\n",
        "            unitary_dot = jax.scipy.linalg.block_diag(*rbs_blocks_dot,\n",
        "                                                      zero_block)\n",
        "            unitary = unitary[permutation][:, permutation]\n",
        "            unitary_dot = unitary_dot[permutation][:, permutation]\n",
        "            unitaries.append(unitary)\n",
        "            unitaries_dot.append(unitary_dot)\n",
        "        primal_out = jnp.stack(unitaries)\n",
        "        tangent_out = jnp.stack(unitaries_dot)\n",
        "        return primal_out, tangent_out\n",
        "\n",
        "    def orthogonal_fn(thetas, precision=None):\n",
        "        assert thetas.shape[0] == num_thetas, \"Wrong number of thetas.\"\n",
        "        unitaries = _get_parallel_rbs_unitary(thetas)\n",
        "        unitary = jnp.linalg.multi_dot(unitaries[::-1], precision=precision)\n",
        "        return unitary\n",
        "\n",
        "    return orthogonal_fn\n",
        "\n",
        "\n",
        "def _get_pyramid_idxs(num_inputs, num_outputs):\n",
        "    num_max = max(num_inputs, num_outputs)\n",
        "    num_min = min(num_inputs, num_outputs)\n",
        "    if num_max == num_min:\n",
        "        num_min -= 1\n",
        "    end_idxs = np.concatenate(\n",
        "        [np.arange(1, num_max - 1), num_max - np.arange(1, num_min + 1)])\n",
        "    start_idxs = np.concatenate([\n",
        "        np.arange(end_idxs.shape[0] + num_min - num_max) % 2,\n",
        "        np.arange(num_max - num_min)\n",
        "    ])\n",
        "    if num_inputs < num_outputs:\n",
        "        start_idxs = start_idxs[::-1]\n",
        "        end_idxs = end_idxs[::-1]\n",
        "    rbs_idxs = [\n",
        "        np.arange(start_idxs[i], end_idxs[i] + 1).reshape(-1, 2)\n",
        "        for i in range(len(start_idxs))\n",
        "    ]\n",
        "    return rbs_idxs\n",
        "\n",
        "\n",
        "def _get_butterfly_idxs(num_inputs, num_outputs):\n",
        "    def _get_butterfly_idxs(n):\n",
        "        if n == 2:\n",
        "            return np.array([[[0, 1]]])\n",
        "        else:\n",
        "            rbs_idxs = _get_butterfly_idxs(n // 2)\n",
        "            first = np.concatenate([rbs_idxs, rbs_idxs + n // 2], 1)\n",
        "            last = np.arange(n).reshape(1, 2, n // 2).transpose(0, 2, 1)\n",
        "            rbs_idxs = np.concatenate([first, last], 0)\n",
        "            return rbs_idxs\n",
        "\n",
        "    circuit_dim = int(2**np.ceil(np.log2(max(num_inputs, num_outputs))))\n",
        "    rbs_idxs = _get_butterfly_idxs(circuit_dim)\n",
        "    if num_inputs < num_outputs:\n",
        "        rbs_idxs = rbs_idxs[::-1]\n",
        "    return rbs_idxs\n",
        "\n",
        "\n",
        "def _get_triangle_idxs(num_inputs, num_outputs):\n",
        "    num_max = max(num_inputs, num_outputs)\n",
        "    num_min = min(num_inputs, num_outputs)\n",
        "    rbs_idxs = [[(i, i + 1)] for i in range(num_max - 1)\n",
        "                ] + [[(num_max - num_min + i, num_max - num_min + i + 1)]\n",
        "                     for i in range(num_min - 1 - 1)][::-1]\n",
        "    if num_inputs < num_outputs:\n",
        "        rbs_idxs = rbs_idxs[::-1]\n",
        "    return rbs_idxs\n",
        "\n",
        "\n",
        "def _get_iks_idxs(num_inputs, num_outputs):\n",
        "    num_max = max(num_inputs, num_outputs)\n",
        "    num_min = min(num_inputs, num_outputs)\n",
        "    rbs_idxs_down = [[(i, i + 1)] for i in range(num_max - 1)]\n",
        "    rbs_idxs_up = [[(num_max - num_min + i, num_max - num_min + i + 1)]\n",
        "                   for i in range(num_min - 1)][::-1]\n",
        "    rbs_idxs = [\n",
        "        (m + n if m != n else m) for m, n in zip(rbs_idxs_down, rbs_idxs_up)\n",
        "    ] + rbs_idxs_down[num_min - 1:]\n",
        "    if num_inputs < num_outputs:\n",
        "        rbs_idxs = rbs_idxs[::-1]\n",
        "    return rbs_idxs\n",
        "\n",
        "def _multi_kron(arrays, order, i, j):\n",
        "    if i == j:\n",
        "        return arrays[i]\n",
        "    else:\n",
        "        return jnp.kron(_multi_kron(arrays, order, i, order[i, j]),\n",
        "                        _multi_kron(arrays, order, order[i, j] + 1, j))\n",
        "\n",
        "\n",
        "def _tensordot_unitary(unitaries):\n",
        "    from jax._src.third_party.numpy.linalg import _multi_dot_matrix_chain_order\n",
        "    if len(unitaries) == 1:\n",
        "        unitary = unitaries[0]\n",
        "    elif len(unitaries) == 2:\n",
        "        unitary = jnp.kron(unitaries[0], unitaries[1])\n",
        "    else:\n",
        "        order = _multi_dot_matrix_chain_order(unitaries)\n",
        "        unitary = _multi_kron(unitaries, order, 0, len(unitaries) - 1)\n",
        "    return unitary\n",
        "\n",
        "def _make_general_orthogonal_fn(rbs_idxs, size):\n",
        "    num_thetas = sum(map(len, rbs_idxs))\n",
        "    rbs_idxs = [list(map(list, rbs_idx)) for rbs_idx in rbs_idxs]\n",
        "    len_idxs = np.cumsum([0] + list(map(len, rbs_idxs)))\n",
        "\n",
        "    def _get_rbs_unitary(theta):\n",
        "        \"\"\" Returns the unitary matrix for a single RBS gate. \"\"\"\n",
        "        cos_t, sin_t = jnp.cos(theta), jnp.sin(theta)\n",
        "        zeros = jnp.zeros_like(cos_t)\n",
        "        ones = jnp.ones_like(cos_t)\n",
        "        unitary = jnp.array([\n",
        "            [ones, zeros, zeros, zeros],\n",
        "            [zeros, cos_t, -sin_t, zeros],\n",
        "            [zeros, sin_t, cos_t, zeros],\n",
        "            [zeros, zeros, zeros, ones],\n",
        "        ])\n",
        "        unitary = unitary.transpose(*[*range(2, unitary.ndim), 0, 1])\n",
        "        return unitary\n",
        "\n",
        "    def _get_parallel_rbs_unitary(thetas):\n",
        "        \"\"\" Returns the unitary matrix for parallel RBS gates. \"\"\"\n",
        "        unitaries = []\n",
        "        num_qubits = size\n",
        "        map_qubits = [[0, 2**q] for q in range(num_qubits)]\n",
        "        for i, idxs in enumerate(rbs_idxs):\n",
        "            idxs = sum(idxs, [])\n",
        "            sub_thetas = thetas[len_idxs[i]:len_idxs[i + 1]]\n",
        "            rbs_blocks = _get_rbs_unitary(sub_thetas)\n",
        "            eye_block = jnp.eye(2**(size - len(idxs)), dtype=thetas.dtype)\n",
        "            unitary = _tensordot_unitary([*rbs_blocks, eye_block])\n",
        "            unitary_qubits = idxs + [\n",
        "                q for q in range(num_qubits) if q not in idxs\n",
        "            ]\n",
        "            permutation = np.argsort([\n",
        "                sum(binary)\n",
        "                for binary in itertools.product(*(map_qubits[q]\n",
        "                                                  for q in unitary_qubits))\n",
        "            ])\n",
        "            unitary = unitary[permutation][:, permutation]\n",
        "            unitaries.append(unitary)\n",
        "        unitaries = jnp.stack(unitaries)\n",
        "\n",
        "        return unitaries\n",
        "\n",
        "    def orthogonal_fn(thetas, precision=None):\n",
        "        \"\"\" Returns the unitary matrix for a sequence of parallel RBS gates. \"\"\"\n",
        "        assert thetas.shape[0] == num_thetas, \"Wrong number of thetas.\"\n",
        "        unitaries = _get_parallel_rbs_unitary(thetas)\n",
        "        unitary = jnp.linalg.multi_dot(unitaries[::-1], precision=precision)\n",
        "        return unitary\n",
        "\n",
        "    return orthogonal_fn\n",
        "    \n",
        "\n",
        "def rbs_fn(num_qubits):\n",
        "  rbs_idxs = _get_butterfly_idxs(num_qubits,num_qubits)\n",
        "  rbs_idxs = [list(map(list, rbs_idx)) for rbs_idx in rbs_idxs]\n",
        "  num_params = len(sum(rbs_idxs, []))\n",
        "  return rbs_idxs, num_params"
      ],
      "metadata": {
        "id": "f_TBfvcjT-67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "nFk4qob9T_lI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDGmnkd-Syuf"
      },
      "outputs": [],
      "source": [
        "import haiku as hk \n",
        "from functools import partial\n",
        "def circuit_v0(seq_jumps):\n",
        "    num_days = seq_jumps.shape[-2]\n",
        "    \n",
        "    @jax.vmap \n",
        "    def encode(seq_jumps):\n",
        "        num_days, num_jumps = seq_jumps.shape\n",
        "        encodings = []\n",
        "        for time_step in range(num_days):\n",
        "            future_qubits = (num_days - time_step) * num_jumps\n",
        "            future = 1/np.sqrt(2**future_qubits) * jnp.ones((2**future_qubits,))\n",
        "            if time_step == 0:\n",
        "                encoding = future\n",
        "            else:\n",
        "                aux = seq_jumps[time_step].reshape(-1)\n",
        "                aux = jnp.concatenate((1-aux,aux),0)\n",
        "                if time_step ==1:\n",
        "                    past = aux \n",
        "                else:\n",
        "                    past = jnp.kron(past, aux)\n",
        "                encoding = jnp.kron(past, future)\n",
        "            encoding = jnp.kron(encoding, jnp.array([0.,1.,0.,0.]))\n",
        "            encodings.append(encoding)\n",
        "        encodings = jnp.stack(encodings,0)\n",
        "        return encodings\n",
        "    \n",
        "    def apply(seq_encodings):\n",
        "        rbs_idxs, num_params = rbs_fn(num_days+2)\n",
        "        seq_thetas = hk.get_parameter(\"thetas\", \n",
        "                                    shape=[num_days,num_params],\n",
        "                                    dtype=jnp.float32,\n",
        "                                    init=hk.initializers.RandomNormal(stddev=1.0/np.sqrt(len(rbs_idxs)), mean=0.0))\n",
        "        orthogonal_fn = _make_general_orthogonal_fn(rbs_idxs=rbs_idxs,size=num_days+2)\n",
        "        seq_unitaries = jax.vmap(orthogonal_fn)(seq_thetas)\n",
        "        seq_results = jnp.einsum(\"...tij,...tj->...ti\",seq_unitaries,seq_encodings)\n",
        "        seq_probs = jnp.abs(seq_results)**2\n",
        "        return seq_probs \n",
        "\n",
        "    supports = []\n",
        "    bits = list(itertools.product(*((num_days+2)*[(0,1)]))) \n",
        "    for time_step in range(num_days):\n",
        "        observables = []\n",
        "        for weight in range(time_step+1):\n",
        "            observable = jnp.zeros((2**(num_days+2),),dtype=jnp.float32)\n",
        "            for subspace in range(weight+1, (num_days-time_step+weight+1)+1):\n",
        "                permutations = [bit for bit in bits if sum(bit)==subspace]\n",
        "                idxs = jnp.array(permutations) @ 2**jnp.arange(num_days+2)\n",
        "                values = jnp.arange(len(idxs))/(len(idxs) - 1) \n",
        "                observable = observable.at[idxs].set(values)\n",
        "            observables.append(observable)\n",
        "        observables = jnp.stack(observables)\n",
        "        supports.append(observables)\n",
        "        \n",
        "    @jax.vmap\n",
        "    def project(seq_jumps):\n",
        "        seq_obs = []\n",
        "        for time_step in range(num_days):\n",
        "            if time_step == 0:\n",
        "                observable = supports[0]\n",
        "            else:\n",
        "                idx = seq_jumps[:time_step,0].sum()\n",
        "                observable = jax.lax.dynamic_index_in_dim(supports[time_step],jnp.int32(idx),0)\n",
        "            seq_obs.append(observable)\n",
        "        seq_obs = jnp.concatenate(seq_obs)\n",
        "        return seq_obs\n",
        "    \n",
        "    seq_encodings = encode(seq_jumps)\n",
        "    seq_probs = apply(seq_encodings)\n",
        "    seq_obs = project(seq_jumps)\n",
        "    seq_vals = jnp.einsum(\"...t,...t->...\",seq_probs,seq_obs)\n",
        "    return seq_vals"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import sys\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "from absl import app, flags\n",
        "from tqdm import trange\n",
        "from scipy import stats\n",
        "import itertools \n",
        "\n",
        "def jumps_to_prices(jumps):\n",
        "    jumps = jumps.reshape(jumps.shape[0], FLAGS.num_days * FLAGS.num_jumps)\n",
        "    brownian = (jumps - FLAGS.bernoulli_p)  # mean 0\n",
        "    brownian /= np.sqrt(FLAGS.bernoulli_p *\n",
        "                        (1 - FLAGS.bernoulli_p))  # variance 1\n",
        "    brownian = jnp.cumsum(brownian, axis=1)  # cumulative sum\n",
        "    brownian /= np.sqrt(FLAGS.num_jumps * FLAGS.num_trading_days )  # standardize\n",
        "    brownian = brownian[:, FLAGS.num_jumps * np.arange(FLAGS.num_days)]\n",
        "    t = jnp.arange(1, 1 + FLAGS.num_days) / FLAGS.num_trading_days\n",
        "    log_prices = (FLAGS.mu - FLAGS.sigma**2/2) * t +  FLAGS.sigma * brownian\n",
        "    prices = jnp.exp(log_prices)\n",
        "    prices = jnp.concatenate((jnp.ones((prices.shape[0], 1)), prices), axis=1)\n",
        "    prices *= FLAGS.initial_price\n",
        "    return prices[..., None]\n",
        "\n",
        "def prices_to_BSdeltas(seq_prices):\n",
        "  seq_prices = seq_prices[:,:-1]\n",
        "  T = jnp.arange(1, FLAGS.num_days+1) / FLAGS.num_trading_days\n",
        "  T = jnp.repeat(jnp.flip(T[None,:]), seq_prices.shape[0],0)\n",
        "  d1 = jnp.divide(jnp.log(seq_prices[...,0]/FLAGS.strike_price)+ (FLAGS.mu + 0.5 * FLAGS.sigma **2)* T, FLAGS.sigma * jnp.sqrt(T))\n",
        "  seq_bs_deltas = (stats.norm.cdf(d1, 0.0, 1.0))[...,None]\n",
        "  seq_deltas = seq_bs_deltas\n",
        "  seq_actions = jnp.concatenate(\n",
        "            [seq_deltas[:, [0]], seq_deltas[:, 1:] - seq_deltas[:, :-1]],\n",
        "            axis=1) \n",
        "  return seq_deltas, seq_actions\n",
        "\n",
        "def build_actor_fn():\n",
        "    def actor_fn(seq_jumps):\n",
        "        seq_deltas = []\n",
        "        seq_prices = jumps_to_prices(seq_jumps)\n",
        "        for time_step in range(FLAGS.num_days):\n",
        "            features = seq_prices[:, :time_step]\n",
        "            features = features.reshape(features.shape[0], -1)\n",
        "            net = hk.nets.MLP(FLAGS.hidden_layers*[ FLAGS.hidden_units]+ [1])\n",
        "            deltas = 0.5 * (1 + jax.nn.tanh(net(features)))\n",
        "            seq_deltas.append(deltas)\n",
        "        seq_deltas = jnp.stack(seq_deltas, axis=1)\n",
        "        seq_actions = jnp.concatenate(\n",
        "            [seq_deltas[:, [0]], seq_deltas[:, 1:] - seq_deltas[:, :-1]],\n",
        "            axis=1)\n",
        "        return seq_deltas, seq_actions\n",
        "\n",
        "    return actor_fn\n",
        "\n",
        "def build_actor_quantum_fn():\n",
        "    def actor_fn(seq_jumps):\n",
        "        seq_deltas = circuit_v0(seq_jumps)\n",
        "        seq_deltas = seq_deltas[...,None]\n",
        "        seq_actions = jnp.concatenate(\n",
        "            [seq_deltas[:, [0]], seq_deltas[:, 1:] - seq_deltas[:, :-1]],\n",
        "            axis=1)\n",
        "        return seq_deltas, seq_actions\n",
        "\n",
        "    return actor_fn\n",
        "\n",
        "def build_critic_fn(activation_fn=None):\n",
        "    def critic_fn(seq_jumps, seq_deltas):\n",
        "        seq_values = []\n",
        "        seq_prices = jumps_to_prices(seq_jumps)\n",
        "        for time_step in range(FLAGS.num_days):\n",
        "            features = seq_prices[:, :time_step]\n",
        "            features = features.reshape(features.shape[0], -1)\n",
        "            net = hk.nets.MLP([FLAGS.hidden_units, FLAGS.hidden_units, 1])\n",
        "            if activation_fn:\n",
        "              values = activation_fn(net(features))\n",
        "            else:\n",
        "              values = net(features)\n",
        "            seq_values.append(values)\n",
        "        seq_values = jnp.stack(seq_values, axis=1)\n",
        "        return seq_values\n",
        "\n",
        "    return critic_fn\n",
        "\n",
        "def build_critic_quantum_fn():\n",
        "    def critic_fn(seq_jumps, seq_deltas):\n",
        "      seq_values = circuit_v0(seq_jumps)\n",
        "      seq_values = seq_values[...,None]\n",
        "      return seq_values\n",
        "    return critic_fn\n"
      ],
      "metadata": {
        "id": "plGCLQYlS6cP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dh_vanilla(model):\n",
        "  np_random = np.random.RandomState(seed=FLAGS.seed)\n",
        "  rng_key = hk.PRNGSequence(np_random.randint(0, sys.maxsize + 1))\n",
        "  if model == 'classical':\n",
        "      actor_fn = build_actor_fn()\n",
        "  elif model == 'quantum':\n",
        "      actor_fn = build_actor_quantum_fn()\n",
        "  actor_net = hk.transform(actor_fn)\n",
        "  actor_params = actor_net.init(\n",
        "      next(rng_key), jnp.ones((1, FLAGS.num_days, FLAGS.num_jumps)))\n",
        "  actor_opt = optax.radam(FLAGS.actor_lr)\n",
        "  actor_state = actor_opt.init(actor_params)\n",
        "  def actor_loss_fn(actor_params, key, seq_jumps):\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, key,\n",
        "                                                seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      seq_returns = jnp.sum(seq_rewards[:, 1:], axis=1)\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = -jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_returns += final_rewards\n",
        "      loss = -(seq_rewards[0, 0] - jnp.log(\n",
        "          1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda * seq_returns).mean()))\n",
        "      return loss.mean()\n",
        "\n",
        "  @jax.jit\n",
        "  def actor_train_step(actor_params, actor_state, key, seq_jumps):\n",
        "      loss, grad = jax.value_and_grad(actor_loss_fn)(actor_params, key,\n",
        "                                                      seq_jumps)\n",
        "      updates, actor_state = actor_opt.update(grad, actor_state,\n",
        "                                              actor_params)\n",
        "      actor_params = optax.apply_updates(actor_params, updates)\n",
        "      return actor_params, actor_state, loss\n",
        "  def eval_step(actor_params, key, seq_jumps):\n",
        "        shape = (FLAGS.num_eval_episodes, FLAGS.num_days, FLAGS.num_jumps)\n",
        "        seq_jumps = jax.random.bernoulli(jax.random.PRNGKey(123),\n",
        "                                        shape=shape,\n",
        "                                        p=FLAGS.bernoulli_p)\n",
        "        seq_prices = jumps_to_prices(seq_jumps)\n",
        "        seq_deltas, seq_actions = actor_net.apply(actor_params, key, seq_jumps)\n",
        "        seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                        seq_actions) * seq_prices[:, :-1]\n",
        "        seq_returns = jnp.sum(seq_rewards[:, 1:], axis=1)\n",
        "        final_actions = -seq_deltas[:, -1]\n",
        "        final_rewards = -jnp.maximum(\n",
        "            seq_prices[:, -1] - FLAGS.strike_price,\n",
        "            0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                  final_actions) * seq_prices[:, -1]\n",
        "        seq_returns += final_rewards\n",
        "        eval_returns = seq_rewards[0, 0] - jnp.log(\n",
        "            1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda * seq_returns).mean())\n",
        "        return eval_returns\n",
        "  def eval_BS(seq_jumps):\n",
        "    seq_prices = jumps_to_prices(seq_jumps)\n",
        "    seq_deltas,seq_actions = prices_to_BSdeltas(seq_prices)\n",
        "    seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                        seq_actions) * seq_prices[:, :-1]\n",
        "    seq_returns = jnp.sum(seq_rewards[:, 1:], axis=1)\n",
        "    final_actions = -seq_deltas[:, -1]\n",
        "    final_rewards = jnp.maximum(\n",
        "        seq_prices[:, -1] - FLAGS.strike_price,\n",
        "        0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "              final_actions) * seq_prices[:, -1]\n",
        "    seq_returns += final_rewards\n",
        "    eval_returns = seq_rewards[0, 0] - jnp.log(\n",
        "        1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda * seq_returns).mean())\n",
        "    return eval_returns\n",
        "\n",
        "  plot_info = {}\n",
        "  plot_info['actor_loss'] = []\n",
        "  plot_info['utility'] = []\n",
        "  plot_info['BS utility'] = []\n",
        "  with trange(FLAGS.num_train_steps) as t:\n",
        "      for train_step in t:\n",
        "          # Train Actor\n",
        "          shape = (FLAGS.num_actor_episodes, FLAGS.num_days, FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          actor_params, actor_state, actor_loss = actor_train_step(\n",
        "              actor_params, actor_state, next(rng_key), seq_jumps)\n",
        "          # Evaluate\n",
        "          shape = (FLAGS.num_eval_episodes, FLAGS.num_days, FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          eval_returns = eval_step(actor_params, next(rng_key), seq_jumps)\n",
        "          BS_returns = eval_BS(seq_jumps)\n",
        "          plot_info['actor_loss'].append(actor_loss)\n",
        "          plot_info['utility'].append(eval_returns.mean())\n",
        "          plot_info['BS utility'].append(BS_returns.mean())\n",
        "          t.set_postfix(utility=eval_returns.mean(),BS_utility=BS_returns.mean(),actor_loss=actor_loss)\n",
        "  return plot_info\n"
      ],
      "metadata": {
        "id": "sDUs4ZrWTCz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FLAGS = flags.FLAGS\n",
        "# Delete all existing attributes in flag before defining any new\n",
        "for name in list(flags.FLAGS): \n",
        "      delattr(flags.FLAGS,name)\n",
        "flags.DEFINE_integer(\"seed\", 42, \"Random seed.\")\n",
        "flags.DEFINE_integer(\"num_days\", 4, \"Number of days per episode.\")\n",
        "flags.DEFINE_integer(\"num_trading_days\", 251, \"Number of trading days in year.\")\n",
        "flags.DEFINE_integer(\"num_jumps\", 1, \"Number jumps per day.\")\n",
        "flags.DEFINE_float(\"bernoulli_p\", 0.5, \"Bernoulli p of Wiener process.\")\n",
        "flags.DEFINE_float(\"mu\", 0., \"Drift of Wiener process.\")\n",
        "flags.DEFINE_float(\"sigma\", 0.2, \"Volatility of Wiener process.\")\n",
        "flags.DEFINE_float(\"initial_price\", 100., \"Initial price.\")\n",
        "flags.DEFINE_float(\"strike_price\", 100., \"Strike price.\")\n",
        "flags.DEFINE_float(\"lamda\", 0.1, \"Risk-measure factor.\")\n",
        "flags.DEFINE_float(\"cost_eps\", 0., \"Cost epsilon.\")\n",
        "flags.DEFINE_integer(\"num_train_steps\", 500, \"Number of train steps.\")\n",
        "flags.DEFINE_integer(\"num_actor_episodes\", 16, \"Number of actor episodes.\")\n",
        "flags.DEFINE_integer(\"num_eval_episodes\", 16, \"Number of eval episodes.\")\n",
        "flags.DEFINE_float(\"actor_lr\", 1, \"Actor learning rate.\")\n",
        "flags.DEFINE_integer(\"hidden_units\", 16, \"Number of hidden units.\")\n",
        "flags.DEFINE_integer(\"hidden_layers\", 2, \"Number of hidden layers.\")\n",
        "dh_quantum_vanilla_4_info = dh_vanilla(model='quantum')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v24BDYpTvv1",
        "outputId": "661ee02a-eadb-4ddc-f63d-794a1c485fcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [04:35<00:00,  1.81it/s, BS_utility=-47.854233, actor_loss=4.77028, utility=-4.717611]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dh_classical_vanilla_4_info['utility'][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsbKeOeMYwjb",
        "outputId": "e3d59ad2-4e21-4471-f539-6409686e7bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(-2.4091146, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('4 days no transaction costs')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Utility')\n",
        "plt.plot(dh_classical_vanilla_4_info['utility'], label='classical')\n",
        "plt.plot(dh_quantum_vanilla_4_info['utility'],color='green', label='quantum')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.savefig('policy_search_4.png', dpi=300)"
      ],
      "metadata": {
        "id": "QU2Xf-pdeSBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('6 days no transaction costs')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Utility')\n",
        "plt.plot(dh_classical_vanilla_6_info['utility'], label='classical')\n",
        "plt.plot(dh_quantum_vanilla_6_info['utility'],color='green', label='quantum')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.savefig('policy_search_6.png', dpi=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "jUpEYU6JSeu9",
        "outputId": "b2bbe2af-0538-48bb-93e2-04950aeb26b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FLAGS = flags.FLAGS\n",
        "# Delete all existing attributes in flag before defining any new\n",
        "for name in list(flags.FLAGS): \n",
        "      delattr(flags.FLAGS,name)\n",
        "flags.DEFINE_integer(\"seed\", 42, \"Random seed.\")\n",
        "flags.DEFINE_integer(\"num_days\", 6, \"Number of days per episode.\")\n",
        "flags.DEFINE_integer(\"num_trading_days\", 251, \"Number of trading days in year.\")\n",
        "flags.DEFINE_integer(\"num_jumps\", 1, \"Number jumps per day.\")\n",
        "flags.DEFINE_float(\"bernoulli_p\", 0.5, \"Bernoulli p of Wiener process.\")\n",
        "flags.DEFINE_float(\"mu\", 0., \"Drift of Wiener process.\")\n",
        "flags.DEFINE_float(\"sigma\", 0.2, \"Volatility of Wiener process.\")\n",
        "flags.DEFINE_float(\"initial_price\", 100., \"Initial price.\")\n",
        "flags.DEFINE_float(\"strike_price\", 100., \"Strike price.\")\n",
        "flags.DEFINE_float(\"lamda\", 0.1, \"Risk-measure factor.\")\n",
        "flags.DEFINE_float(\"cost_eps\", 0., \"Cost epsilon.\")\n",
        "flags.DEFINE_integer(\"num_train_steps\", 500, \"Number of train steps.\")\n",
        "flags.DEFINE_integer(\"num_actor_episodes\", 1, \"Number of actor episodes.\")\n",
        "flags.DEFINE_integer(\"num_eval_episodes\", 16, \"Number of eval episodes.\")\n",
        "flags.DEFINE_float(\"actor_lr\", 1, \"Actor learning rate.\")\n",
        "flags.DEFINE_integer(\"hidden_units\", 16, \"Number of hidden units.\")\n",
        "flags.DEFINE_integer(\"hidden_layers\", 2, \"Number of hidden layers.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI9iUhjIKt2u",
        "outputId": "6367279a-153b-4cef-ae06-862b70bbd875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<absl.flags._flagvalues.FlagHolder at 0x7f84423b0a90>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rng_key = hk.PRNGSequence(np_random.randint(0, sys.maxsize + 1))\n",
        "shape = (FLAGS.num_actor_episodes, FLAGS.num_days, FLAGS.num_jumps)\n",
        "seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                shape=shape,\n",
        "                                p=0.)"
      ],
      "metadata": {
        "id": "oUqNN6g7wdBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_jumps.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqAjvBFBwc2h",
        "outputId": "7504139a-ceb8-4475-f5c9-905974740ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 6, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_jumps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ac-7eSHAw28Z",
        "outputId": "dbc18731-44fb-4b95-b0b3-ad91391d6b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[ True],\n",
              "              [ True],\n",
              "              [ True],\n",
              "              [ True],\n",
              "              [ True],\n",
              "              [ True]]], dtype=bool)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_prices_max = jumps_to_prices(seq_jumps)"
      ],
      "metadata": {
        "id": "Jjfi76IZxArK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_prices_max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iw1AS2oHxF2R",
        "outputId": "a0f5ccad-266c-4542-8fe8-1cde42514895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[100.      ],\n",
              "              [101.26232 ],\n",
              "              [102.54057 ],\n",
              "              [103.83498 ],\n",
              "              [105.145706],\n",
              "              [106.472984],\n",
              "              [107.81701 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_prices_min = jumps_to_prices(seq_jumps)"
      ],
      "metadata": {
        "id": "9brrxkJzxMzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_prices_min"
      ],
      "metadata": {
        "id": "HnX0Ul9bxQnU",
        "outputId": "0b5c9343-8783-4e1e-c707-44a9175dee75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[100.      ],\n",
              "              [ 98.73768 ],\n",
              "              [ 97.49129 ],\n",
              "              [ 96.260635],\n",
              "              [ 95.04552 ],\n",
              "              [ 93.84573 ],\n",
              "              [ 92.6611  ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prices_max = seq_prices_max.reshape(-1)\n",
        "prices_min = seq_prices_min.reshape(-1)"
      ],
      "metadata": {
        "id": "ske8wCcRKM-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prices_max - FLAGS.strike_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhynpZNpLMcc",
        "outputId": "bd357355-0c20-458e-82bb-203f2105ae00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([0.       , 1.2623215, 2.5405731, 3.8349762, 5.145706 ,\n",
              "             6.4729843, 7.817009 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prices_min - FLAGS.strike_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59pvtHXxLSV4",
        "outputId": "af3cb103-470a-4f7f-bf96-4884dcaa7439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([ 0.       , -1.2623215, -2.5087128, -3.7393646, -4.954483 ,\n",
              "             -6.1542664, -7.3388977], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_payoffs = -jnp.maximum(prices_max-FLAGS.strike_price,0)\n",
        "max_payoffs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wujx7mtXLUN3",
        "outputId": "d06d66be-8af3-40df-8792-de2c4464eb5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([-0.       , -1.2623215, -2.5405731, -3.8349762, -5.145706 ,\n",
              "             -6.4729843, -7.817009 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values_max = (2*(prices_max - FLAGS.strike_price))[::-1][:-1]\n",
        "values_max"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d2NuiO0MGW7",
        "outputId": "a1c66ed6-14b8-49c8-ffbc-626c39be09e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([15.634018 , 12.945969 , 10.291412 ,  7.6699524,  5.0811462,\n",
              "              2.524643 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values_min = (2*(prices_min - FLAGS.strike_price) + max_payoffs)[::-1][:-1]\n",
        "values_min"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-6XO8pPMZbX",
        "outputId": "61549c9d-58fd-4255-d45c-1e25447b6f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([-22.494804 , -18.781517 , -15.054672 , -11.313705 ,\n",
              "              -7.5579987,  -3.7869644], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values_range = jnp.stack( (values_min, values_max), axis=-1 )\n",
        "values_range"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-RbTbTpMsRO",
        "outputId": "bd03f916-1be3-47e0-e7c3-26442c145022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[-22.494804 ,  15.634018 ],\n",
              "             [-18.781517 ,  12.945969 ],\n",
              "             [-15.054672 ,  10.291412 ],\n",
              "             [-11.313705 ,   7.6699524],\n",
              "             [ -7.5579987,   5.0811462],\n",
              "             [ -3.7869644,   2.524643 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (1, FLAGS.num_days, FLAGS.num_jumps)\n",
        "seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                shape=shape,\n",
        "                                p=1.)"
      ],
      "metadata": {
        "id": "HFQB1-2mNcCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7ENDVGyNdef",
        "outputId": "248e9c51-a57d-4f47-abfc-1d52f9511a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[False],\n",
              "              [False],\n",
              "              [False],\n",
              "              [False],\n",
              "              [False],\n",
              "              [False]]], dtype=bool)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def values_range():\n",
        "  shape = (1, FLAGS.num_days, FLAGS.num_jumps)\n",
        "  seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                  shape=shape,\n",
        "                                  p=1.)\n",
        "  prices_max = jumps_to_prices(seq_jumps).reshape(-1)\n",
        "  prices_min = jumps_to_prices(~seq_jumps).reshape(-1)\n",
        "  payoffs_min = -jnp.maximum(prices_max-FLAGS.strike_price,0)\n",
        "  values_max =  (2*(prices_max - FLAGS.strike_price))[::-1][:-1]\n",
        "  values_min = (2*(prices_min - FLAGS.strike_price) + payoffs_min)[::-1][:-1]\n",
        "  Gt_range = jnp.stack((values_max, values_min), axis=-1)\n",
        "  values_range = jnp.exp(-FLAGS.lamda*Gt_range)\n",
        "  return values_range\n",
        "values_range()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx7RWP9xNEbl",
        "outputId": "457cda6a-16e3-4bb4-edad-5eae0f8f9757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[0.20942244, 9.482808  ],\n",
              "             [0.2740083 , 6.541404  ],\n",
              "             [0.35731363, 4.506259  ],\n",
              "             [0.4644064 , 3.0999022 ],\n",
              "             [0.6016288 , 2.129314  ],\n",
              "             [0.77688396, 1.4603796 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dh_actor_critic_v0(critic_loss_version):\n",
        "  np_random = np.random.RandomState(seed=FLAGS.seed)\n",
        "  rng_key = hk.PRNGSequence(np_random.randint(0, sys.maxsize + 1))\n",
        "  actor_fn = build_actor_quantum_fn()\n",
        "  actor_net = hk.transform(actor_fn)\n",
        "  actor_params = actor_net.init(\n",
        "      next(rng_key), jnp.ones((1, FLAGS.num_days, FLAGS.num_jumps)))\n",
        "  actor_opt = optax.adamw(FLAGS.actor_lr)\n",
        "  actor_state = actor_opt.init(actor_params)\n",
        "  buffer = collections.deque(maxlen=FLAGS.num_buffer_episodes)\n",
        "  critic_fn = build_critic_quantum_fn()\n",
        "  critic_net = hk.transform(critic_fn)\n",
        "  critic_params = critic_net.init(\n",
        "      next(rng_key), jnp.ones((1, FLAGS.num_days, FLAGS.num_jumps)),\n",
        "      jnp.ones((1, FLAGS.num_days, 1)))\n",
        "  critic_opt = optax.adam(FLAGS.critic_lr)\n",
        "  critic_state = critic_opt.init(critic_params)\n",
        "\n",
        "  def critic_loss_fn(critic_params, key, seq_jumps,\n",
        "                      seq_deltas, seq_rewards, seq_returns):\n",
        "      critic_key, target_key = jax.random.split(key, 2)\n",
        "      seq_values = critic_net.apply(critic_params, critic_key, seq_jumps,\n",
        "                                    seq_deltas)\n",
        "      seq_targets = seq_returns\n",
        "      if critic_loss_version==0:\n",
        "          loss = (jnp.exp(-FLAGS.lamda * seq_targets)\n",
        "          - seq_values)**2\n",
        "      elif critic_loss_version==1:\n",
        "           loss = 1 / FLAGS.lamda * jnp.exp(\n",
        "          -FLAGS.lamda * (seq_targets - seq_values)) - seq_values\n",
        "      return loss.mean()\n",
        "\n",
        "  @jax.jit\n",
        "  def critic_train_step(critic_params, critic_state, key,\n",
        "                        seq_jumps, seq_deltas, seq_rewards, seq_returns):\n",
        "      loss, grad = jax.value_and_grad(critic_loss_fn)(\n",
        "          critic_params, key, seq_jumps, seq_deltas,\n",
        "          seq_rewards, seq_returns)\n",
        "      updates, critic_state = critic_opt.update(grad, critic_state,\n",
        "                                                critic_params)\n",
        "      critic_new_params = optax.apply_updates(critic_params, updates)\n",
        "      critic_params = jax.tree_util.tree_map(\n",
        "          lambda x, y: (1 - FLAGS.critic_tau) * x + FLAGS.critic_tau * y,\n",
        "          critic_new_params, critic_params)\n",
        "      return critic_params, critic_state, loss\n",
        "\n",
        "  def actor_loss_fn(actor_params, critic_params, key, seq_jumps):\n",
        "      critic_key, actor_key = jax.random.split(key, 2)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, actor_key,\n",
        "                                                seq_jumps)\n",
        "      seq_values = critic_net.apply(critic_params, critic_key, seq_jumps,\n",
        "                                    seq_deltas)\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_values = jnp.concatenate(\n",
        "          [seq_values[:, 1:], final_rewards[..., None]], axis=1)\n",
        "      # loss =  -(seq_rewards - jnp.log(\n",
        "      #     1 / FLAGS.lamda * seq_values))\n",
        "      # loss = 1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda *\n",
        "      #                                   (seq_rewards + seq_values))\n",
        "      loss  = -(seq_rewards[0, 0] - 1/FLAGS.lamda* jnp.log( seq_values))\n",
        "      return loss.mean()\n",
        "\n",
        "  @jax.jit\n",
        "  def actor_train_step(actor_params, critic_params, actor_state, key,\n",
        "                        seq_jumps):\n",
        "      loss, grad = jax.value_and_grad(actor_loss_fn)(actor_params,\n",
        "                                                      critic_params, key,\n",
        "                                                      seq_jumps)\n",
        "      updates, actor_state = actor_opt.update(grad, actor_state,\n",
        "                                              actor_params)\n",
        "      actor_params = optax.apply_updates(actor_params, updates)\n",
        "      return actor_params, actor_state, loss\n",
        "\n",
        "  @jax.jit\n",
        "  def rollout_step(actor_params, key, seq_jumps):\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, key,\n",
        "                                                seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_next_rewards = jnp.concatenate(\n",
        "          [seq_rewards[:, 1:], final_rewards[..., None]], axis=1)\n",
        "      seq_returns = jnp.cumsum(seq_next_rewards[:, ::-1],\n",
        "                                axis=-1)[:, ::-1]\n",
        "      return seq_deltas, seq_actions, seq_rewards, seq_returns\n",
        "  def eval_step(actor_params, key, seq_jumps):\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, key, seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      seq_returns = jnp.sum(seq_rewards[:, 1:], axis=1)\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_returns += final_rewards\n",
        "      eval_returns = seq_rewards[0, 0] - jnp.log(\n",
        "          1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda * seq_returns).mean())\n",
        "      return eval_returns\n",
        "  plot_info = {}\n",
        "  plot_info['utility'] = []\n",
        "  plot_info['actor_loss'] = []\n",
        "  plot_info['critic_loss'] = []\n",
        "  with trange(FLAGS.num_train_steps) as t:\n",
        "      for train_step in t:\n",
        "          # Rollout\n",
        "          shape = (FLAGS.num_rollout_episodes, FLAGS.num_days,\n",
        "                  FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          seq_deltas, seq_actions, seq_rewards, seq_returns = rollout_step(\n",
        "              actor_params, next(rng_key), seq_jumps)\n",
        "          for episode in range(FLAGS.num_rollout_episodes):\n",
        "              buffer.append(\n",
        "                  tuple(seq[episode] for seq in (seq_jumps, seq_deltas,\n",
        "                                                seq_rewards, seq_returns)))\n",
        "          # Train critic\n",
        "          critic_idxs = np_random.randint(0,\n",
        "                                          len(buffer),\n",
        "                                          size=FLAGS.num_critic_episodes)\n",
        "          critic_episodes = [buffer[idx] for idx in critic_idxs]\n",
        "          seq_jumps, seq_deltas, seq_rewards, seq_returns = (\n",
        "              jnp.asarray(seq) for seq in zip(*critic_episodes))\n",
        "          critic_params, critic_state, critic_loss = critic_train_step(\n",
        "              critic_params, critic_state, next(rng_key),\n",
        "              seq_jumps, seq_deltas, seq_rewards, seq_returns)\n",
        "\n",
        "          # Train actor\n",
        "          actor_idxs = np_random.randint(0,\n",
        "                                        len(buffer),\n",
        "                                        size=FLAGS.num_actor_episodes)\n",
        "          actor_episodes = [buffer[idx] for idx in actor_idxs]\n",
        "          seq_jumps, _, _, _ = (jnp.asarray(seq)\n",
        "                                for seq in zip(*actor_episodes))\n",
        "          actor_params, actor_state, actor_loss = actor_train_step(\n",
        "              actor_params, critic_params, actor_state, next(rng_key),\n",
        "              seq_jumps)\n",
        "\n",
        "          # Evaluate\n",
        "          shape = (FLAGS.num_eval_episodes, FLAGS.num_days, FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          eval_returns = eval_step(actor_params, next(rng_key), seq_jumps)\n",
        "          plot_info['utility'].append(eval_returns.mean())\n",
        "          plot_info['actor_loss'].append(actor_loss)\n",
        "          plot_info['critic_loss'].append(critic_loss)\n",
        "          t.set_postfix(utility=eval_returns.mean(), actor_loss=actor_loss,critic_loss=critic_loss)\n",
        "  return plot_info"
      ],
      "metadata": {
        "id": "o6tNy-jNffcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FLAGS = flags.FLAGS\n",
        "# Delete all existing attributes in flag before defining any new\n",
        "for name in list(flags.FLAGS): \n",
        "      delattr(flags.FLAGS,name)\n",
        "flags.DEFINE_integer(\"seed\", 42, \"Random seed.\")\n",
        "flags.DEFINE_integer(\"num_days\", 6, \"Number of days per episode.\")\n",
        "flags.DEFINE_integer(\"num_trading_days\", 251, \"Number of trading days in year.\")\n",
        "flags.DEFINE_integer(\"num_jumps\", 1, \"Number jumps per day.\")\n",
        "flags.DEFINE_float(\"bernoulli_p\", 0.5, \"Bernoulli p of Wiener process.\")\n",
        "flags.DEFINE_float(\"mu\", 0., \"Drift of Wiener process.\")\n",
        "flags.DEFINE_float(\"sigma\", 0.2, \"Volatility of Wiener process.\")\n",
        "flags.DEFINE_float(\"initial_price\", 100., \"Initial price.\")\n",
        "flags.DEFINE_float(\"strike_price\", 100., \"Strike price.\")\n",
        "flags.DEFINE_float(\"lamda\", 0.1, \"Risk-measure factor.\")\n",
        "flags.DEFINE_float(\"cost_eps\", 0., \"Cost epsilon.\")\n",
        "flags.DEFINE_integer(\"num_train_steps\", 4000, \"Number of train steps.\")\n",
        "flags.DEFINE_integer(\"num_actor_episodes\", 16, \"Number of actor episodes.\")\n",
        "flags.DEFINE_integer(\"num_eval_episodes\", 128, \"Number of eval episodes.\")\n",
        "flags.DEFINE_float(\"actor_lr\", 1E-3, \"Actor learning rate.\")\n",
        "flags.DEFINE_integer(\"hidden_units\", 16, \"Number of hidden units.\")\n",
        "\n",
        "flags.DEFINE_integer(\"num_buffer_episodes\", 64,\n",
        "                      \"Number of buffer episodes.\")\n",
        "flags.DEFINE_integer(\"num_critic_episodes\", 64,\n",
        "                      \"Number of critic episodes.\")\n",
        "flags.DEFINE_integer(\"num_rollout_episodes\", 64,\n",
        "                      \"Number of rollout episodes.\")\n",
        "flags.DEFINE_float(\"critic_lr\", 1E-4, \"Critic learning rate.\")\n",
        "flags.DEFINE_float(\"critic_tau\", 0.001, \"Critic target smoothing factor.\")\n",
        "FLAGS(sys.argv)\n",
        "actor_critic_quantum_info  = dh_actor_critic_v0(critic_loss_version=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "40Na7t2Gi7fc",
        "outputId": "936b9164-3489-4ebd-bfeb-bd4eba5cba48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 916/4000 [12:46<43:01,  1.19it/s, actor_loss=nan, critic_loss=nan, utility=nan]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-a3ff9a1b2f9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"critic_tau\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Critic target smoothing factor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mactor_critic_quantum_info\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdh_actor_critic_v0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_loss_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-55-dc9d232123a9>\u001b[0m in \u001b[0;36mdh_actor_critic_v0\u001b[0;34m(critic_loss_version)\u001b[0m\n\u001b[1;32m    135\u001b[0m           \u001b[0mcritic_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcritic_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m           seq_jumps, seq_deltas, seq_rewards, seq_returns = (\n\u001b[0;32m--> 137\u001b[0;31m               jnp.asarray(seq) for seq in zip(*critic_episodes))\n\u001b[0m\u001b[1;32m    138\u001b[0m           critic_params, critic_state, critic_loss = critic_train_step(\n\u001b[1;32m    139\u001b[0m               \u001b[0mcritic_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-dc9d232123a9>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    135\u001b[0m           \u001b[0mcritic_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcritic_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m           seq_jumps, seq_deltas, seq_rewards, seq_returns = (\n\u001b[0;32m--> 137\u001b[0;31m               jnp.asarray(seq) for seq in zip(*critic_episodes))\n\u001b[0m\u001b[1;32m    138\u001b[0m           critic_params, critic_state, critic_loss = critic_train_step(\n\u001b[1;32m    139\u001b[0m               \u001b[0mcritic_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m   1919\u001b[0m   \u001b[0mlax_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_user_dtype_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"asarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1921\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin)\u001b[0m\n\u001b[1;32m   1887\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype)\u001b[0m\n\u001b[1;32m   1633\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mshape0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"All input arrays must have the same shape.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m       \u001b[0mnew_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    892\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"expand_dims\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(array, dimensions)\u001b[0m\n\u001b[1;32m   1289\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[0mresult_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m   \u001b[0mbroadcast_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbroadcast_in_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1289\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[0mresult_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m   \u001b[0mbroadcast_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbroadcast_in_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6fNHw16jjMxP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}