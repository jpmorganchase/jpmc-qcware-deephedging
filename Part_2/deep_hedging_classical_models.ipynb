{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from absl import app\n",
        "\n",
        "# Addresses `UnrecognizedFlagError: Unknown command line flag 'f'`\n",
        "sys.argv = sys.argv[:1]\n",
        "\n",
        "# `app.run` calls `sys.exit`\n",
        "try:\n",
        "  app.run(lambda argv: None)\n",
        "except:\n",
        "  pass\n",
        "%pip install dm-haiku\n",
        "%pip install optax"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms27NQILnjaj",
        "outputId": "f859b6da-9026-435f-f0cb-5e8d6e944695"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dm-haiku\n",
            "  Downloading dm_haiku-0.0.8-py3-none-any.whl (350 kB)\n",
            "\u001b[K     |████████████████████████████████| 350 kB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.21.6)\n",
            "Collecting jmp>=0.0.2\n",
            "  Downloading jmp-0.0.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (4.1.1)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (1.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from dm-haiku) (0.8.10)\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.8 jmp-0.0.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optax\n",
            "  Downloading optax-0.1.3-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 12.4 MB/s \n",
            "\u001b[?25hCollecting chex>=0.0.4\n",
            "  Downloading chex-0.1.5-py3-none-any.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax>=0.1.55 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.17)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from optax) (4.1.1)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.7/dist-packages (from optax) (0.3.15+cuda11.cudnn805)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from optax) (1.21.6)\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from optax) (1.2.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.12.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from chex>=0.0.4->optax) (0.1.7)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (1.7.3)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (0.7.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.1.55->optax) (3.3.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (3.8.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.7/dist-packages (from etils[epath]->jax>=0.1.55->optax) (5.9.0)\n",
            "Installing collected packages: chex, optax\n",
            "Successfully installed chex-0.1.5 optax-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# qnn"
      ],
      "metadata": {
        "id": "FmXWowLFe4ye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "vuq_WrlZe8Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import sys\n",
        "\n",
        "import haiku as hk\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import optax\n",
        "from absl import app, flags\n",
        "from tqdm import trange\n",
        "from scipy import stats\n",
        "\n",
        "dt = 1/365\n",
        "\n",
        "def jumps_to_prices(jumps):\n",
        "    jumps = jumps.reshape(jumps.shape[0], FLAGS.num_days * FLAGS.num_jumps)\n",
        "    brownian = (jumps - FLAGS.bernoulli_p)  # mean 0\n",
        "    brownian /= np.sqrt(FLAGS.bernoulli_p *\n",
        "                        (1 - FLAGS.bernoulli_p))  # variance 1\n",
        "    brownian = jnp.cumsum(brownian, axis=1)  # cumulative sum\n",
        "    brownian /= np.sqrt( FLAGS.num_jumps)  # standardize\n",
        "    brownian = brownian[:, FLAGS.num_jumps * np.arange(FLAGS.num_days)]\n",
        "    t = jnp.arange(1, 1 + FLAGS.num_days) * dt\n",
        "    log_prices = (FLAGS.mu - FLAGS.sigma**2 / 2) * t + FLAGS.sigma * jnp.sqrt(t) * brownian\n",
        "    prices = jnp.exp(log_prices)\n",
        "    prices = jnp.concatenate((jnp.ones((prices.shape[0], 1)), prices), axis=1)\n",
        "    prices *= FLAGS.initial_price\n",
        "    return prices[..., None]\n",
        "\n",
        "def prices_to_BSdeltas(seq_prices):\n",
        "  seq_prices = seq_prices[:,:-1]\n",
        "  T = jnp.arange(1, FLAGS.num_days+1)*dt\n",
        "  T = jnp.repeat(jnp.flip(T[None,:]), seq_prices.shape[0],0)\n",
        "  d1 = jnp.divide(jnp.log(seq_prices[...,0]/FLAGS.strike_price)+ (FLAGS.mu + 0.5 * FLAGS.sigma **2)* T, FLAGS.sigma * jnp.sqrt(T))\n",
        "  seq_bs_deltas = (stats.norm.cdf(d1, 0.0, 1.0))[...,None]\n",
        "  seq_deltas = seq_bs_deltas\n",
        "  seq_actions = jnp.concatenate(\n",
        "            [seq_deltas[:, [0]], seq_deltas[:, 1:] - seq_deltas[:, :-1]],\n",
        "            axis=1) \n",
        "  return seq_deltas, seq_actions\n",
        "\n",
        "def build_actor_fn():\n",
        "    def actor_fn(seq_jumps):\n",
        "        seq_deltas = []\n",
        "        seq_prices = jumps_to_prices(seq_jumps)\n",
        "        for time_step in range(FLAGS.num_days):\n",
        "            features = seq_prices[:, :time_step]\n",
        "            features = features.reshape(features.shape[0], -1)\n",
        "            net = hk.nets.MLP(FLAGS.hidden_layers*[FLAGS.hidden_units] + [1])\n",
        "            deltas = 0.5 * (1 + jax.nn.tanh(net(features)))\n",
        "            seq_deltas.append(deltas)\n",
        "        seq_deltas = jnp.stack(seq_deltas, axis=1)\n",
        "        seq_actions = jnp.concatenate(\n",
        "            [seq_deltas[:, [0]], seq_deltas[:, 1:] - seq_deltas[:, :-1]],\n",
        "            axis=1)\n",
        "        return seq_deltas, seq_actions\n",
        "\n",
        "    return actor_fn\n",
        "\n",
        "\n",
        "def build_critic_fn(activation_fn=None):\n",
        "    def critic_fn(seq_jumps, seq_deltas):\n",
        "        seq_values = []\n",
        "        seq_prices = jumps_to_prices(seq_jumps)\n",
        "        for time_step in range(FLAGS.num_days):\n",
        "            features = seq_prices[:, :time_step]\n",
        "            features = features.reshape(features.shape[0], -1)\n",
        "            net = hk.nets.MLP([FLAGS.hidden_units, FLAGS.hidden_units, 1])\n",
        "            if activation_fn:\n",
        "              values = activation_fn(net(features))\n",
        "            else:\n",
        "              values = net(features)\n",
        "            seq_values.append(values)\n",
        "        seq_values = jnp.stack(seq_values, axis=1)\n",
        "        return seq_values\n",
        "\n",
        "    return critic_fn\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0zT_4EZdmZy9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MZNiKgUnYjY2"
      },
      "outputs": [],
      "source": [
        "import math \n",
        "def binom(n, k):\n",
        "    return math.factorial(n) // math.factorial(k) // math.factorial(n - k)\n",
        "def build_critic_distributional_fn(activation_fn=None):\n",
        "    def critic_fn(seq_jumps, seq_deltas):\n",
        "        seq_values = []\n",
        "        seq_dist_values = []\n",
        "        seq_prices = jumps_to_prices(seq_jumps)\n",
        "        for time_step in range(FLAGS.num_days):\n",
        "            features = seq_prices[:, :time_step]\n",
        "            features = features.reshape(features.shape[0], -1)\n",
        "            net = hk.nets.MLP([FLAGS.hidden_units, FLAGS.hidden_units, FLAGS.num_days - time_step + 1])\n",
        "            if activation_fn:\n",
        "              dist_values = activation_fn(net(features))\n",
        "            else:\n",
        "              dist_values = net(features)\n",
        "            dist_probs = jnp.array([binom(FLAGS.num_days - time_step, k) for k in range(FLAGS.num_days - time_step+1)])\n",
        "            dist_probs /= 2** (FLAGS.num_days - time_step)\n",
        "            values = jnp.einsum('i,...i->...', dist_probs, dist_values)\n",
        "            values = values[...,None]            \n",
        "            seq_values.append(values)\n",
        "            seq_dist_values.append(dist_values)\n",
        "        seq_values = jnp.stack(seq_values, axis=1)\n",
        "        return seq_values, seq_dist_values\n",
        "\n",
        "    return critic_fn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dh_actor_critic_dist(critic_loss_version):\n",
        "  np_random = np.random.RandomState(seed=FLAGS.seed)\n",
        "  rng_key = hk.PRNGSequence(np_random.randint(0, sys.maxsize + 1))\n",
        "  actor_fn = build_actor_fn()\n",
        "  actor_net = hk.transform(actor_fn)\n",
        "  actor_params = actor_net.init(\n",
        "      next(rng_key), jnp.ones((1, FLAGS.num_days, FLAGS.num_jumps)))\n",
        "  actor_opt = optax.adamw(FLAGS.actor_lr)\n",
        "  actor_state = actor_opt.init(actor_params)\n",
        "  buffer = collections.deque(maxlen=FLAGS.num_buffer_episodes)\n",
        "  critic_fn = build_critic_distributional_fn(jax.nn.softplus)\n",
        "  critic_net = hk.transform(critic_fn)\n",
        "  critic_params = critic_net.init(\n",
        "      next(rng_key), jnp.ones((1, FLAGS.num_days, FLAGS.num_jumps)),\n",
        "      jnp.ones((1, FLAGS.num_days, 1)))\n",
        "  critic_opt = optax.adam(FLAGS.critic_lr)\n",
        "  critic_state = critic_opt.init(critic_params)\n",
        "\n",
        "  def critic_loss_fn(critic_params, key, seq_jumps,\n",
        "                      seq_deltas, seq_rewards, seq_returns):\n",
        "      critic_key, target_key = jax.random.split(key, 2)\n",
        "      _ , seq_dist_values = critic_net.apply(critic_params, critic_key, seq_jumps,\n",
        "                                    seq_deltas)\n",
        "      preds = []\n",
        "      for time_step in range(FLAGS.num_days):\n",
        "        future = seq_jumps[:,time_step:,0]\n",
        "        weight = future.sum(axis=-1)\n",
        "        pred = jax.vmap(jax.lax.dynamic_index_in_dim)(seq_dist_values[time_step],jnp.int32(weight))\n",
        "        preds.append(pred)\n",
        "      preds = jnp.stack(preds,axis=1)\n",
        "      seq_values = preds\n",
        "      print\n",
        "      if critic_loss_version==0:\n",
        "          loss = (jnp.exp(-FLAGS.lamda * seq_returns)\n",
        "          - seq_values)**2\n",
        "      elif critic_loss_version==1:\n",
        "           loss = 1 / FLAGS.lamda * jnp.exp(\n",
        "          -FLAGS.lamda * (seq_targets - seq_values)) - seq_values\n",
        "      return loss.mean()\n",
        "\n",
        "  @jax.jit\n",
        "  def critic_train_step(critic_params, critic_state, key,\n",
        "                        seq_jumps, seq_deltas, seq_rewards, seq_returns):\n",
        "      loss, grad = jax.value_and_grad(critic_loss_fn)(\n",
        "          critic_params, key, seq_jumps, seq_deltas,\n",
        "          seq_rewards, seq_returns)\n",
        "      updates, critic_state = critic_opt.update(grad, critic_state,\n",
        "                                                critic_params)\n",
        "      critic_new_params = optax.apply_updates(critic_params, updates)\n",
        "      critic_params = jax.tree_util.tree_map(\n",
        "          lambda x, y: (1 - FLAGS.critic_tau) * x + FLAGS.critic_tau * y,\n",
        "          critic_new_params, critic_params)\n",
        "      return critic_params, critic_state, loss\n",
        "\n",
        "  def actor_loss_fn(actor_params, critic_params, key, seq_jumps):\n",
        "      critic_key, actor_key = jax.random.split(key, 2)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, actor_key,\n",
        "                                                seq_jumps)\n",
        "      seq_values, _ = critic_net.apply(critic_params, critic_key, seq_jumps,\n",
        "                                    seq_deltas)\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_values = jnp.concatenate(\n",
        "          [seq_values[:, 1:], final_rewards[..., None]], axis=1)\n",
        "      # loss =  -(seq_rewards - jnp.log(\n",
        "      #     1 / FLAGS.lamda * seq_values))\n",
        "      # loss = 1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda *\n",
        "      #                                   (seq_rewards + seq_values))\n",
        "      loss  = -(seq_rewards[0, 0] - 1/FLAGS.lamda* jnp.log( seq_values))\n",
        "      return loss.mean()\n",
        "\n",
        "  @jax.jit\n",
        "  def actor_train_step(actor_params, critic_params, actor_state, key,\n",
        "                        seq_jumps):\n",
        "      loss, grad = jax.value_and_grad(actor_loss_fn)(actor_params,\n",
        "                                                      critic_params, key,\n",
        "                                                      seq_jumps)\n",
        "      updates, actor_state = actor_opt.update(grad, actor_state,\n",
        "                                              actor_params)\n",
        "      actor_params = optax.apply_updates(actor_params, updates)\n",
        "      return actor_params, actor_state, loss\n",
        "\n",
        "  @jax.jit\n",
        "  def rollout_step(actor_params, key, seq_jumps):\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, key,\n",
        "                                                seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_next_rewards = jnp.concatenate(\n",
        "          [seq_rewards[:, 1:], final_rewards[..., None]], axis=1)\n",
        "      seq_returns = jnp.cumsum(seq_next_rewards[:, ::-1],\n",
        "                                axis=-1)[:, ::-1]\n",
        "      return seq_deltas, seq_actions, seq_rewards, seq_returns\n",
        "  def eval_step(actor_params, key, seq_jumps):\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, key, seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      seq_returns = jnp.sum(seq_rewards[:, 1:], axis=1)\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_returns += final_rewards\n",
        "      eval_returns = seq_rewards[0, 0] - jnp.log(\n",
        "          1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda * seq_returns).mean())\n",
        "      return eval_returns\n",
        "  plot_info = {}\n",
        "  plot_info['utility'] = []\n",
        "  plot_info['actor_loss'] = []\n",
        "  plot_info['critic_loss'] = []\n",
        "  with trange(FLAGS.num_train_steps) as t:\n",
        "      for train_step in t:\n",
        "          # Rollout\n",
        "          shape = (FLAGS.num_rollout_episodes, FLAGS.num_days,\n",
        "                  FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          seq_deltas, seq_actions, seq_rewards, seq_returns = rollout_step(\n",
        "              actor_params, next(rng_key), seq_jumps)\n",
        "          for episode in range(FLAGS.num_rollout_episodes):\n",
        "              buffer.append(\n",
        "                  tuple(seq[episode] for seq in (seq_jumps, seq_deltas,\n",
        "                                                seq_rewards, seq_returns)))\n",
        "          # Train critic\n",
        "          critic_idxs = np_random.randint(0,\n",
        "                                          len(buffer),\n",
        "                                          size=FLAGS.num_critic_episodes)\n",
        "          critic_episodes = [buffer[idx] for idx in critic_idxs]\n",
        "          seq_jumps, seq_deltas, seq_rewards, seq_returns = (\n",
        "              jnp.asarray(seq) for seq in zip(*critic_episodes))\n",
        "          critic_params, critic_state, critic_loss = critic_train_step(\n",
        "              critic_params, critic_state, next(rng_key),\n",
        "              seq_jumps, seq_deltas, seq_rewards, seq_returns)\n",
        "\n",
        "          # Train actor\n",
        "          actor_idxs = np_random.randint(0,\n",
        "                                        len(buffer),\n",
        "                                        size=FLAGS.num_actor_episodes)\n",
        "          actor_episodes = [buffer[idx] for idx in actor_idxs]\n",
        "          seq_jumps, _, _, _ = (jnp.asarray(seq)\n",
        "                                for seq in zip(*actor_episodes))\n",
        "          actor_params, actor_state, actor_loss = actor_train_step(\n",
        "              actor_params, critic_params, actor_state, next(rng_key),\n",
        "              seq_jumps)\n",
        "\n",
        "          # Evaluate\n",
        "          shape = (FLAGS.num_eval_episodes, FLAGS.num_days, FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          eval_returns = eval_step(actor_params, next(rng_key), seq_jumps)\n",
        "          plot_info['utility'].append(eval_returns.mean())\n",
        "          plot_info['actor_loss'].append(actor_loss)\n",
        "          plot_info['critic_loss'].append(critic_loss)\n",
        "          t.set_postfix(utility=eval_returns.mean(), actor_loss=actor_loss,critic_loss=critic_loss)\n",
        "  return plot_info"
      ],
      "metadata": {
        "id": "mgqct7xFmUhd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FLAGS = flags.FLAGS\n",
        "# Delete all existing attributes in flag before defining any new\n",
        "for name in list(flags.FLAGS): \n",
        "      delattr(flags.FLAGS,name)\n",
        "flags.DEFINE_integer(\"seed\", 42, \"Random seed.\")\n",
        "flags.DEFINE_integer(\"num_days\", 8, \"Number of days per episode.\")\n",
        "flags.DEFINE_integer(\"num_trading_days\", 251, \"Number of trading days in year.\")\n",
        "flags.DEFINE_integer(\"num_jumps\", 1, \"Number jumps per day.\")\n",
        "flags.DEFINE_float(\"bernoulli_p\", 0.5, \"Bernoulli p of Wiener process.\")\n",
        "flags.DEFINE_float(\"mu\", 0., \"Drift of Wiener process.\")\n",
        "flags.DEFINE_float(\"sigma\", 0.2, \"Volatility of Wiener process.\")\n",
        "flags.DEFINE_float(\"initial_price\", 100., \"Initial price.\")\n",
        "flags.DEFINE_float(\"strike_price\", 100., \"Strike price.\")\n",
        "flags.DEFINE_float(\"lamda\", 0.1, \"Risk-measure factor.\")\n",
        "flags.DEFINE_float(\"cost_eps\", 0., \"Cost epsilon.\")\n",
        "flags.DEFINE_integer(\"num_train_steps\", 500, \"Number of train steps.\")\n",
        "flags.DEFINE_integer(\"num_actor_episodes\", 16, \"Number of actor episodes.\")\n",
        "flags.DEFINE_integer(\"num_eval_episodes\", 128, \"Number of eval episodes.\")\n",
        "flags.DEFINE_float(\"actor_lr\", 1E-1, \"Actor learning rate.\")\n",
        "flags.DEFINE_integer(\"hidden_units\", 16, \"Number of hidden units.\")\n",
        "flags.DEFINE_integer(\"hidden_layers\", 2, \"Number of hidden layers.\")\n",
        "flags.DEFINE_integer(\"num_buffer_episodes\", 64,\n",
        "                      \"Number of buffer episodes.\")\n",
        "flags.DEFINE_integer(\"num_critic_episodes\", 64,\n",
        "                      \"Number of critic episodes.\")\n",
        "flags.DEFINE_integer(\"num_rollout_episodes\", 64,\n",
        "                      \"Number of rollout episodes.\")\n",
        "flags.DEFINE_float(\"critic_lr\", 1E-2, \"Critic learning rate.\")\n",
        "flags.DEFINE_float(\"critic_tau\", 0.001, \"Critic target smoothing factor.\")\n",
        "FLAGS(sys.argv)\n",
        "distributional_actor_critic_info  = dh_actor_critic_dist(critic_loss_version=0)"
      ],
      "metadata": {
        "id": "za2mBc7Znqag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dh_vanilla():\n",
        "  np_random = np.random.RandomState(seed=FLAGS.seed)\n",
        "  rng_key = hk.PRNGSequence(np_random.randint(0, sys.maxsize + 1))\n",
        "  actor_fn = build_actor_fn()\n",
        "  actor_net = hk.transform(actor_fn)\n",
        "  actor_params = actor_net.init(\n",
        "      next(rng_key), jnp.ones((1, FLAGS.num_days, FLAGS.num_jumps)))\n",
        "  actor_opt = optax.adamw(FLAGS.actor_lr)\n",
        "  actor_state = actor_opt.init(actor_params)\n",
        "  def actor_loss_fn(actor_params, key, seq_jumps):\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, key,\n",
        "                                                seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      seq_returns = jnp.sum(seq_rewards[:, 1:], axis=1)\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = -jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_returns += final_rewards\n",
        "      loss = -(seq_rewards[0, 0] - jnp.log(\n",
        "          1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda * seq_returns).mean()))\n",
        "      return loss.mean()\n",
        "\n",
        "  @jax.jit\n",
        "  def actor_train_step(actor_params, actor_state, key, seq_jumps):\n",
        "      loss, grad = jax.value_and_grad(actor_loss_fn)(actor_params, key,\n",
        "                                                      seq_jumps)\n",
        "      updates, actor_state = actor_opt.update(grad, actor_state,\n",
        "                                              actor_params)\n",
        "      actor_params = optax.apply_updates(actor_params, updates)\n",
        "      return actor_params, actor_state, loss\n",
        "  def eval_step(actor_params, key, seq_jumps):\n",
        "        seq_prices = jumps_to_prices(seq_jumps)\n",
        "        seq_deltas, seq_actions = actor_net.apply(actor_params, key, seq_jumps)\n",
        "        seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                        seq_actions) * seq_prices[:, :-1]\n",
        "        seq_returns = jnp.sum(seq_rewards[:, 1:], axis=1)\n",
        "        final_actions = -seq_deltas[:, -1]\n",
        "        final_rewards = -jnp.maximum(\n",
        "            seq_prices[:, -1] - FLAGS.strike_price,\n",
        "            0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                  final_actions) * seq_prices[:, -1]\n",
        "        seq_returns += final_rewards\n",
        "        eval_returns = seq_rewards[0, 0] - jnp.log(\n",
        "            1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda * seq_returns).mean())\n",
        "        return eval_returns\n",
        "  def eval_BS(seq_jumps):\n",
        "    seq_prices = jumps_to_prices(seq_jumps)\n",
        "    seq_deltas,seq_actions = prices_to_BSdeltas(seq_prices)\n",
        "    seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                        seq_actions) * seq_prices[:, :-1]\n",
        "    seq_returns = jnp.sum(seq_rewards[:, 1:], axis=1)\n",
        "    final_actions = -seq_deltas[:, -1]\n",
        "    final_rewards = jnp.maximum(\n",
        "        seq_prices[:, -1] - FLAGS.strike_price,\n",
        "        0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "              final_actions) * seq_prices[:, -1]\n",
        "    seq_returns += final_rewards\n",
        "    eval_returns = seq_rewards[0, 0] - jnp.log(\n",
        "        1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda * seq_returns).mean())\n",
        "    return eval_returns\n",
        "\n",
        "  plot_info = {}\n",
        "  plot_info['actor_loss'] = []\n",
        "  plot_info['utility'] = []\n",
        "  plot_info['BS utility'] = []\n",
        "  with trange(FLAGS.num_train_steps) as t:\n",
        "      for train_step in t:\n",
        "          # Train Actor\n",
        "          shape = (FLAGS.num_actor_episodes, FLAGS.num_days, FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          actor_params, actor_state, actor_loss = actor_train_step(\n",
        "              actor_params, actor_state, next(rng_key), seq_jumps)\n",
        "          # Evaluate\n",
        "          shape = (FLAGS.num_eval_episodes, FLAGS.num_days, FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          eval_returns = eval_step(actor_params, next(rng_key), seq_jumps)\n",
        "          BS_returns = eval_BS(seq_jumps)\n",
        "          plot_info['actor_loss'].append(actor_loss)\n",
        "          plot_info['utility'].append(eval_returns.mean())\n",
        "          plot_info['BS utility'].append(BS_returns.mean())\n",
        "          t.set_postfix(utility=eval_returns.mean(),BS_utility=BS_returns.mean(),actor_loss=actor_loss)\n",
        "  return plot_info\n"
      ],
      "metadata": {
        "id": "lOvKOcMT1AN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FLAGS = flags.FLAGS\n",
        "# Delete all existing attributes in flag before defining any new\n",
        "for name in list(flags.FLAGS): \n",
        "      delattr(flags.FLAGS,name)\n",
        "flags.DEFINE_integer(\"seed\", 42, \"Random seed.\")\n",
        "flags.DEFINE_integer(\"num_days\", 8, \"Number of days per episode.\")\n",
        "flags.DEFINE_integer(\"num_jumps\", 1, \"Number jumps per day.\")\n",
        "flags.DEFINE_float(\"bernoulli_p\", 0.5, \"Bernoulli p of Wiener process.\")\n",
        "flags.DEFINE_float(\"mu\", 0., \"Drift of Wiener process.\")\n",
        "flags.DEFINE_float(\"sigma\", 0.2, \"Volatility of Wiener process.\")\n",
        "flags.DEFINE_float(\"initial_price\", 100., \"Initial price.\")\n",
        "flags.DEFINE_float(\"strike_price\", 100., \"Strike price.\")\n",
        "flags.DEFINE_float(\"lamda\", 0.1, \"Risk-measure factor.\")\n",
        "flags.DEFINE_float(\"cost_eps\", 0., \"Cost epsilon.\")\n",
        "flags.DEFINE_integer(\"num_train_steps\", 500, \"Number of train steps.\")\n",
        "flags.DEFINE_integer(\"num_actor_episodes\", 16, \"Number of actor episodes.\")\n",
        "flags.DEFINE_integer(\"num_eval_episodes\", 128, \"Number of eval episodes.\")\n",
        "flags.DEFINE_float(\"actor_lr\", 1E-1, \"Actor learning rate.\")\n",
        "flags.DEFINE_integer(\"hidden_units\", 8, \"Number of hidden units.\")\n",
        "flags.DEFINE_integer(\"hidden_layers\", 2, \"Number of hidden layers.\")\n",
        "dh_vanilla_info = dh_vanilla()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL_diPAU6Oa1",
        "outputId": "07acdf5c-347f-404e-e159-d8e87ee70a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [00:47<00:00, 10.46it/s, BS_utility=-47.712574, actor_loss=2.7781162, utility=-2.6838903]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(dh_vanilla_info['utility'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "nh_Kg-Lzxi54",
        "outputId": "c3a24b46-72a1-45d7-b090-4f394c877b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7feed5016cd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot()\n",
        "plt.title('8 days no transaction costs')\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Utility')\n",
        "plt.plot(dh_vanilla_info['utility'],label='vanilla')\n",
        "# plt.plot(distributional_actor_critic_info['utility'],label='distributional-actor-critic')\n",
        "plt.plot(dh_expected_actor_critic_info['utility'],label='expected-actor-critic')\n",
        "plt.plot(jp_ac_info['utility'],label='[jpmc]actor-critic')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "psHA_exV90Us",
        "outputId": "4cc1fc77-21ee-41b5-eb82-c013f05270cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7feed566e9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dh_actor_critic_v0(critic_loss_version):\n",
        "  np_random = np.random.RandomState(seed=FLAGS.seed)\n",
        "  rng_key = hk.PRNGSequence(np_random.randint(0, sys.maxsize + 1))\n",
        "  actor_fn = build_actor_fn()\n",
        "  actor_net = hk.transform(actor_fn)\n",
        "  actor_params = actor_net.init(\n",
        "      next(rng_key), jnp.ones((1, FLAGS.num_days, FLAGS.num_jumps)))\n",
        "  actor_opt = optax.adamw(FLAGS.actor_lr)\n",
        "  actor_state = actor_opt.init(actor_params)\n",
        "  buffer = collections.deque(maxlen=FLAGS.num_buffer_episodes)\n",
        "  critic_fn = build_critic_fn(activation_fn=jax.nn.softplus)\n",
        "  critic_net = hk.transform(critic_fn)\n",
        "  critic_params = critic_net.init(\n",
        "      next(rng_key), jnp.ones((1, FLAGS.num_days, FLAGS.num_jumps)),\n",
        "      jnp.ones((1, FLAGS.num_days, 1)))\n",
        "  critic_opt = optax.adam(FLAGS.critic_lr)\n",
        "  critic_state = critic_opt.init(critic_params)\n",
        "\n",
        "  def critic_loss_fn(critic_params, key, seq_jumps,\n",
        "                      seq_deltas, seq_rewards, seq_returns):\n",
        "      critic_key, target_key = jax.random.split(key, 2)\n",
        "      seq_values = critic_net.apply(critic_params, critic_key, seq_jumps,\n",
        "                                    seq_deltas)\n",
        "      seq_targets = seq_returns\n",
        "      if critic_loss_version==0:\n",
        "          loss = (jnp.exp(-FLAGS.lamda * seq_targets)\n",
        "          - seq_values)**2\n",
        "      elif critic_loss_version==1:\n",
        "           loss = 1 / FLAGS.lamda * jnp.exp(\n",
        "          -FLAGS.lamda * (seq_targets - seq_values)) - seq_values\n",
        "      return loss.mean()\n",
        "\n",
        "  @jax.jit\n",
        "  def critic_train_step(critic_params, critic_state, key,\n",
        "                        seq_jumps, seq_deltas, seq_rewards, seq_returns):\n",
        "      loss, grad = jax.value_and_grad(critic_loss_fn)(\n",
        "          critic_params, key, seq_jumps, seq_deltas,\n",
        "          seq_rewards, seq_returns)\n",
        "      updates, critic_state = critic_opt.update(grad, critic_state,\n",
        "                                                critic_params)\n",
        "      critic_new_params = optax.apply_updates(critic_params, updates)\n",
        "      critic_params = jax.tree_util.tree_map(\n",
        "          lambda x, y: (1 - FLAGS.critic_tau) * x + FLAGS.critic_tau * y,\n",
        "          critic_new_params, critic_params)\n",
        "      return critic_params, critic_state, loss\n",
        "\n",
        "  def actor_loss_fn(actor_params, critic_params, key, seq_jumps):\n",
        "      critic_key, actor_key = jax.random.split(key, 2)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, actor_key,\n",
        "                                                seq_jumps)\n",
        "      seq_values = critic_net.apply(critic_params, critic_key, seq_jumps,\n",
        "                                    seq_deltas)\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_values = jnp.concatenate(\n",
        "          [seq_values[:, 1:], final_rewards[..., None]], axis=1)\n",
        "      # loss =  -(seq_rewards - jnp.log(\n",
        "      #     1 / FLAGS.lamda * seq_values))\n",
        "      # loss = 1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda *\n",
        "      #                                   (seq_rewards + seq_values))\n",
        "      loss  = -(seq_rewards[0, 0] - 1/FLAGS.lamda* jnp.log( seq_values))\n",
        "      return loss.mean()\n",
        "\n",
        "  @jax.jit\n",
        "  def actor_train_step(actor_params, critic_params, actor_state, key,\n",
        "                        seq_jumps):\n",
        "      loss, grad = jax.value_and_grad(actor_loss_fn)(actor_params,\n",
        "                                                      critic_params, key,\n",
        "                                                      seq_jumps)\n",
        "      updates, actor_state = actor_opt.update(grad, actor_state,\n",
        "                                              actor_params)\n",
        "      actor_params = optax.apply_updates(actor_params, updates)\n",
        "      return actor_params, actor_state, loss\n",
        "\n",
        "  @jax.jit\n",
        "  def rollout_step(actor_params, key, seq_jumps):\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, key,\n",
        "                                                seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_next_rewards = jnp.concatenate(\n",
        "          [seq_rewards[:, 1:], final_rewards[..., None]], axis=1)\n",
        "      seq_returns = jnp.cumsum(seq_next_rewards[:, ::-1],\n",
        "                                axis=-1)[:, ::-1]\n",
        "      return seq_deltas, seq_actions, seq_rewards, seq_returns\n",
        "  def eval_step(actor_params, key, seq_jumps):\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, key, seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      seq_returns = jnp.sum(seq_rewards[:, 1:], axis=1)\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_returns += final_rewards\n",
        "      eval_returns = seq_rewards[0, 0] - jnp.log(\n",
        "          1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda * seq_returns).mean())\n",
        "      return eval_returns\n",
        "  plot_info = {}\n",
        "  plot_info['utility'] = []\n",
        "  plot_info['actor_loss'] = []\n",
        "  plot_info['critic_loss'] = []\n",
        "  with trange(FLAGS.num_train_steps) as t:\n",
        "      for train_step in t:\n",
        "          # Rollout\n",
        "          shape = (FLAGS.num_rollout_episodes, FLAGS.num_days,\n",
        "                  FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          seq_deltas, seq_actions, seq_rewards, seq_returns = rollout_step(\n",
        "              actor_params, next(rng_key), seq_jumps)\n",
        "          for episode in range(FLAGS.num_rollout_episodes):\n",
        "              buffer.append(\n",
        "                  tuple(seq[episode] for seq in (seq_jumps, seq_deltas,\n",
        "                                                seq_rewards, seq_returns)))\n",
        "          # Train critic\n",
        "          critic_idxs = np_random.randint(0,\n",
        "                                          len(buffer),\n",
        "                                          size=FLAGS.num_critic_episodes)\n",
        "          critic_episodes = [buffer[idx] for idx in critic_idxs]\n",
        "          seq_jumps, seq_deltas, seq_rewards, seq_returns = (\n",
        "              jnp.asarray(seq) for seq in zip(*critic_episodes))\n",
        "          critic_params, critic_state, critic_loss = critic_train_step(\n",
        "              critic_params, critic_state, next(rng_key),\n",
        "              seq_jumps, seq_deltas, seq_rewards, seq_returns)\n",
        "\n",
        "          # Train actor\n",
        "          actor_idxs = np_random.randint(0,\n",
        "                                        len(buffer),\n",
        "                                        size=FLAGS.num_actor_episodes)\n",
        "          actor_episodes = [buffer[idx] for idx in actor_idxs]\n",
        "          seq_jumps, _, _, _ = (jnp.asarray(seq)\n",
        "                                for seq in zip(*actor_episodes))\n",
        "          actor_params, actor_state, actor_loss = actor_train_step(\n",
        "              actor_params, critic_params, actor_state, next(rng_key),\n",
        "              seq_jumps)\n",
        "\n",
        "          # Evaluate\n",
        "          shape = (FLAGS.num_eval_episodes, FLAGS.num_days, FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          eval_returns = eval_step(actor_params, next(rng_key), seq_jumps)\n",
        "          plot_info['utility'].append(eval_returns.mean())\n",
        "          plot_info['actor_loss'].append(actor_loss)\n",
        "          plot_info['critic_loss'].append(critic_loss)\n",
        "          t.set_postfix(utility=eval_returns.mean(), actor_loss=actor_loss,critic_loss=critic_loss)\n",
        "  return plot_info"
      ],
      "metadata": {
        "id": "KqLQx-sl6PnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FLAGS = flags.FLAGS\n",
        "# Delete all existing attributes in flag before defining any new\n",
        "for name in list(flags.FLAGS): \n",
        "      delattr(flags.FLAGS,name)\n",
        "flags.DEFINE_integer(\"seed\", 42, \"Random seed.\")\n",
        "flags.DEFINE_integer(\"num_days\", 8, \"Number of days per episode.\")\n",
        "flags.DEFINE_integer(\"num_trading_days\", 251, \"Number of trading days in year.\")\n",
        "flags.DEFINE_integer(\"num_jumps\", 1, \"Number jumps per day.\")\n",
        "flags.DEFINE_float(\"bernoulli_p\", 0.5, \"Bernoulli p of Wiener process.\")\n",
        "flags.DEFINE_float(\"mu\", 0., \"Drift of Wiener process.\")\n",
        "flags.DEFINE_float(\"sigma\", 0.2, \"Volatility of Wiener process.\")\n",
        "flags.DEFINE_float(\"initial_price\", 100., \"Initial price.\")\n",
        "flags.DEFINE_float(\"strike_price\", 100., \"Strike price.\")\n",
        "flags.DEFINE_float(\"lamda\", 0.1, \"Risk-measure factor.\")\n",
        "flags.DEFINE_float(\"cost_eps\", 0., \"Cost epsilon.\")\n",
        "flags.DEFINE_integer(\"num_train_steps\", 500, \"Number of train steps.\")\n",
        "flags.DEFINE_integer(\"num_actor_episodes\", 16, \"Number of actor episodes.\")\n",
        "flags.DEFINE_integer(\"num_eval_episodes\", 128, \"Number of eval episodes.\")\n",
        "flags.DEFINE_float(\"actor_lr\", 1E-1, \"Actor learning rate.\")\n",
        "flags.DEFINE_integer(\"hidden_units\", 16, \"Number of hidden units.\")\n",
        "flags.DEFINE_integer(\"hidden_layers\", 2, \"Number of hidden layers.\")\n",
        "flags.DEFINE_integer(\"num_buffer_episodes\", 64,\n",
        "                      \"Number of buffer episodes.\")\n",
        "flags.DEFINE_integer(\"num_critic_episodes\", 64,\n",
        "                      \"Number of critic episodes.\")\n",
        "flags.DEFINE_integer(\"num_rollout_episodes\", 64,\n",
        "                      \"Number of rollout episodes.\")\n",
        "flags.DEFINE_float(\"critic_lr\", 1E-2, \"Critic learning rate.\")\n",
        "flags.DEFINE_float(\"critic_tau\", 0.001, \"Critic target smoothing factor.\")\n",
        "FLAGS(sys.argv)\n",
        "dh_expected_actor_critic_info  = dh_actor_critic_v0(critic_loss_version=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCQpODT97vIt",
        "outputId": "8745f6fd-36c5-46fd-a384-513051a53c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [02:02<00:00,  4.07it/s, actor_loss=-inf, critic_loss=89049704.0, utility=-2.4364672]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dh_actor_critic_jp():\n",
        "  np_random = np.random.RandomState(seed=FLAGS.seed)\n",
        "  rng_key = hk.PRNGSequence(np_random.randint(0, sys.maxsize + 1))\n",
        "  actor_fn = build_actor_fn()\n",
        "  actor_net = hk.transform(actor_fn)\n",
        "  actor_params = actor_net.init(\n",
        "      next(rng_key), jnp.ones((1, FLAGS.num_days, FLAGS.num_jumps)))\n",
        "  actor_opt = optax.adamw(FLAGS.actor_lr)\n",
        "  actor_state = actor_opt.init(actor_params)\n",
        "  buffer = collections.deque(maxlen=FLAGS.num_buffer_episodes)\n",
        "  critic_fn = build_critic_fn()\n",
        "  critic_net = hk.transform(critic_fn)\n",
        "  critic_params = target_params = critic_net.init(\n",
        "      next(rng_key), jnp.ones((1, FLAGS.num_days, FLAGS.num_jumps)),\n",
        "      jnp.ones((1, FLAGS.num_days, 1)))\n",
        "  critic_opt = optax.adam(FLAGS.critic_lr)\n",
        "  critic_state = critic_opt.init(critic_params)\n",
        "\n",
        "  def critic_loss_fn(critic_params, target_params, key, seq_jumps,\n",
        "                      seq_deltas, seq_rewards, seq_returns):\n",
        "      critic_key, target_key = jax.random.split(key, 2)\n",
        "      seq_values = critic_net.apply(critic_params, critic_key, seq_jumps,\n",
        "                                    seq_deltas)\n",
        "      seq_target_values = critic_net.apply(target_params, target_key,\n",
        "                                            seq_jumps, seq_deltas)\n",
        "      last_target_values = seq_returns[:, -1][..., None]\n",
        "      seq_target_values = jnp.concatenate(\n",
        "          [seq_target_values[:, 1:], last_target_values], axis=1)\n",
        "      seq_targets = seq_rewards + seq_target_values\n",
        "      loss = 1 / FLAGS.lamda * jnp.exp(\n",
        "          -FLAGS.lamda * (seq_targets - seq_values)) - seq_values\n",
        "      return loss.mean()\n",
        "\n",
        "  @jax.jit\n",
        "  def critic_train_step(critic_params, target_params, critic_state, key,\n",
        "                        seq_jumps, seq_deltas, seq_rewards, seq_returns):\n",
        "      loss, grad = jax.value_and_grad(critic_loss_fn)(\n",
        "          critic_params, target_params, key, seq_jumps, seq_deltas,\n",
        "          seq_rewards, seq_returns)\n",
        "      updates, critic_state = critic_opt.update(grad, critic_state,\n",
        "                                                critic_params)\n",
        "      critic_params = optax.apply_updates(critic_params, updates)\n",
        "      target_params = jax.tree_util.tree_map(\n",
        "          lambda x, y: (1 - FLAGS.critic_tau) * x + FLAGS.critic_tau * y,\n",
        "          target_params, critic_params)\n",
        "      # target_params = critic_params\n",
        "      return critic_params, target_params, critic_state, loss\n",
        "\n",
        "  def actor_loss_fn(actor_params, critic_params, key, seq_jumps):\n",
        "      critic_key, actor_key = jax.random.split(key, 2)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, actor_key,\n",
        "                                                seq_jumps)\n",
        "      seq_values = critic_net.apply(critic_params, critic_key, seq_jumps,\n",
        "                                    seq_deltas)\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_values = jnp.concatenate(\n",
        "          [seq_values[:, 1:], final_rewards[..., None]], axis=1)\n",
        "      loss = 1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda *\n",
        "                                        (seq_rewards + seq_values))\n",
        "      return loss.mean()\n",
        "\n",
        "  @jax.jit\n",
        "  def actor_train_step(actor_params, critic_params, actor_state, key,\n",
        "                        seq_jumps):\n",
        "      loss, grad = jax.value_and_grad(actor_loss_fn)(actor_params,\n",
        "                                                      critic_params, key,\n",
        "                                                      seq_jumps)\n",
        "      updates, actor_state = actor_opt.update(grad, actor_state,\n",
        "                                              actor_params)\n",
        "      actor_params = optax.apply_updates(actor_params, updates)\n",
        "      return actor_params, actor_state, loss\n",
        "\n",
        "  @jax.jit\n",
        "  def rollout_step(actor_params, key, seq_jumps):\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, key,\n",
        "                                                seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_next_rewards = jnp.concatenate(\n",
        "          [seq_rewards[:, 1:], final_rewards[..., None]], axis=1)\n",
        "      seq_returns = jnp.cumsum(seq_next_rewards[:, ::-1],\n",
        "                                axis=-1)[:, ::-1]\n",
        "      return seq_deltas, seq_actions, seq_rewards, seq_returns\n",
        "  def eval_step(actor_params, key, seq_jumps):\n",
        "      seq_prices = jumps_to_prices(seq_jumps)\n",
        "      seq_deltas, seq_actions = actor_net.apply(actor_params, key, seq_jumps)\n",
        "      seq_rewards = -(jnp.abs(seq_actions) * FLAGS.cost_eps +\n",
        "                      seq_actions) * seq_prices[:, :-1]\n",
        "      seq_returns = jnp.sum(seq_rewards[:, 1:], axis=1)\n",
        "      final_actions = -seq_deltas[:, -1]\n",
        "      final_rewards = jnp.maximum(\n",
        "          seq_prices[:, -1] - FLAGS.strike_price,\n",
        "          0) - (jnp.abs(final_actions) * FLAGS.cost_eps +\n",
        "                final_actions) * seq_prices[:, -1]\n",
        "      seq_returns += final_rewards\n",
        "      eval_returns = seq_rewards[0, 0] - jnp.log(\n",
        "          1 / FLAGS.lamda * jnp.exp(-FLAGS.lamda * seq_returns).mean())\n",
        "      return eval_returns\n",
        "  plot_info = {}\n",
        "  plot_info['utility'] = []\n",
        "  plot_info['actor_loss'] = []\n",
        "  plot_info['critic_loss'] = []\n",
        "  with trange(FLAGS.num_train_steps) as t:\n",
        "      for train_step in t:\n",
        "          # Rollout\n",
        "          shape = (FLAGS.num_rollout_episodes, FLAGS.num_days,\n",
        "                  FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          seq_deltas, seq_actions, seq_rewards, seq_returns = rollout_step(\n",
        "              actor_params, next(rng_key), seq_jumps)\n",
        "          for episode in range(FLAGS.num_rollout_episodes):\n",
        "              buffer.append(\n",
        "                  tuple(seq[episode] for seq in (seq_jumps, seq_deltas,\n",
        "                                                seq_rewards, seq_returns)))\n",
        "          # Train critic\n",
        "          critic_idxs = np_random.randint(0,\n",
        "                                          len(buffer),\n",
        "                                          size=FLAGS.num_critic_episodes)\n",
        "          critic_episodes = [buffer[idx] for idx in critic_idxs]\n",
        "          seq_jumps, seq_deltas, seq_rewards, seq_returns = (\n",
        "              jnp.asarray(seq) for seq in zip(*critic_episodes))\n",
        "          critic_params, target_params, critic_state, critic_loss = critic_train_step(\n",
        "              critic_params, target_params, critic_state, next(rng_key),\n",
        "              seq_jumps, seq_deltas, seq_rewards, seq_returns)\n",
        "\n",
        "          # Train actor\n",
        "          actor_idxs = np_random.randint(0,\n",
        "                                        len(buffer),\n",
        "                                        size=FLAGS.num_actor_episodes)\n",
        "          actor_episodes = [buffer[idx] for idx in actor_idxs]\n",
        "          seq_jumps, _, _, _ = (jnp.asarray(seq)\n",
        "                                for seq in zip(*actor_episodes))\n",
        "          actor_params, actor_state, actor_loss = actor_train_step(\n",
        "              actor_params, critic_params, actor_state, next(rng_key),\n",
        "              seq_jumps)\n",
        "\n",
        "          # Evaluate\n",
        "          shape = (FLAGS.num_eval_episodes, FLAGS.num_days, FLAGS.num_jumps)\n",
        "          seq_jumps = jax.random.bernoulli(next(rng_key),\n",
        "                                          shape=shape,\n",
        "                                          p=FLAGS.bernoulli_p)\n",
        "          eval_returns = eval_step(actor_params, next(rng_key), seq_jumps)\n",
        "          plot_info['utility'].append(eval_returns.mean())\n",
        "          plot_info['actor_loss'].append(actor_loss)\n",
        "          plot_info['critic_loss'].append(critic_loss)\n",
        "          t.set_postfix(utility=eval_returns.mean(), actor_loss=actor_loss,critic_loss=critic_loss)\n",
        "  return plot_info"
      ],
      "metadata": {
        "id": "U1niwHvh732H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FLAGS = flags.FLAGS\n",
        "# Delete all existing attributes in flag before defining any new\n",
        "for name in list(flags.FLAGS): \n",
        "      delattr(flags.FLAGS,name)\n",
        "flags.DEFINE_integer(\"seed\", 42, \"Random seed.\")\n",
        "flags.DEFINE_integer(\"num_days\", 8, \"Number of days per episode.\")\n",
        "flags.DEFINE_integer(\"num_jumps\", 1, \"Number jumps per day.\")\n",
        "flags.DEFINE_float(\"bernoulli_p\", 0.5, \"Bernoulli p of Wiener process.\")\n",
        "flags.DEFINE_float(\"mu\", 0., \"Drift of Wiener process.\")\n",
        "flags.DEFINE_float(\"sigma\", 0.2, \"Volatility of Wiener process.\")\n",
        "flags.DEFINE_float(\"initial_price\", 100., \"Initial price.\")\n",
        "flags.DEFINE_float(\"strike_price\", 100., \"Strike price.\")\n",
        "flags.DEFINE_float(\"lamda\", 0.1, \"Risk-measure factor.\")\n",
        "flags.DEFINE_float(\"cost_eps\", 0., \"Cost epsilon.\")\n",
        "flags.DEFINE_integer(\"num_train_steps\", 500, \"Number of train steps.\")\n",
        "flags.DEFINE_integer(\"num_actor_episodes\", 16, \"Number of actor episodes.\")\n",
        "flags.DEFINE_integer(\"num_eval_episodes\", 128, \"Number of eval episodes.\")\n",
        "flags.DEFINE_float(\"actor_lr\", 1E-1, \"Actor learning rate.\")\n",
        "flags.DEFINE_integer(\"hidden_units\", 16, \"Number of hidden units.\")\n",
        "flags.DEFINE_integer(\"hidden_layers\", 2, \"Number of hidden layers.\")\n",
        "flags.DEFINE_integer(\"num_buffer_episodes\", 64,\n",
        "                      \"Number of buffer episodes.\")\n",
        "flags.DEFINE_integer(\"num_critic_episodes\", 64,\n",
        "                      \"Number of critic episodes.\")\n",
        "flags.DEFINE_integer(\"num_rollout_episodes\", 64,\n",
        "                      \"Number of rollout episodes.\")\n",
        "flags.DEFINE_float(\"critic_lr\", 1E-2, \"Critic learning rate.\")\n",
        "flags.DEFINE_float(\"critic_tau\", 0.001, \"Critic target smoothing factor.\")\n",
        "FLAGS(sys.argv)\n",
        "jp_ac_info = dh_actor_critic_jp()"
      ],
      "metadata": {
        "id": "QSjK_9j_AWFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lNCpT0lYAXex"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}